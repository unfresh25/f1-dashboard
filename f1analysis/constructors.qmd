---
title: "Campeonato Mundial de la Formula 1 (1950 - 2023)"
subtitle: "Visualización Científica"
description: |
 La Fórmula 1, también conocida como F1, representa la cúspide de las carreras internacionales de monoplazas de ruedas abiertas, bajo la supervisión de la Federación Internacional del Automóvil (FIA). Desde su primera temporada en 1950, el Campeonato Mundial de Pilotos, rebautizado como el Campeonato Mundial de Fórmula 1 de la FIA en 1981, ha destacado como una de las principales competiciones a nivel global. La palabra "fórmula" en su nombre alude al conjunto de reglas que guían a todos los participantes en cuanto a la construcción y funcionamiento de los vehículos.
---

``` {python load_os}
#| echo: false
import os 
from dotenv import load_dotenv

load_dotenv()

DATABASE_URL = os.environ.get('DATABASE_URL')
```

# ¿Qué haremos?

En esta sección, llevaremos a cabo un análisis exploratorio centrado en la tabla `constructors`, que abarca los datos de los equipos que han competido en las carreras disputadas desde 1950 hasta 2023. Sin embargo, para llevar a cabo este análisis de manera integral, necesitamos consolidar información proveniente de diversas fuentes. Utilizaremos consultas para unificar los datos de la tabla `constructors` con aquellos de las tablas `circuits` (que contiene información sobre los circuitos donde se celebran las carreras de Fórmula 1), `results` (que proporciona los resultados de las carreras), `pit_stops` (paradas realizadas en boxes).

Es fundamental destacar que, para la tabla `results` nos enfocaremos exclusivamente en los equipos que obtuvieron puntos en cada carrera. Asimismo, de la tabla `pit_stops`, extraeremos únicamente la información correspondiente a la parada en boxes más rápida realizada.

# Librerías

Para este proyecto trabajaremos con las siguientes librerías:

* Pandas
* Psycopg2
* Plotly
* Matplotlib
* Seaborn
* Scikit-learn

Pueden instalarse utilizando el siguiente comando desde la terminal: `pip install pandas psycopg2 plotly...`, o bien, mediante el archivo [requirements.txt](https://github.com/unfresh25/f1-dashboard) utilizando `pip install -r requirements.txt` en la terminal.

Una vez instaladas, podemos importarlas en nuestro entorno de trabajo de la siguiente manera:

``` {python libraries}
import pandas as pd
import psycopg2 as psy
from psycopg2 import Error

import numpy as np

from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

import plotly.graph_objects as go
import plotly.express as px
import matplotlib.pyplot as plt
import seaborn as sns

sns.set_style('white')
```

Además, haremos uso de la siguiente función para evitar la repetición de código y facilitar la conexión a la base de datos:

``` {python db_function}
def connection_db() -> psy.extensions.connection:
    try:
        conn = psy.connect(DATABASE_URL)
        return conn
    except (Exception, Error) as e:
        print('Error while connecting to PostgreSQL', e)
```

Es importante destacar que en esta función, obtenemos una variable de entorno que almacena los datos de conexión a la base de datos. En este caso, estamos utilizando [Neon](https://neon.tech/) que nos permite crear un servidor de bases de datos con `PostgreSQL`. 

# Obtención de los datos

Veamos inicialmente las columnas que tenemos para cada una de las tablas mencionadas. 

## Tabla constructors

``` {python get_race_table}
try:
    connection = connection_db()
    cursor = connection.cursor()

    cursor.execute(
        """
            SELECT *
            FROM constructors
            LIMIT 5;
        """
    )

    records = cursor.fetchall()
    records_data = pd.DataFrame(records)

    columns = []
    for column in cursor.description:
        columns.append(column[0])

    records_data.columns = columns

    display(records_data)
except (Exception, Error) as e:
    print('Error while executing the query', e)
finally:
    if(connection):
        cursor.close()
        connection.close()
```

## Tabla circuits

``` {python get_circuit_table}
try:
    connection = connection_db()
    cursor = connection.cursor()

    cursor.execute(
        """
            SELECT *
            FROM circuits
            LIMIT 5;
        """
    )

    records = cursor.fetchall()
    records_data = pd.DataFrame(records)

    columns = []
    for column in cursor.description:
        columns.append(column[0])

    records_data.columns = columns

    display(records_data)
except (Exception, Error) as e:
    print('Error while executing the query', e)
finally:
    if(connection):
        cursor.close()
        connection.close()
```

## Tabla results

``` {python get_result_table}
try:
    connection = connection_db()
    cursor = connection.cursor()

    cursor.execute(
        """
            SELECT *
            FROM results
            LIMIT 5;
        """
    )

    records = cursor.fetchall()
    records_data = pd.DataFrame(records)

    columns = []
    for column in cursor.description:
        columns.append(column[0])

    records_data.columns = columns

    display(records_data)
except (Exception, Error) as e:
    print('Error while executing the query', e)
finally:
    if(connection):
        cursor.close()
        connection.close()
```

## Tabla pit stops

``` {python get_lap_times_table}
try:
    connection = connection_db()
    cursor = connection.cursor()

    cursor.execute(
        """
            SELECT *
            FROM pit_stops
            LIMIT 5;
        """
    )

    records = cursor.fetchall()
    records_data = pd.DataFrame(records)

    columns = []
    for column in cursor.description:
        columns.append(column[0])

    records_data.columns = columns

    display(records_data)
except (Exception, Error) as e:
    print('Error while executing the query', e)
finally:
    if(connection):
        cursor.close()
        connection.close()
```

## Tabla final

Con base en las columnas proporcionadas de cada tabla, podemos listar las que se utilizarán en el análisis de la siguiente manera:

* **constructors**: constructorId, constructorRef, name, nationality
* **Circuits**: name, location, country.
* **Results**: raceId, driverId, points, grid, laps, milliseconds, fastestlap, rank, fastestlapspeed, number, status.
* **Pit Stops**: stop, miliseconds.

Realicemos entonces la consulta a la base de datos para obtener esta tabla.

``` {python get_final_table}
try:
    connection = connection_db()
    cursor = connection.cursor()

    cursor.execute(
        """
            SELECT 
                c.constructorid, c.constructorref, c.name, c.nationality,
                circuits.name AS circuit_name, circuits.location AS circuit_location, circuits.country AS circuit_country,
                races.year,
                r.raceid, r.driverid, r.number, r.grid, r.positionorder, r.points, r.laps, r.milliseconds, r.fastestlap, r.rank, r.fastestlapspeed, r.statusid,
                fastest_pit_stop.stop AS fastest_pit_stop, fastest_pit_stop.milliseconds AS fastest_pit_stop_time
            FROM constructors c
            JOIN constructor_results ON c.constructorId = constructor_results.constructorId
            JOIN races ON constructor_results.raceId = races.raceId
            JOIN circuits ON races.circuitId = circuits.circuitId
            JOIN (
                SELECT raceId, constructorId, MAX(points) AS points
                FROM constructor_standings
                GROUP BY raceId, constructorId
            ) AS cs ON constructor_results.raceId = cs.raceId AND constructor_results.constructorId = cs.constructorId
            JOIN results as r ON constructor_results.raceId = r.raceId AND constructor_results.constructorId = r.constructorId AND r.points > 0
            LEFT JOIN (
                SELECT ps.raceId, ps.driverId, ps.stop, ps.milliseconds
                FROM pit_stops ps
                JOIN drivers d ON ps.driverId = d.driverId
                WHERE (ps.raceId, ps.driverId, ps.milliseconds) IN (
                    SELECT raceId, driverId, MIN(milliseconds)
                    FROM pit_stops
                    GROUP BY raceId, driverId
                )
            ) AS fastest_pit_stop ON constructor_results.raceId = fastest_pit_stop.raceId AND r.driverId = fastest_pit_stop.driverId;
        """
    )

    records = cursor.fetchall()
    records_data = pd.DataFrame(records)

    columns = []
    for column in cursor.description:
        columns.append(column[0])

    records_data.columns = columns

    display(records_data.head())
except (Exception, Error) as e:
    print('Error while executing the query', e)
finally:
    if(connection):
        cursor.close()
        connection.close()
```

# Análisis exploratorio de datos

En esta sección nos sumergiremos en la comprensión de los datos disponibles, exploraremos los tipos de variables presentes, calcularemos medidas de tendencia central, llevaremos a cabo la depuración de los datos y procederemos a su visualización.

Para llevar a cabo este análisis, nos apoyaremos en el marco de trabajo establecido, APP Framework.

1. **Atención**: Entender el conjunto de datos.
2. **Propósito**: Establecer objetivos claros.
3. **Proceso**: Realizar el Análisis Exploratorio de Datos (EDA) propiamente dicho.
4. **Beneficio**: Extraer y aplicar los resultados obtenidos.

## Conociendo los datos

Conocer los datos es un paso fundamental en cualquier análisis. Proporciona una comprensión inicial del problema, permite validar la calidad de los datos, seleccionar características relevantes, preparar los datos adecuadamente y generar ideas y hipótesis. En resumen, la exploración inicial de los datos sienta las bases para un análisis más profundo y asegura que los resultados sean significativos y confiables.

### Tipos de datos

Para realizar un análisis exploratorio, primero debes conocer el tipo de variables con las que estamos tratando. Conocer si tenemos variables numéricas o categóricas podrían determinar el rumbo del análisis que realizaremos.

``` {python}
records_data.dtypes
```

Observemos que todas las variables tienen el tipo de dato correcto, excepto la columna `fastestlapspeed`, que toma valores numéricos pero está siendo interpretada como un dato tipo `object`. Por lo tanto, es necesario convertir esta columna en tipo numérico. Además, vamos a cambiar los tipos de datos de las variables `raceid`,  `statusid`,`circuitid`, `driverid` y `constructorid` a tipo `object`.

``` {python}
records_data['fastestlapspeed'] = pd.to_numeric(records_data['fastestlapspeed'])
records_data[['raceid', 'driverid', 'constructorid', 'statusid']] = records_data[['raceid', 'driverid', 'constructorid', 'statusid']].astype('object')

records_data.dtypes
``` 

### Dimensiones de los registros

Determinar el tamaño de nuestros registros es fundamental, ya que nos permite comprender la magnitud de la información que estamos manejando. Esto a su vez nos ayuda a establecer posibles caminos a seguir en caso de realizar transformaciones y análisis adicionales.

``` {python}
records_data.shape
```

``` {python}
len(records_data['constructorref'].unique())
```

Esto indica que desde el año 1950 hasta el 2023, en las más de 1000 carreras que se han llevado a cabo, han competido 88 equipos en esta competencia. Además, teniendo más de 7000 registros significa que estamos trabajando con una cantidad considerable de datos sobre equipos constructores.

### Datos faltantes

Determinar la presencia de datos faltantes es crucial, ya que puede indicar si podemos confiar en una columna para el análisis o si necesitamos tomar medidas para imputar esos valores ausentes.

``` {python}
records_data.isnull().sum()
```

Con los resultados obtenidos, observamos que tenemos una cantidad significativa de datos faltantes. Esta situación puede afectar los análisis futuros, dependiendo del tipo de variable que estemos considerando. Es importante determinar un método adecuado para la imputación de datos en caso de que sea necesario. Veamos el porcentaje que representa esta cantidad de datos faltantes en el total de nuestros datos.

``` {python}
missing_values = records_data.isnull().sum()
missing_percentage = round((missing_values / len(records_data)) * 100, 4)
missing_percentage
```

Tenemos un gran porcentaje de datos faltantes en nuestras variables. Sin embargo, estos datos faltantes parecen estar concentrados en las variables relacionadas con medidas de tiempos y velocidades. Esto sugiere que estos datos podrían faltar debido a limitaciones técnicas o falta de registro en las fechas más antiguas, donde la toma de estas medidas podría no haber sido sistemática.

Para comprender mejor la distribución de estos datos faltantes, examinemos en qué fechas están ocurriendo y verifiquemos la fecha máxima y mínima en la que faltan estas observaciones.

``` {python}
records_data[records_data.isnull().any(axis = 1)]
```

``` {python}
#| echo: false
missing = records_data[records_data.isnull().any(axis = 1)]
print('Fecha mínima: ', min(missing['year']))
print('Fecha promedio: ', int(round(missing['year'].mean(), 0)))
print('Fecha máxima: ', max(missing['year']))
```

Observando estos resultados, podemos confirmar nuestra teoría. Estos registros faltantes pueden ser debidos a limitaciones técnicas en aquellos tiempos. Sin embargo, también tenemos datos faltantes recientes.

## Exploración de los datos

En esta sección realizaremos el verdadero análisis exploratorio de nuestros datos. Abordaremos los siguientes aspectos:

1. **Medidas de tendencia central**: Calcularemos medidas como la media, la mediana y la moda para entender mejor la distribución de nuestros datos.

2. **Limpieza de los datos**: Abordaremos la limpieza de nuestros datos, incluyendo la búsqueda de datos atípicos.

3. **Transformación**: Determinaremos si es necesario aplicar alguna transformación a nuestros datos para facilitar los análisis subsiguientes.

4. **Visualización**: Utilizaremos herramientas gráficas para explorar el comportamiento de nuestros datos y extraer patrones o tendencias.

Esta fase nos permitirá comprender mejor la naturaleza de nuestros datos y prepararlos adecuadamente para análisis más avanzados.

### Medidas de tendencia central

``` {python}
records_data.describe()
```

<br>

Estos resultados nos pueden permitir concluir lo siguiente: 

* **Puntos, posición en la parrilla y número de vueltas**: Los datos muestran que el promedio de puntos obtenidos por carrera es de aproximadamente 6.47. La posición promedio en la parrilla de salida es alrededor de 7.14. En cuanto al número de vueltas, el promedio es de aproximadamente 62.39. Estas variabilidades indican que hay una amplia gama de resultados en términos de puntos, posición en la parrilla y número de vueltas, lo que podría atribuirse a diferencias en la dificultad de los circuitos, la calidad de los vehículos y las estrategias de los equipos en cada carrera.

* **Tiempo de carrera y velocidad**: El tiempo medio de carrera es de aproximadamente 5.99 millones de milisegundos (alrededor de 99.83 minutos) millones de milisegundos. Esta variabilidad en los tiempos de carrera puede deberse a la longitud del circuito, las condiciones climáticas y la cantidad de incidentes en la pista. La velocidad media de la vuelta más rápida realizada por el ganador es de alrededor de 206.01 km/h. Estas diferencias en la velocidad pueden ser atribuibles a las características específicas del circuito y la competencia entre los conductores.

* **Paradas en boxes**: El tiempo medio para la parada en boxes más rápida es de aproximadamente 31.73 segundos. Las paradas en boxes indican que hay una variabilidad en los tiempos de pit stop entre las carreras, que puede estar influenciada por factores como la estrategia del equipo y la eficiencia en el box.

### Limpieza de los datos

La limpieza de datos es una etapa crucial en cualquier análisis, por lo que en este apartado trataremos los datos faltantes y observaremos si existen datos atípicos en nuestras variables.

#### Datos faltantes

Existen diversas estrategias para abordar este problema. Usualmente, en este tipo de análisis se recurre a la `imputación` de valores faltantes utilizando la `media`, `moda` o `mediana`, o llenando los datos con los valores `anteriores o siguientes`. Sin embargo, estas técnicas pueden no ser óptimas para conjuntos de datos extensos o con características específicas.

En nuestro caso, una estrategia efectiva sería utilizar la `imputación` de datos faltantes basada en puntos similares en los datos mediante el algoritmo `KNN (K-Nearest Neighbors)` y `Random Forest Classification`. Este método considera las características de observaciones similares para estimar los valores faltantes de manera más precisa y realista, lo que resulta especialmente útil en conjuntos de datos complejos como el nuestro.

Inicialmente, creemos un `DataFrame` temporal donde estarán los mismos datos de `records_data` pero sin las columnas correspondientes a tipo `object`.

``` {python}
temp_df = records_data.select_dtypes(exclude=['object'])

imputer = IterativeImputer(min_value=0, max_iter=30, imputation_order='roman', random_state=1)
imputed_data = imputer.fit_transform(temp_df)

temp_df_imputed = pd.DataFrame(imputed_data, columns=temp_df.columns)
temp_df_imputed.isnull().sum()
```

Bien, ya no tenemos datos faltantes. Ahora, verifiquemos si los resultados obtenidos en las medidas de tendencia central del DataFrame original cambiaron significativamente.

``` {python}
temp_df_imputed.describe()
```

<br>

Comparando los resultados de las medidas de tendencia central antes y después de la imputación de datos con el algoritmo `KNN`, observamos algunas diferencias significativas en ciertas variables:

* **Puntos, posición en la parrilla y número de vueltas**: No se observan cambios significativos en las medidas de tendencia central y dispersión de los puntos obtenidos, la posición en la parrilla de salida y el número de vueltas antes y después de la imputación de datos.

* **Tiempo de carrera y velocidad**: Después de la imputación de datos, se observa un ligero aumento en la media del tiempo de carrera, mientras que la desviación estándar disminuye. Esto sugiere una mayor consistencia en los tiempos de carrera entre las carreras. Por otro lado, no hay cambios significativos en las estadísticas de velocidad de la vuelta más rápida antes y después de la imputación.

* **Paradas en boxes**: Después de la imputación de datos, se observa un aumento en la media del tiempo de la parada más rápida, lo que indica que las paradas en boxes pueden haber sido ligeramente más lentas en promedio después de la imputación. Sin embargo, la desviación estándar disminuye, lo que sugiere una mayor consistencia en los tiempos de parada más rápida entre las carreras.

Ahora que hemos realizado la imputación de datos, pasemos estos datos a nuestro dataframe original. 

``` {python}
records_data[temp_df.columns] = temp_df_imputed
records_data.isnull().sum()
```

#### Datos atípicos

Veamos ahora si existen `datos atípicos` en nuestro registro. En este caso, utilizaremos el `rango intercuartílico (IQR)` para identificar los valores atípicos. Si un valor cae por debajo de `Q1 - 1.5 * IQR` o por encima de `Q3 + 1.5 * IQR`, se considera un valor atípico.

``` {python}
numeric_columns = temp_df.columns

for col in numeric_columns:
    q1 = records_data[col].quantile(0.25)
    q3 = records_data[col].quantile(0.75)

    iqr = q3 - q1
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr
    outliers = records_data[(records_data[col] < lower_bound) | (records_data[col] > upper_bound)]
    n_outliers = len(outliers)
    print(f'#Outliers in {col} are {n_outliers} and represent a {round(n_outliers/len(records_data) * 100, 4)}% of total records')
```

Como podemos observar, respecto a los más de 7000 registros que tiene la tabla, hay una pequeña cantidada de datos significativa de datos atípicos en nuestras variables. Veamos gráficamente qué es lo que está ocurriendo con ellos.

Realizaremos un gráfico de `caja y bigotes` e `histogramas` para ver el comportamiento y la distribución de nuestros datos.

``` {python}
plt.figure(figsize=(9,12))

i = 1
for col in numeric_columns:
    plt.subplot(5,3,i)
    plt.boxplot(records_data[col],whis=1.5)
    plt.title(col)

    i += 1
plt.show()
```

``` {python}
plt.figure(figsize=(8,12))

i = 1
for col in numeric_columns:
    plt.subplot(5, 3, i)
    sns.histplot(records_data[col], kde=True)
    plt.title(col)
    i += 1
plt.tight_layout()
plt.show()
```

<br>

Dada la naturaleza de las variables, en algunos casos como `rank`, `lap`, `grid`, `points`, entre otros que son datos numéricos `discretos` y representan una `categoría` específica, es normal que existan datos atípicos. Por otro lado, para las otras variables en nuestra base de datos, estos datos atípicos no están afectando mucho la distribución de cada una de ellas, por lo tanto, no realizaremos cambios en ellas.

## Visualización

La visualización es uno de los puntos más importantes a la hora de realizar una exploración de los datos. Con ella, no solo podemos encontrar las relaciones que existen entre nuestras variables, sino que también podemos representar gráficamente las informaciones más relevantes de los datos.

Comencemos visualizando los gráficos de `correlación` y `dispersión` entre las variables para comprender mejor sus relaciones y encontrar posibles patrones.

### Gráfico de correlación

``` {python}
corr = records_data[numeric_columns].corr()
mask = np.triu(np.ones_like(corr, dtype=bool))

sns.heatmap(corr, annot=True, cmap='PRGn', square=True, center=0, mask=mask)
```

Como podemos observar, las variables con una alta correlación (`>0.5` o `<-0.5`) son aquellas que están relacionadas entre sí, como `laps`, `fastestlapspeed`, `fastest_lap`, `positionorder`, `year`, `fastest_pip_stop` entre otras. Por lo tanto, esto no debería ser un problema y podemos proseguir con la exploración de los datos.

### Gráfico de dispersión 

``` {python}
plt.figure(figsize=(8, 12))
sns.pairplot(records_data[numeric_columns])
plt.show()
```

<br>

De este gráfico podemos notar que a medida que pasan los años, los equipos han ha evolucionado progresivamente en términos de velocidades y tiempos de carreras obtenidos. La velocidad y duración en boxes han aumentado, lo que indica una mejora en los automóviles y las técnicas de revisión de ellos. Sin embargo, estos cambios en las velocidades y tiempos también se han vuelto más dispersos a lo largo de los años, lo que implica que ha habido una gran diferencia entre los equipos constructores. Además, también podemos observar algunas relaciones proporcionales en nuestras variables, como aquellas relacionadas nuevamente con las velocidades y tiempos.

### Distribución de carreras

``` {python}
constructor_stats = records_data.groupby('name').size().reset_index(name='total_races')
constructor_stats = constructor_stats.sort_values(by='total_races', ascending=False)
constructor_stats = constructor_stats.rename(columns={'name': 'constructor_name'})

top_constructors = constructor_stats.head(5)

plt.figure(figsize=(8, 7))
sns.histplot(constructor_stats['total_races'], kde=False, bins=30, color='skyblue', edgecolor='black')
plt.title('Distribución del Número Total de Carreras por Constructor')
plt.xlabel('Número Total de Carreras')
plt.ylabel('Frecuencia')

text = '\n'.join([f"{i+1}. {row['constructor_name']}: {row['total_races']} carreras" for i, (index, row) in enumerate(top_constructors.iterrows(), start=0)])
plt.text(max(top_constructors['total_races']) * 1.02, plt.ylim()[1] * 0.9, text, ha='right', va='top', fontsize=10)

plt.tight_layout()
plt.show()

```

<br>

Se observa que la mayoría de los constructores han participado en una cantidad menor de carreras, con una concentración significativa cerca del cero. Esto indica que hay muchos equipos que han tenido una presencia breve en el deporte (pocas temporadas). Sin embargo, hay un pequeño grupo de equipos, como Ferrari y McLaren, que resaltan con una participación en un número mucho mayor de carreras, superando los 800 Grandes Premios, lo que subraya su posición como pilares históricos de la Fórmula 1 con una larga tradición de competencia continua.

### Distribución de costructores por nacionalidad

``` {python}
constructor_stats = records_data.groupby('nationality').size().reset_index(name='num_constructors')
constructor_stats = constructor_stats.sort_values(by='num_constructors', ascending=False)
constructor_stats = constructor_stats.rename(columns={'nationality': 'constructor_nationality'})

top_constructors = constructor_stats.head(5)

plt.figure(figsize=(8, 7))
constructor_stats.set_index('constructor_nationality')['num_constructors'].plot(kind='bar')
plt.title('Número de Constructores por Nacionalidad')
plt.xlabel('Nacionalidad')
plt.ylabel('Número de Constructores')
plt.xticks(rotation=45)  
plt.tight_layout() 
plt.show()
```

<br>

El gráfico muestra la distribución de constructores de Fórmula 1 por nacionalidad. La nacionalidad británica domina claramente con la mayor cantidad de constructores, lo cual resalta la influencia y la historia del Reino Unido en el automovilismo de F1. Le siguen con menor frecuencia los constructores americanos e italianos, reflejando también su papel significativo en la F1. 

La presencia de una variedad de otras nacionalidades indica la diversidad internacional de los equipos, aunque con una representación mucho menor comparada con las tres principales. Esta distribución no solo refleja la historia y geografía del deporte sino también las industrias automotrices nacionales y su apoyo al automovilismo.

### Top 5 equipos más ganadores

``` {python}
constructor_stats = records_data[records_data['positionorder'] == 1]
constructor_stats = records_data.groupby('name').size().reset_index(name='total_wins')
constructor_stats = constructor_stats.sort_values(by='total_wins', ascending=False)
constructor_stats = constructor_stats.rename(columns={'name': 'constructor_name'})

top_constructors = constructor_stats.head(5)

plt.figure(figsize=(8, 7))
plt.bar(top_constructors['constructor_name'], top_constructors['total_wins'], color='skyblue')
plt.title('Top 5 Equipos Más Ganadores en F1')
plt.xlabel('Equipo')
plt.ylabel('Número Total de Victorias')
plt.xticks()
plt.show()
```

<br>

El gráfico muestra el top 10 de equipos más ganadores en la historia de la Fórmula 1. Ferrari lidera con una diferencia significativa, destacando su legado como la escudería más exitosa. McLaren le sigue, con Mercedes, Williams y Red Bull completando los cinco primeros lugares. Estos equipos han sido fundamentales en el deporte, no solo por su número de victorias sino también por su influencia en la evolución de la competición.

### Evolución de la velocidad

``` {python}
plt.figure(figsize=(8, 8))
sns.lineplot(x='year', y='fastestlapspeed', data=records_data, label='Velocidad de Vuelta Más Rápida')
plt.title('Evolución de la velocidad a lo largo de los años')
plt.xlabel('Año')
plt.ylabel('Velocidad (km/h)')
plt.legend()
plt.show()
```

<br>

El gráfico presenta la evolución de la velocidad de la vuelta más rápida en la Fórmula 1 a lo largo de los años. Se observan fluctuaciones en la velocidad a lo largo del tiempo, con una tendencia general al aumento. La sombra alrededor de la línea indica la variabilidad en la velocidad de la vuelta más rápida cada año, sugiriendo que, aunque hay años con velocidades pico, también existen otros factores que pueden afectar la velocidad, como las regulaciones técnicas, las condiciones meteorológicas o el diseño de los circuitos.

El incremento significativo de la velocidad podría atribuirse a avances tecnológicos en los motores y la aerodinámica, así como a cambios en las regulaciones de la F1 que permiten vehículos más rápidos. Sin embargo, el pico en los años recientes también puede reflejar el desarrollo y perfeccionamiento constante en las estrategias de carrera y la optimización del rendimiento del vehículo.

### Evolución de la velocidad máxima alcanzada por equipo

``` {python}
fig, axes = plt.subplots(3, 2, figsize=(12, 8))

for ax, team in zip(axes.flatten(), top_constructors['constructor_name']):
    team_data = records_data[records_data['name'] == team]
    sns.lineplot(x='year', y='fastestlapspeed', data=team_data, ax=ax)
    ax.set_title(f'Evolución de {team} - Velocidad máxima alcanzada')
    ax.set_xlabel('Año')
    ax.set_ylabel('Velocidad máxima alcanzada (km/h)')

plt.tight_layout()
plt.show()
```

<br>

La **evolución de la velocidad máxima** en la Fórmula 1 a lo largo de los años es un resultado complejo de factores como la tecnología, las regulaciones, el diseño de los circuitos y la competencia entre equipos. Cada equipo tiene su propia trayectoria, y las mejoras constantes o altibajos pueden atribuirse a diversas razones.

### Evolución de las paradas en boxes

``` {python}
records_data['fastest_pit_stop_time_in_seconds'] = records_data['fastest_pit_stop_time'] / 1000

plt.figure(figsize=(8, 8))
sns.lineplot(x='year', y='fastestlapspeed', data=records_data, label='Velocidad de Vuelta Más Rápida')
plt.title('Evolución de la velocidad a lo largo de los años')
plt.xlabel('Año')
plt.ylabel('Velocidad (km/h)')
plt.legend()
plt.show()
```

### Evolución de las paradas en boxes por equipo

``` {python}
fig, axes = plt.subplots(3, 2, figsize=(12, 12))

for ax, team in zip(axes.flatten(), top_constructors['constructor_name']):
    team_data = records_data[records_data['name'] == team]
    sns.lineplot(x='year', y='fastest_pit_stop_time_in_seconds', data=team_data, ax=ax)
    ax.set_title(f'Evolución de {team} - Tiempo Promedio de Parada en Boxes')
    ax.set_xlabel('Año')
    ax.set_ylabel('Tiempo Promedio de Parada en Boxes (segundos)')

plt.tight_layout()
plt.show()
```

<br>

La gráfica muestra cómo ha evolucionado el tiempo promedio de parada en boxes para los mejores equipos de Fórmula 1 a lo largo de los años. Las mejoras tecnológicas, el entrenamiento del personal, las estrategias de carrera y los cambios en el diseño de los autos han influido en estos tiempos. Los equipos más eficientes han logrado reducir sus tiempos de parada, demostrando habilidad y dedicación en las carreras.