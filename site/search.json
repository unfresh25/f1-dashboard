[
  {
    "objectID": "timeseries.html",
    "href": "timeseries.html",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "",
    "text": "Una serie temporal es una realización parcial de un proceso estocástico de parámetro tiempo discreto, donde los elementos de \\(I\\) están ordenados y corresponden a instantes equidistantes del tiempo. Estos procesos estocásticos son colecciones o familias de variables aleatorias \\(\\{X_{t}\\}_{t\\in I}\\) ordenadas según el subíndice \\(t\\) que en general se suele identificar con el tiempo. Llamamos trayectoria del proceso a una realización del proceso estocástico. Si \\(I\\) es discreto, el proceso es en tiempo discreto. Si \\(I\\) es continuo, el proceso es en tiempo continuo. Entre las series de tiempo, existen modelos estadísticos que definen el proceso de cualquier conjunto de hipótesis bien definidas sobre las propeidades estadísticas de dicho proceso estocástico.\nUno de los modelos más utilizados a la hora de realizar pronósticos de series de tiempo es el modelo ARIMA. Estos modelos ARIMA (Autorregresivos Integrados de Media Móvil) aproximan los valores futuros de una serie temporal como una función lineal de observaciones pasadas y términos de ruido blanco. Una serie de tiempo \\(y_t\\) se llama un proceso de media móvil integrada autorregresiva (ARIMA) de órdenes \\(p, d, q\\), denotado ARIMA(\\(p, d, q\\)) si su diferencia \\(d\\) da lugar a un proceso estacionario ARMA(\\(p, q\\)). Por lo tanto, un ARIMA(\\(p, d, q\\)) puede escribirse como\n\\[\n    \\Phi(B)(1 - B)^{d} y_{t} = \\delta + \\Theta(B) \\varepsilon_{t}\n\\]\ndonde\n\\[\n    \\Phi(B) = 1 - \\sum_{i = 1}^{p} \\phi_{i} B^{i} \\quad \\text{y} \\quad \\Theta(B) = 1 - \\sum_{i = 1}^{q} \\theta_{i} B^{i},\n\\]\nson los términos del operador back-shit en los AR(\\(p\\)) y MA(\\(q\\)) definidos como \\(\\Phi(B) y_{t} = \\delta + \\varepsilon_{t}\\) y \\(y_{t} = \\mu + \\Theta(B) \\varepsilon_{t}\\) con \\(\\delta = \\mu - \\phi \\mu\\), donde \\(\\mu\\) es la media y \\(\\varepsilon_{t}\\) el ruido blanco con \\(E(\\varepsilon_t) = 0\\) (Rubio 2024).",
    "crumbs": [
      "Análisis Predictivos",
      "Modelo de Serie de Tiempo"
    ]
  },
  {
    "objectID": "timeseries.html#visualización-de-las-series-de-tiempo",
    "href": "timeseries.html#visualización-de-las-series-de-tiempo",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Visualización de las series de tiempo",
    "text": "Visualización de las series de tiempo\nInicialmente, veamos gráficamente las series de tiempo que tenemos para cada equipo\n\nFerrari\n\nm &lt;- list(\n    l = 0,\n    r = 0,\n    b = 0,\n    t = 80\n)\n\nfrecuencia &lt;- 25  \n\nferrari_ts &lt;- ts(\n    race_ts_data$Ferrari, \n    frequency = frecuencia, \n    start = c(\n        as.integer(\n            format(min(race_ts_data$race_date), \"%Y\")\n        ),\n        as.integer(format(min(race_ts_data$race_date), \"%j\"))\n    )\n)\n\nfig &lt;- ts_plot(\n    ferrari_ts,\n    title = \"Rendimiento de Ferrari desde el 2013-Presente\",\n    Ytitle = \"Porcentajes de puntos ganados\",\n    Xtitle = \"Año\",\n    color = \"#a6051a\"\n)\n\nfig %&gt;%\n    layout(\n        paper_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        plot_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        xaxis = list(gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        yaxis = list(title = \"\", gridcolor = \"#111\", showline = FALSE, showticklabels = F),\n        showlegend = FALSE,\n        font = list(color = \"white\"),\n        margin = m\n    )\n\n\n\n\n\n\n\nRed Bull\n\nredbull_ts &lt;- ts(\n    race_ts_data$`Red Bull`, \n    frequency = frecuencia, \n    start = c(\n        as.integer(\n            format(min(race_ts_data$race_date), \"%Y\")\n        ),\n        as.integer(format(min(race_ts_data$race_date), \"%j\"))\n    )\n)\n\nfig &lt;- ts_plot(\n    redbull_ts,\n    title = \"Rendimiento de Red Bull desde el 2013-Presente\",\n    Ytitle = \"Porcentajes de puntos ganados\",\n    Xtitle = \"Año\",\n    color = \"#223971\"\n)\n\nfig %&gt;%\n    layout(\n        paper_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        plot_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        xaxis = list(gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        yaxis = list(title = \"\", gridcolor = \"#111\", showline = FALSE, showticklabels = F),\n        showlegend = FALSE,\n        font = list(color = \"white\"),\n        margin = m\n    )\n\n\n\n\n\n\n\nMercedes\n\nmercedes_ts &lt;- ts(\n    race_ts_data$Mercedes, \n    frequency = frecuencia, \n    start = c(\n        as.integer(\n            format(min(race_ts_data$race_date), \"%Y\")\n        ),\n        as.integer(format(min(race_ts_data$race_date), \"%j\"))\n    )\n)\n\nfig &lt;- ts_plot(\n    mercedes_ts,\n    title = \"Rendimiento de Mercedes desde el 2013-Presente\",\n    Ytitle = \"Porcentajes de puntos ganados\",\n    Xtitle = \"Año\",\n    color = \"#00a19c\"\n)\n\nfig %&gt;%\n    layout(\n        paper_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        plot_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        xaxis = list(gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        yaxis = list(title = \"\", gridcolor = \"#111\", showline = FALSE, showticklabels = F),\n        showlegend = FALSE,\n        font = list(color = \"white\"),\n        margin = m\n    )\n\n\n\n\n\n\n\nWilliams\n\nwilliams_ts &lt;- ts(\n    race_ts_data$Williams, \n    frequency = frecuencia, \n    start = c(\n        as.integer(\n            format(min(race_ts_data$race_date), \"%Y\")\n        ),\n        as.integer(format(min(race_ts_data$race_date), \"%j\"))\n    )\n)\n\nfig &lt;- ts_plot(\n    williams_ts,\n    title = \"Rendimiento de Williams desde el 2013-Presente\",\n    Ytitle = \"Porcentajes de puntos ganados\",\n    Xtitle = \"Año\",\n    color = \"#00a3e0\"\n)\n\nfig %&gt;%\n    layout(\n        paper_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        plot_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        xaxis = list(gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        yaxis = list(title = \"\", gridcolor = \"#111\", showline = FALSE, showticklabels = F),\n        showlegend = FALSE,\n        font = list(color = \"white\"),\n        margin = m\n    )\n\n\n\n\n\n\n\nMcLaren\n\nmclaren_ts &lt;- ts(\n    race_ts_data$McLaren, \n    frequency = frecuencia, \n    start = c(\n        as.integer(\n            format(min(race_ts_data$race_date), \"%Y\")\n        ),\n        as.integer(format(min(race_ts_data$race_date), \"%j\"))\n    )\n)\n\nfig &lt;- ts_plot(\n    mclaren_ts,\n    title = \"Rendimiento de McLaren desde el 2013-Presente\",\n    Ytitle = \"Porcentajes de puntos ganados\",\n    Xtitle = \"Año\",\n    color = \"#ff8000\"\n)\n\nfig %&gt;%\n    layout(\n        paper_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        plot_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        xaxis = list(gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        yaxis = list(title = \"\", gridcolor = \"#111\", showline = FALSE, showticklabels = F),\n        showlegend = FALSE,\n        font = list(color = \"white\"),\n        margin = m\n    )",
    "crumbs": [
      "Análisis Predictivos",
      "Modelo de Serie de Tiempo"
    ]
  },
  {
    "objectID": "timeseries.html#divisón-de-datos-para-entrenamiento-del-modelo",
    "href": "timeseries.html#divisón-de-datos-para-entrenamiento-del-modelo",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Divisón de datos para entrenamiento del modelo",
    "text": "Divisón de datos para entrenamiento del modelo\nAhora procederemos a definir nuestro conjunto de datos para entrenar el modelo. Donde, como mencionamos anteriormente, tomaremos como horizonte 25 premios.\n\nferrari_split &lt;- ts_split(ferrari_ts, sample.out = 25)\nredbull_split &lt;- ts_split(redbull_ts, sample.out = 25)\nwilliams_split &lt;- ts_split(williams_ts, sample.out = 25)\nmclaren_split &lt;- ts_split(mclaren_ts, sample.out = 25)\nmercedes_split &lt;- ts_split(mercedes_ts, sample.out = 25)\n\nferrari_train &lt;- ferrari_split$train\nferrari_test &lt;- ferrari_split$test\n\nredbull_train &lt;- redbull_split$train\nredbull_test &lt;- redbull_split$test\n\nwilliams_train &lt;- williams_split$train\nwilliams_test &lt;- williams_split$test\n\nmclaren_train &lt;- mclaren_split$train\nmclaren_test &lt;- mclaren_split$test\n\nmercedes_train &lt;- mercedes_split$train\nmercedes_test &lt;- mercedes_split$test",
    "crumbs": [
      "Análisis Predictivos",
      "Modelo de Serie de Tiempo"
    ]
  },
  {
    "objectID": "timeseries.html#criterios-aic-bic-y-hqic",
    "href": "timeseries.html#criterios-aic-bic-y-hqic",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Criterios AIC, BIC y HQIC",
    "text": "Criterios AIC, BIC y HQIC\nLos criterios de información de Akaike (AIC), Bayesiano (BIC) y de Hannan-Quinn (HQIC) utilizan el método de estimación de máxima verosimilitud (log-verosimilitud) de los modelos como medida de ajuste. Estas medidas buscan valores bajos para indicar un mejor ajuste del modelo a los datos, empleando las siguientes fórmulas:\n\\[\n\\begin{align*}\n    \\text{AIC} &= 2k - 2 \\ln(L) \\\\\n    \\text{BIC} &= k \\ln(n) - 2 \\ln(L) \\\\\n    \\text{HQIC} &= 2k \\ln(\\ln(n)) - 2 \\ln(L).\n\\end{align*}\n\\]\ndonde \\(k\\) representa el número de parámetros en el modelo estadístico, \\(L\\) el valor de la función de máxima verosimilitud del modelo estimado, y \\(n\\) el tamaño de la muestra.\nEs importante destacar que, aunque aumentar el número de parámetros puede aumentar el valor de la verosimilitud, esto puede conducir a problemas de sobreajuste en el modelo. Para abordar este problema, los criterios mencionados anteriormente introducen un término de penalización basado en el número de parámetros. El término de penalización es mayor en el BIC que en el AIC para muestras superiores a 7. Por su parte, el HQIC busca equilibrar esta penalización, situándose entre el AIC y el BIC. La elección del criterio a utilizar dependerá del objetivo principal de la investigación.\nEn nuestra investigación, consideraremos el criterio de Akaike para identificar el mejor modelo. Comencemos creando una función que tome un dataframe de entrenamiento y devuelva el mejor conjunto de órdenes \\(p, d, q\\) y \\(P, D, Q\\) asociados al criterio AIC de bondad de ajuste, junto con el valor de AIC del mejor modelo encontrado para cada uno de los equipos.\n\nbest_ARIMA &lt;- function(ts_in, p_n, d_n, q_n) {\n    best_aic &lt;- Inf\n    best_pdq &lt;- NULL\n    best_PDQ &lt;- NULL\n    fit &lt;- NULL\n    for(p in 1:p_n) {\n        for(d in 1:d_n) {\n            for (q in 1:q_n) {\n                for(P in 1:p_n) {\n                    for(D in 1:d_n) {\n                        for (Q in 1:q_n) {\n                            tryCatch({\n                                fit &lt;- arima(\n                                    scale(ts_in), \n                                    order=c(p, d, q), \n                                    seasonal = list(order = c(P, D, Q), period = 25),\n                                    xreg=1:length(ts_in), \n                                    method=\"CSS-ML\"\n                                )\n                                tmp_aic &lt;- AIC(fit)\n                                if (tmp_aic &lt; best_aic) {\n                                    best_aic &lt;- tmp_aic\n                                    best_pdq = c(p, d, q)\n                                    best_PDQ = c(P, D, Q)\n                                }\n                            }, error=function(e){})\n                        }\n                    }\n                }\n            }\n        }\n    }\n    return(list(\"best_aic\" = best_aic, \"best_pdq\" = best_pdq, \"best_PDQ\" = best_PDQ))\n}\n\nProcedemos a obtener los modelos:\n\nif(file.exists(\"models/ferrari_best_arima.rda\")) {\n    ferrari_best_model = readRDS(\"models/ferrari_best_arima.rda\")\n} else {\n    ferrari_best_model = best_ARIMA(ferrari_train, 3, 1, 3)\n    saveRDS(best_model, file = \"models/ferrari_best_arima.rda\")\n}\n\nif(file.exists(\"models/redbull_best_arima.rda\")) {\n    redbull_best_model = readRDS(\"models/redbull_best_arima.rda\")\n} else {\n    redbull_best_model = best_ARIMA(redbull_train, 3, 1, 3)\n    saveRDS(best_model, file = \"models/redbull_best_arima.rda\")\n}\n\nif(file.exists(\"models/williams_best_arima.rda\")) {\n    williams_best_model = readRDS(\"models/williams_best_arima.rda\")\n} else {\n    williams_best_model = best_ARIMA(williams_train, 3, 1, 3)\n    saveRDS(best_model, file = \"models/williams_best_arima.rda\")\n}\n\nif(file.exists(\"models/mclaren_best_arima.rda\")) {\n    mclaren_best_model = readRDS(\"models/mclaren_best_arima.rda\")\n} else {\n    mclaren_best_model = best_ARIMA(mclaren_train, 3, 1, 3)\n    saveRDS(best_model, file = \"models/mclaren_best_arima.rda\")\n}\n\nif(file.exists(\"models/mercedes_best_arima.rda\")) {\n    mercedes_best_model = readRDS(\"models/mercedes_best_arima.rda\")\n} else {\n    mercedes_best_model = best_ARIMA(mercedes_train, 3, 1, 3)\n    saveRDS(best_model, file = \"models/mercedes_best_arima.rda\")\n}\n\n\n\nBest Ferrari model: SARIMA(2,1,3) (1,1,1) | Best AIC: 676.741028823375\nBest Red Bull model: SARIMA(2,1,1) (1,1,2) | Best AIC: 658.138691622105\nBest Mercedes model: SARIMA(2,1,3) (1,1,2) | Best AIC: 534.574235117408\nBest Williams model: SARIMA(3,1,3) (1,1,1) | Best AIC: 535.393333012716\nBest McLaren model: SARIMA(3,1,3) (1,1,1) | Best AIC: 578.999389008676",
    "crumbs": [
      "Análisis Predictivos",
      "Modelo de Serie de Tiempo"
    ]
  },
  {
    "objectID": "timeseries.html#ferrari-1",
    "href": "timeseries.html#ferrari-1",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Ferrari",
    "text": "Ferrari\n\nferrari_fit_model &lt;- fitted_model('models/ferrari_model.rda', ferrari_train, ferrari_best_model$best_pdq, ferrari_best_model$best_PDQ)\ncheckresiduals(ferrari_fit_model)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(2,1,3)(1,1,1)[25]\nQ* = 27.147, df = 42, p-value = 0.9632\n\nModel df: 7.   Total lags used: 49\n\n\n\nForecasting sin rolling\n\nferrari_pred_25 &lt;- forecast(ferrari_fit_model, h = 25)\nferrari_pred_25\n\n        Point Forecast     Lo 80     Hi 80        Lo 95     Hi 95\n2022.72       64.89216 36.114274  93.67005  20.88018134 108.90414\n2022.76       67.48479 38.262048  96.70754  22.79246178 112.17712\n2022.80       53.65407 24.024977  83.28317   8.34028008  98.96787\n2022.84       49.80833 19.818323  79.79834   3.94257104  95.67409\n2022.88       44.74469 14.514650  74.97472  -1.48816453  90.97754\n2022.92       47.83882 17.298642  78.37900   1.13164716  94.54600\n2022.96       49.14583 18.281043  80.01062   1.94221035  96.34945\n2023.00       53.90034 22.678677  85.12201   6.15092535 101.64976\n2023.04       60.23923 28.626499  91.85197  11.89172818 108.58674\n2023.08       57.61234 25.590611  89.63406   8.63933396 106.58534\n2023.12       54.51237 22.090746  86.93399   4.92777573 104.09696\n2023.16       49.60666 16.817809  82.39551  -0.53955978  99.75288\n2023.20       50.68929 17.574455  83.80413   0.04451918 101.33406\n2023.24       39.47190  6.063613  72.88019 -11.62166826  90.56548\n2023.28       50.37498 16.685517  84.06444  -1.14860546 101.89856\n2023.32       53.57825 19.596778  87.55972   1.60807396 105.54843\n2023.36       56.36384 22.062218  90.66547   3.90403566 108.82365\n2023.40       58.63530 23.981531  93.28906   5.63693588 111.63366\n2023.44       66.17163 31.146404 101.19686  12.60516804 119.73810\n2023.48       54.61252 19.220226  90.00481   0.48467719 108.74036\n2023.52       62.75652 27.023972  98.48906   8.10830618 117.40473\n2023.56       44.69876  8.662669  80.73485 -10.41368503  99.81120\n2023.60       41.04906  4.740166  77.35795 -14.48060191  96.57872\n2023.64       55.15901 18.590676  91.72735  -0.76743125 111.08545\n2023.68       43.04838  6.212865  79.88389 -13.28667728  99.38343\n\n\n\nfig &lt;- plot_forecast(\n    ferrari_pred_25,\n    title = \"Pronóstico últimas 25 carreras Ferrari\",\n    Ytitle = \"\",\n    Xtitle = \"Year\",\n    color = \"#a6051a\"\n)\n\nfig %&gt;%\n    layout(\n        paper_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        plot_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        xaxis = list(gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        yaxis = list(title = \"\", gridcolor = \"#111\", showline = FALSE, showticklabels = F),\n        showlegend = FALSE,\n        font = list(color = \"white\"),\n        margin = m\n    )\n\n\n\n\n\n\n\nRolling Forecasting\n\npred_rolling &lt;- function(historico, prueba, modelo) {\n    predicciones &lt;- numeric(length(prueba))\n    \n    for (t in seq_along(prueba)) {\n        modelo_ajustado &lt;- Arima(historico, model=modelo)\n        pronostico &lt;- forecast(modelo_ajustado, h=1)\n        predicciones[t] &lt;- pronostico$mean\n\n        if (predicciones[t]&lt; 0) {\n            predicciones[t] &lt;- 0\n        } else if (predicciones[t] &gt; 100) {\n            predicciones[t] &lt;- 100\n        }\n        historico &lt;- c(historico, prueba[t])\n    }\n\n    return(predicciones)\n}\n\npredicciones_ferrari &lt;- pred_rolling(ferrari_train, ferrari_test, ferrari_fit_model)\n\ndf_entrenamiento &lt;- data.frame(Fecha = time(ferrari_train), Valor = as.numeric(ferrari_train))\ndf_prueba &lt;- data.frame(Fecha = time(ferrari_test), Valor = as.numeric(ferrari_test))\ndf_predicciones &lt;- data.frame(Fecha = time(ferrari_test), Valor = predicciones_ferrari)\n\np_ferrari &lt;- plot_ly() %&gt;%\n    add_lines(data = df_entrenamiento, x = ~Fecha, y = ~Valor, name = \"Entrenamiento\", line = list(color = '#a6051a')) %&gt;%\n    add_lines(data = df_prueba, x = ~Fecha, y = ~Valor, name = \"Prueba\", line = list(color = '#ffeb00')) %&gt;%\n    add_lines(data = df_predicciones, x = ~Fecha, y = ~Valor, name = \"Predicción\", line = list(color = '#fff')) %&gt;%\n    layout(\n        title = paste(\"Predicción ARIMA Rolling -\", 25, \"premios\"),\n        xaxis = list(title = \"Año\", gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        yaxis = list(title = \"\", gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        showlegend = TRUE,\n        paper_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        plot_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        font = list(color = \"white\"),\n        margin = m\n    )\n\np_ferrari",
    "crumbs": [
      "Análisis Predictivos",
      "Modelo de Serie de Tiempo"
    ]
  },
  {
    "objectID": "timeseries.html#red-bull-1",
    "href": "timeseries.html#red-bull-1",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Red Bull",
    "text": "Red Bull\n\nredbull_fit_model &lt;- fitted_model('models/redbull_model.rda', redbull_train, redbull_best_model$best_pdq, redbull_best_model$best_PDQ)\ncheckresiduals(redbull_fit_model)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(2,1,1)(1,1,2)[25]\nQ* = 40.678, df = 43, p-value = 0.5725\n\nModel df: 6.   Total lags used: 49\n\n\n\nForecasting sin rolling\n\nredbull_pred_25 &lt;- forecast(redbull_fit_model, h = 25)\nredbull_pred_25\n\n        Point Forecast    Lo 80     Hi 80    Lo 95    Hi 95\n2022.72       77.23443 46.51130 107.95756 30.24746 124.2214\n2022.76       68.37542 37.19930  99.55153 20.69566 116.0552\n2022.80       66.86079 34.65631  99.06527 17.60829 116.1133\n2022.84       79.30214 46.75327 111.85100 29.52294 129.0813\n2022.88       81.19826 48.42753 113.96899 31.07976 131.3168\n2022.92       81.64702 48.57870 114.71534 31.07339 132.2207\n2022.96       79.87575 46.51245 113.23905 28.85098 130.9005\n2023.00       67.90005 34.25252 101.54758 16.44059 119.3595\n2023.04       78.88032 44.95140 112.80924 26.99051 130.7701\n2023.08       83.06694 48.86008 117.27381 30.75206 135.3818\n2023.12       66.20413 31.72169 100.68657 13.46778 118.9405\n2023.16       67.31245 32.55678 102.06813 14.15823 120.4667\n2023.20       82.90410 47.87735 117.93084 29.33531 136.4729\n2023.24       83.79745 48.50174 119.09317 29.81731 137.7776\n2023.28       68.72183 33.15919 104.28448 14.33346 123.1102\n2023.32       68.55585 32.72826 104.38343 13.76229 123.3494\n2023.36       84.75133 48.66075 120.84190 29.55556 139.9471\n2023.40       71.23061 34.87895 107.58228 15.63554 126.8257\n2023.44       76.90339 40.29250 113.51428 20.91187 132.8949\n2023.48       73.62196 36.75367 110.49026 17.23677 130.0072\n2023.52       82.89631 45.77239 120.02023 26.12018 139.6724\n2023.56       76.83706 39.45925 114.21486 19.67264 134.0015\n2023.60       83.41197 45.78200 121.04195 25.86189 140.9621\n2023.64       85.13179 47.25125 123.01234 27.19850 143.0651\n2023.68       76.65561 38.52614 114.78508 18.34162 134.9696\n\n\n\nfig &lt;- plot_forecast(\n    redbull_pred_25,\n    title = \"Pronóstico últimas 25 carreras Red Bull\",\n    Ytitle = \"\",\n    Xtitle = \"Year\",\n    color = '#223971'\n)\n\nfig %&gt;%\n    layout(\n        paper_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        plot_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        xaxis = list(gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        yaxis = list(title = \"\", gridcolor = \"#111\", showline = FALSE, showticklabels = F),\n        showlegend = FALSE,\n        font = list(color = \"white\"),\n        margin = m\n    )\n\n\n\n\n\n\n\nRolling Forecasting\n\npredicciones_redbull &lt;- pred_rolling(redbull_train, redbull_test, redbull_fit_model)\n\ndf_entrenamiento &lt;- data.frame(Fecha = time(redbull_train), Valor = as.numeric(redbull_train))\ndf_prueba &lt;- data.frame(Fecha = time(redbull_test), Valor = as.numeric(redbull_test))\ndf_predicciones &lt;- data.frame(Fecha = time(redbull_test), Valor = predicciones_redbull)\n\np_redbull &lt;- plot_ly() %&gt;%\n    add_lines(data = df_entrenamiento, x = ~Fecha, y = ~Valor, name = \"Entrenamiento\", line = list(color = '#223971')) %&gt;%\n    add_lines(data = df_prueba, x = ~Fecha, y = ~Valor, name = \"Prueba\", line = list(color = '#cc1e4a')) %&gt;%\n    add_lines(data = df_predicciones, x = ~Fecha, y = ~Valor, name = \"Predicción\", line = list(color = '#ffc906')) %&gt;%\n    layout(\n        title = paste(\"Predicción ARIMA Rolling -\", 25, \"premios\"),\n        xaxis = list(title = \"Año\", gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        yaxis = list(title = \"\", gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        showlegend = TRUE,\n        paper_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        plot_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        font = list(color = \"white\"),\n        margin = m\n    )\n\np_redbull",
    "crumbs": [
      "Análisis Predictivos",
      "Modelo de Serie de Tiempo"
    ]
  },
  {
    "objectID": "timeseries.html#mercedes-1",
    "href": "timeseries.html#mercedes-1",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Mercedes",
    "text": "Mercedes\n\nmercedes_fit_model &lt;- fitted_model('models/mercedes_model.rda', mercedes_train, mercedes_best_model$best_pdq, mercedes_best_model$best_PDQ)\ncheckresiduals(mercedes_fit_model)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(2,1,3)(1,1,2)[25]\nQ* = 59.821, df = 41, p-value = 0.02894\n\nModel df: 8.   Total lags used: 49\n\n\n\nForecasting sin rolling\n\nmercedes_pred_25 &lt;- forecast(mercedes_fit_model, h = 25)\nmercedes_pred_25\n\n        Point Forecast     Lo 80     Hi 80       Lo 95     Hi 95\n2022.72       42.97671 14.040902  71.91252  -1.2767899  87.23021\n2022.76       51.48153 22.437065  80.52599   7.0618545  95.90120\n2022.80       55.52588 25.645174  85.40659   9.8272817 101.22448\n2022.84       54.05646 23.484336  84.62859   7.3004296 100.81250\n2022.88       52.19536 21.575777  82.81495   5.3667470  99.02398\n2022.92       50.31769 19.134560  81.50083   2.6272060  98.00818\n2022.96       60.71599 28.817430  92.61455  11.9313527 109.50063\n2023.00       59.42068 27.300846  91.54051  10.2976339 108.54373\n2023.04       66.59120 34.057730  99.12466  16.8355539 116.34684\n2023.08       37.45663  4.251574  70.66169 -13.3261221  88.23939\n2023.12       57.90353 24.404243  91.40282   6.6707922 109.13627\n2023.16       60.31590 26.479356  94.15245   8.5673714 112.06443\n2023.20       42.19866  7.766517  76.63080 -10.4607568  94.85807\n2023.24       64.08325 29.295798  98.87070  10.8804353 117.28606\n2023.28       53.43908 18.346405  88.53175  -0.2305343 107.10869\n2023.32       52.93462 17.326162  88.54308  -1.5238188 107.39306\n2023.36       29.74798 -6.255628  65.75159 -25.3147884  84.81075\n2023.40       38.06940  1.767040  74.37176 -17.4502697  93.58907\n2023.44       58.17589 21.426057  94.92572   1.9718724 114.37990\n2023.48       46.24906  9.087175  83.41095 -10.5851412 103.08327\n2023.52       40.24723  2.779780  77.71468 -17.0542912  97.54875\n2023.56       65.08028 27.216784 102.94377   7.1730623 122.98749\n2023.60       55.28715 17.013745  93.56055  -3.2469702 113.82126\n2023.64       57.07778 18.487095  95.66846  -1.9415783 116.09713\n2023.68       51.66780 12.715974  90.61962  -7.9038745 111.23947\n\n\n\nfig &lt;- plot_forecast(\n    mercedes_pred_25,\n    title = \"Pronóstico últimas 25 carreras Mercedes\",\n    Ytitle = \"\",\n    Xtitle = \"Year\",\n    color = '#00a19c'\n)\n\nfig %&gt;%\n    layout(\n        paper_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        plot_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        xaxis = list(gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        yaxis = list(title = \"\", gridcolor = \"#111\", showline = FALSE, showticklabels = F),\n        showlegend = FALSE,\n        font = list(color = \"white\"),\n        margin = m\n    )\n\n\n\n\n\n\n\nRolling Forecasting\n\npredicciones_mercedes &lt;- pred_rolling(mercedes_train, mercedes_test, mercedes_fit_model)\n\ndf_entrenamiento &lt;- data.frame(Fecha = time(mercedes_train), Valor = as.numeric(mercedes_train))\ndf_prueba &lt;- data.frame(Fecha = time(mercedes_test), Valor = as.numeric(mercedes_test))\ndf_predicciones &lt;- data.frame(Fecha = time(mercedes_test), Valor = predicciones_mercedes)\n\np_mercedes &lt;- plot_ly() %&gt;%\n    add_lines(data = df_entrenamiento, x = ~Fecha, y = ~Valor, name = \"Entrenamiento\", line = list(color = '#00a19c')) %&gt;%\n    add_lines(data = df_prueba, x = ~Fecha, y = ~Valor, name = \"Prueba\", line = list(color = '#80142b')) %&gt;%\n    add_lines(data = df_predicciones, x = ~Fecha, y = ~Valor, name = \"Predicción\", line = list(color = '#c6c6c6')) %&gt;%\n    layout(\n        title = paste(\"Predicción ARIMA Rolling -\", 25, \"premios\"),\n        xaxis = list(title = \"Año\", gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        yaxis = list(title = \"\", gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        showlegend = TRUE,\n        paper_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        plot_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        font = list(color = \"white\"),\n        margin = m\n    )\n\np_mercedes",
    "crumbs": [
      "Análisis Predictivos",
      "Modelo de Serie de Tiempo"
    ]
  },
  {
    "objectID": "timeseries.html#williams-1",
    "href": "timeseries.html#williams-1",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Williams",
    "text": "Williams\n\nwilliams_fit_model &lt;- fitted_model('models/williams_model.rda', williams_train, williams_best_model$best_pdq, williams_best_model$best_PDQ)\ncheckresiduals(williams_fit_model)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(3,1,3)(1,1,1)[25]\nQ* = 24.201, df = 41, p-value = 0.9829\n\nModel df: 8.   Total lags used: 49\n\n\n\nForecasting sin rolling\n\nwilliams_pred_25 &lt;- forecast(williams_fit_model, h = 25)\nwilliams_pred_25\n\n        Point Forecast      Lo 80    Hi 80     Lo 95    Hi 95\n2022.72    -2.92262198 -16.494597 10.64935 -23.67917 17.83392\n2022.76    -1.66065607 -16.129885 12.80857 -23.78943 20.46812\n2022.80     4.25142274 -11.204597 19.70744 -19.38652 27.88937\n2022.84     0.10730987 -16.041396 16.25602 -24.59000 24.80462\n2022.88    -1.02135177 -17.391565 15.34886 -26.05743 24.01473\n2022.92     0.87879321 -15.812818 17.57040 -24.64882 26.40641\n2022.96     7.39704629  -9.980915 24.77501 -19.18025 33.97434\n2023.00     6.83030797 -11.080986 24.74160 -20.56265 34.22327\n2023.04     2.11998645 -16.037032 20.27701 -25.64878 29.88875\n2023.08     3.85567844 -14.633726 22.34508 -24.42143 32.13278\n2023.12    -0.01034271 -19.077553 19.05687 -29.17112 29.15044\n2023.16     2.86309429 -16.649794 22.37598 -26.97929 32.70548\n2023.20    -0.95690395 -20.721597 18.80779 -31.18439 29.27059\n2023.24     5.58340684 -14.515580 25.68239 -25.15534 36.32215\n2023.28     4.62993092 -15.967528 25.22739 -26.87116 36.13103\n2023.32     4.70479399 -16.280505 25.69009 -27.38945 36.79904\n2023.36     4.49578553 -16.745647 25.73722 -27.99018 36.98175\n2023.40     1.96002664 -19.611209 23.53126 -31.03033 34.95038\n2023.44     5.27471400 -16.735345 27.28477 -28.38677 38.93619\n2023.48     1.67422779 -20.683945 24.03240 -32.51965 35.86810\n2023.52     1.09712036 -21.519391 23.71363 -33.49185 35.68609\n2023.56     5.16411475 -17.773734 28.10196 -29.91630 40.24453\n2023.60     8.07904394 -15.251975 31.41006 -27.60267 43.76076\n2023.64     0.99622808 -22.654654 24.64711 -35.17467 37.16713\n2023.68     0.91093394 -22.998385 24.82025 -35.65521 37.47708\n\n\n\nfig &lt;- plot_forecast(\n    williams_pred_25,\n    title = \"Pronóstico últimas 25 carreras Williams\",\n    Ytitle = \"\",\n    Xtitle = \"Year\",\n    color = '#00a3e0'\n)\n\nfig %&gt;%\n    layout(\n        paper_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        plot_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        xaxis = list(gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        yaxis = list(title = \"\", gridcolor = \"#111\", showline = FALSE, showticklabels = F),\n        showlegend = FALSE,\n        font = list(color = \"white\"),\n        margin = m\n    )\n\n\n\n\n\n\n\nRolling Forecasting\n\npredicciones_williams &lt;- pred_rolling(williams_train, williams_test, williams_fit_model)\n\ndf_entrenamiento &lt;- data.frame(Fecha = time(williams_train), Valor = as.numeric(williams_train))\ndf_prueba &lt;- data.frame(Fecha = time(williams_test), Valor = as.numeric(williams_test))\ndf_predicciones &lt;- data.frame(Fecha = time(williams_test), Valor = predicciones_williams)\n\np_williams &lt;- plot_ly() %&gt;%\n    add_lines(data = df_entrenamiento, x = ~Fecha, y = ~Valor, name = \"Entrenamiento\", line = list(color = '#00a3e0')) %&gt;%\n    add_lines(data = df_prueba, x = ~Fecha, y = ~Valor, name = \"Prueba\", line = list(color = '#e40046')) %&gt;%\n    add_lines(data = df_predicciones, x = ~Fecha, y = ~Valor, name = \"Predicción\", line = list(color = '#041e42')) %&gt;%\n    layout(\n        title = paste(\"Predicción ARIMA Rolling -\", 25, \"premios\"),\n        xaxis = list(title = \"Año\", gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        yaxis = list(title = \"\", gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        showlegend = TRUE,\n        paper_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        plot_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        font = list(color = \"white\"),\n        margin = m\n    )\n\np_williams",
    "crumbs": [
      "Análisis Predictivos",
      "Modelo de Serie de Tiempo"
    ]
  },
  {
    "objectID": "timeseries.html#mclaren-1",
    "href": "timeseries.html#mclaren-1",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "McLaren",
    "text": "McLaren\n\nmclaren_fit_model &lt;- fitted_model('models/mclaren_model.rda', mclaren_train, mclaren_best_model$best_pdq, mclaren_best_model$best_PDQ)\ncheckresiduals(mclaren_fit_model)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(3,1,3)(1,1,1)[25]\nQ* = 50.772, df = 41, p-value = 0.141\n\nModel df: 8.   Total lags used: 49\n\n\n\nForecasting sin rolling\n\nmclaren_pred_25 &lt;- forecast(mclaren_fit_model, h = 25)\nmclaren_pred_25\n\n        Point Forecast       Lo 80    Hi 80      Lo 95    Hi 95\n2022.72       27.29786   3.6223290 50.97340  -8.910742 63.50647\n2022.76       23.64509  -0.6467697 47.93695 -13.506104 60.79628\n2022.80       33.12711   8.5853564 57.66886  -4.406261 70.66047\n2022.84       32.54800   7.9552240 57.14077  -5.063403 70.15940\n2022.88       21.12748  -3.9615711 46.21653 -17.242912 59.49787\n2022.92       22.41200  -2.6930942 47.51710 -15.982931 60.80694\n2022.96       13.70429 -11.8348902 39.24348 -25.354518 52.76311\n2023.00       34.16183   8.5404978 59.78317  -5.022618 73.34629\n2023.04       26.75649   0.9551518 52.55784 -12.703254 66.21624\n2023.08       22.37703  -3.6981238 48.45218 -17.501475 62.25553\n2023.12       30.29711   4.1688176 56.42540  -9.662663 70.25688\n2023.16       20.30576  -6.2131738 46.82468 -20.251447 60.86296\n2023.20       18.70793  -7.8608388 45.27670 -21.925496 59.34136\n2023.24       17.45056  -9.4028716 44.30400 -23.618222 58.51935\n2023.28       18.26857  -8.7222396 45.25938 -23.010310 59.54745\n2023.32       20.43566  -6.6844274 47.55574 -21.040934 61.91225\n2023.36       17.93969  -9.4508444 45.33022 -23.950515 59.82989\n2023.40       21.03588  -6.4211569 48.49291 -20.956032 63.02778\n2023.44       24.78511  -2.9707030 52.54093 -17.663745 67.23397\n2023.48       21.18122  -6.6615364 49.02399 -21.400604 63.76305\n2023.52       24.27119  -3.7749784 52.31736 -18.621725 67.16411\n2023.56       14.47817 -13.7378950 42.69424 -28.674578 57.63092\n2023.60       20.32873  -7.9982275 48.65569 -22.993613 63.65107\n2023.64       17.61866 -10.9545177 46.19184 -26.080245 61.31757\n2023.68       18.00467 -10.6529797 46.66233 -25.823424 61.83277\n\n\n\nfig &lt;- plot_forecast(\n    mclaren_pred_25,\n    title = \"Pronóstico últimas 25 carreras McLaren\",\n    Ytitle = \"\",\n    Xtitle = \"Year\",\n    color = '#ff8000'\n)\n\nfig %&gt;%\n    layout(\n        paper_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        plot_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        xaxis = list(gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        yaxis = list(title = \"\", gridcolor = \"#111\", showline = FALSE, showticklabels = F),\n        showlegend = FALSE,\n        font = list(color = \"white\"),\n        margin = m\n    )\n\n\n\n\n\n\n\nRolling Forecasting\n\npredicciones_mclaren &lt;- pred_rolling(mclaren_train, mclaren_test, mclaren_fit_model)\n\ndf_entrenamiento &lt;- data.frame(Fecha = time(mclaren_train), Valor = as.numeric(mclaren_train))\ndf_prueba &lt;- data.frame(Fecha = time(mclaren_test), Valor = as.numeric(mclaren_test))\ndf_predicciones &lt;- data.frame(Fecha = time(mclaren_test), Valor = predicciones_mclaren)\n\np_mclaren &lt;- plot_ly() %&gt;%\n    add_lines(data = df_entrenamiento, x = ~Fecha, y = ~Valor, name = \"Entrenamiento\", line = list(color = '#ff8000')) %&gt;%\n    add_lines(data = df_prueba, x = ~Fecha, y = ~Valor, name = \"Prueba\", line = list(color = '#47c7fc')) %&gt;%\n    add_lines(data = df_predicciones, x = ~Fecha, y = ~Valor, name = \"Predicción\", line = list(color = '#fff')) %&gt;%\n    layout(\n        title = paste(\"Predicción ARIMA Rolling -\", 25, \"premios\"),\n        xaxis = list(title = \"Año\", gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        yaxis = list(title = \"\", gridcolor = \"#111\", showline = FALSE, color = 'white'),\n        showlegend = TRUE,\n        paper_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        plot_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n        font = list(color = \"white\"),\n        margin = m\n    )\n\np_mclaren",
    "crumbs": [
      "Análisis Predictivos",
      "Modelo de Serie de Tiempo"
    ]
  },
  {
    "objectID": "timeseries.html#correlación-observación-real-v.s.-predicha",
    "href": "timeseries.html#correlación-observación-real-v.s.-predicha",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Correlación observación real v.s. predicha",
    "text": "Correlación observación real v.s. predicha\n\ncreate_correlation_plot &lt;- function(actual, predicted, title, color1, color2) {\n    data &lt;- data.frame(Actual = actual, Predicted = predicted)\n    p &lt;- ggplot(data, aes(x = Actual, y = Predicted)) +\n        geom_point(color = color1, alpha = 0.5) +\n        geom_smooth(method = \"lm\", se = FALSE, color = color2) +\n        xlab(\"Valores Reales\") +\n        ylab(\"Valores Predichos\") +\n        ggtitle(title) + \n        theme_minimal()\n\n    fig &lt;- ggplotly(p)\n\n    fig %&gt;%\n        layout(\n            xaxis = list(gridcolor = \"#111\", showline = FALSE, color = 'white', tickfont = list(color = \"white\")),\n            yaxis = list(gridcolor = \"#111\", showline = FALSE, color = 'white', tickfont = list(color = \"white\")),\n            showlegend = TRUE,\n            paper_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n            plot_bgcolor = \"rgba(0, 0, 0, 0.0)\",\n            font = list(color = \"white\"),\n            margin = m\n        )\n}\n\n\nFerrari\n\nplot_rolling &lt;- create_correlation_plot(ferrari_test, predicciones_ferrari, \"Correlación Rolling Forecast - Ferrari\", \"#ffeb00\", \"#a6051a\")\nplot_forecast &lt;- create_correlation_plot(ferrari_test, ferrari_pred_25$mean, \"Correlación Direct Forecast - Ferrari\", \"#ffeb00\", \"#a6051a\")\n\nsubplot &lt;- subplot(plot_rolling, plot_forecast, nrows = 2, shareX = TRUE) %&gt;%\n    layout(\n        hovermode = \"x unified\"\n    )\n\nannotations = list( \n  list( \n    x = 0.5,  \n    y = 1.0,  \n    text = \"Correlación Rolling Forecast - Ferrari\",  \n    xref = \"paper\",  \n    yref = \"paper\",  \n    xanchor = \"center\",  \n    yanchor = \"bottom\",  \n    showarrow = FALSE \n  ),  \n  list( \n    x = 0.5,  \n    y = 0.45,  \n    text = \"Correlación Direct Forecast - Ferrari\",  \n    xref = \"paper\",  \n    yref = \"paper\",  \n    xanchor = \"center\",  \n    yanchor = \"bottom\",  \n    showarrow = FALSE \n  )\n)\n\nsubplot &lt;- subplot %&gt;%layout(annotations = annotations) \nsubplot\n\n\n\n\n\n\n\nRed Bull\n\nplot_rolling &lt;- create_correlation_plot(redbull_test, predicciones_redbull, \"Correlación Rolling Forecast - Red Bull\", \"#cc1e4a\", \"#223971\")\nplot_forecast &lt;- create_correlation_plot(redbull_test, redbull_pred_25$mean, \"Correlación Direct Forecast - Red Bull\", \"#cc1e4a\", \"#223971\")\n\nsubplot &lt;- subplot(plot_rolling, plot_forecast, nrows = 2, shareX = TRUE) %&gt;%\n    layout(\n        hovermode = \"x unified\"\n    )\n    \nannotations = list( \n  list( \n    x = 0.5,  \n    y = 1.0,  \n    text = \"Correlación Rolling Forecast - Red Bull\",  \n    xref = \"paper\",  \n    yref = \"paper\",  \n    xanchor = \"center\",  \n    yanchor = \"bottom\",  \n    showarrow = FALSE \n  ),  \n  list( \n    x = 0.5,  \n    y = 0.45,  \n    text = \"Correlación Direct Forecast - Red Bull\",  \n    xref = \"paper\",  \n    yref = \"paper\",  \n    xanchor = \"center\",  \n    yanchor = \"bottom\",  \n    showarrow = FALSE \n  )\n)\n\nsubplot &lt;- subplot %&gt;%layout(annotations = annotations) \nsubplot\n\n\n\n\n\n\n\nMercedes\n\nplot_rolling &lt;- create_correlation_plot(mercedes_test, predicciones_mercedes, \"Correlación Rolling Forecast - Mercedes\", \"#80142b\", \"#00a19c\")\nplot_forecast &lt;- create_correlation_plot(mercedes_test, mercedes_pred_25$mean, \"Correlación Direct Forecast - Mercedes\", \"#80142b\", \"#00a19c\")\n\nsubplot &lt;- subplot(plot_rolling, plot_forecast, nrows = 2, shareX = TRUE) %&gt;%\n    layout(\n        hovermode = \"x unified\"\n    )\n    \nannotations = list( \n  list( \n    x = 0.5,  \n    y = 1.0,  \n    text = \"Correlación Rolling Forecast - Mercedes\",  \n    xref = \"paper\",  \n    yref = \"paper\",  \n    xanchor = \"center\",  \n    yanchor = \"bottom\",  \n    showarrow = FALSE \n  ),  \n  list( \n    x = 0.5,  \n    y = 0.45,  \n    text = \"Correlación Direct Forecast - Mercedes\",  \n    xref = \"paper\",  \n    yref = \"paper\",  \n    xanchor = \"center\",  \n    yanchor = \"bottom\",  \n    showarrow = FALSE \n  )\n)\n\nsubplot &lt;- subplot %&gt;%layout(annotations = annotations) \nsubplot\n\n\n\n\n\n\n\nWilliams\n\nplot_rolling &lt;- create_correlation_plot(williams_test, predicciones_williams, \"Correlación Rolling Forecast - Williams\", \"#e40046\", \"#00a3e0\")\nplot_forecast &lt;- create_correlation_plot(williams_test, williams_pred_25$mean, \"Correlación Direct Forecast - Williams\", \"#e40046\", \"#00a3e0\")\n\nsubplot &lt;- subplot(plot_rolling, plot_forecast, nrows = 2, shareX = TRUE) %&gt;%\n    layout(\n        hovermode = \"x unified\"\n    )\n    \nannotations = list( \n  list( \n    x = 0.5,  \n    y = 1.0,  \n    text = \"Correlación Rolling Forecast - Williams\",  \n    xref = \"paper\",  \n    yref = \"paper\",  \n    xanchor = \"center\",  \n    yanchor = \"bottom\",  \n    showarrow = FALSE \n  ),  \n  list( \n    x = 0.5,  \n    y = 0.45,  \n    text = \"Correlación Direct Forecast - Williams\",  \n    xref = \"paper\",  \n    yref = \"paper\",  \n    xanchor = \"center\",  \n    yanchor = \"bottom\",  \n    showarrow = FALSE \n  )\n)\n\nsubplot &lt;- subplot %&gt;%layout(annotations = annotations) \nsubplot\n\n\n\n\n\n\n\nMcLaren\n\nplot_rolling &lt;- create_correlation_plot(mclaren_test, predicciones_mclaren, \"Correlación Rolling Forecast - McLaren\", \"#47c7fc\", \"#ff8000\")\nplot_forecast &lt;- create_correlation_plot(mclaren_test, mclaren_pred_25$mean, \"Correlación Direct Forecast - McLaren\", \"#47c7fc\", \"#ff8000\")\n\nsubplot &lt;- subplot(plot_rolling, plot_forecast, nrows = 2, shareX = TRUE) %&gt;%\n    layout(\n        hovermode = \"x unified\"\n    )\n    \nannotations = list( \n  list( \n    x = 0.5,  \n    y = 1.0,  \n    text = \"Correlación Rolling Forecast - McLaren\",  \n    xref = \"paper\",  \n    yref = \"paper\",  \n    xanchor = \"center\",  \n    yanchor = \"bottom\",  \n    showarrow = FALSE \n  ),  \n  list( \n    x = 0.5,  \n    y = 0.45,  \n    text = \"Correlación Direct Forecast - McLaren\",  \n    xref = \"paper\",  \n    yref = \"paper\",  \n    xanchor = \"center\",  \n    yanchor = \"bottom\",  \n    showarrow = FALSE \n  )\n)\n\nsubplot &lt;- subplot %&gt;%layout(annotations = annotations) \nsubplot",
    "crumbs": [
      "Análisis Predictivos",
      "Modelo de Serie de Tiempo"
    ]
  },
  {
    "objectID": "pca.html",
    "href": "pca.html",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "",
    "text": "Definición\nEl Análisis de Componentes Principales (PCA) es una técnica que permite resumir y simplificar conjuntos de datos complejos y multidimensionales. Consolida variables que están correlacionadas entre sí en nuevas variables, combinando linealmente las originales de manera que se conserve la mayor cantidad posible de información observada.\nMediante PCA, es posible extraer la esencia de la información contenida en los datos al agrupar múltiples variables que describen a los individuos. Además de su capacidad para resumir datos, PCA también se utiliza como herramienta visual para comprender las estructuras de los datos. Logra esto al reducir la dimensionalidad de los datos, proyectándolos en un espacio de menor dimensión, como una línea, un plano o un espacio tridimensional. Esta reducción de dimensión facilita la interpretación y el análisis de conjuntos de datos complejos (Rubio 2022).\nEn el Análisis de Componentes Principales (PCA), seguimos una secuencia de ejes de proyección con un propósito específico. Primero, identificamos el eje de proyección que maximiza la varianza global. Este eje se conoce como el primer componente principal. Su objetivo es capturar la mayor cantidad posible de variabilidad presente en los datos.\nLuego, buscamos el segundo eje de proyección que maximiza la varianza, pero bajo la restricción de ser ortogonal al primer componente principal. Este segundo componente principal ayuda a capturar la variabilidad restante que no fue explicada por el primer componente. La ortogonalidad entre las componentes principales garantiza que cada una capture diferentes aspectos de la variabilidad de los datos. Esta representación óptima facilita la interpretación y el análisis de los datos al proporcionar una visión clara de las relaciones entre las variables originales.\n\n\nPlanteamiento del problema\nEl análisis de componentes principales (PCA) y la técnica de clustering se utilizarán para clasificar y agrupar los distintos equipos (constructores) que han participado en la Fórmula 1 desde su inicio en 1950 hasta el año 2023. Este análisis se basará en una variedad de características relacionadas con el desempeño de los equipos en las carreras de F1. Las características incluirán la cantidad de puntos promedio obtenidos, la posición inicial en parrilla promedio, la posición final promedio, el número de vueltas promedio, la velocidad más alta promedio conseguida en la vuelta más rápida, el promedio de victorias, las paradas en pits promedio y el promedio de abandonos (no finalizaron la carrera).\nVariables utilizadas * Cantidad de Puntos Promedio (avg_points): Representa la cantidad media de puntos obtenidos por el equipo en una temporada. * Posición Inicial en Parrilla Promedio (avg_grid): La posición media en la que el equipo comenzó las carreras en una temporada. * Posición Final Promedio (avg_positionOrder): La posición media en la que el equipo terminó las carreras en una temporada. * Número de Vueltas Promedio (avg_laps): La cantidad media de vueltas completadas por el equipo en una carrera. * Velocidad Más Alta Promedio en la Vuelta Más Rápida (avg_fastestlapspeed): La velocidad media más alta alcanzada por el equipo en la vuelta más rápida durante una carrera. * Promedio de Victorias (avg_wins): El número medio de victorias obtenidas por el equipo en una temporada. * Paradas en Pits Promedio (avg_stop): La cantidad media de paradas en pits realizadas por el equipo en una carrera. * Promedio de Abandonos (avg_retirements): La cantidad media de abandonos experimentados por el equipo en una temporada.\nEl objetivo principal será proporcionar una comprensión más profunda de la evolución y diversidad en el desempeño de los equipos de F1 a lo largo de la historia. Además, busca facilitar análisis comparativos y estratégicos para equipos, aficionados y analistas de la Fórmula 1.\n\n\nObtención de los datos\nSiguiendo el mismo enfoque utilizado en la sección anterior para llevar a cabo los análisis exploratorios, emplearemos una función para establecer la conexión con la base de datos.\nPrimero, importamos las bibliotecas necesarias:\n\nimport pandas as pd\nimport psycopg2 as psy\nfrom psycopg2 import Error\n\nimport plotly.graph_objects as go\nimport plotly.express as px\n\nimport numpy as np\n\nA continuación, creamos la función que facilita las conexiones:\n\ndef connection_db() -&gt; psy.extensions.connection:\n    try:\n        conn = psy.connect(DATABASE_URL)\n        return conn\n    except (Exception, Error) as e:\n        print('Error while connecting to PostgreSQL', e)\n\nEs importante destacar que esta función utiliza una variable de entorno para almacenar los datos de conexión a la base de datos. En este caso, estamos utilizando Neon, que nos permite crear un servidor de bases de datos con PostgreSQL.\nComo mencionamos previamente, las tablas y sus respectivas columnas que utilizaremos para el desarrollo de este modelo son las siguientes:\n\nResults: points (determinará si finalizó la carrera o no), grid (posición inicial), milliseconds (duración de la carrera en milisegundos), fastestlapspeed (velocidad más alta alcanzada en la vuelta más rápida) y constructorid (identificador del equipo).\nRaces: date (fecha en que se celebró la carrera).\nDrivers: dob (fecha de nacimiento del piloto).\nPit_stops: stop (número de paradas en boxes).\n\nLuego, ejecutamos la consulta SQL para obtener los datos relevantes:\n\ntry:\n    connection = connection_db()\n    cursor = connection.cursor()\n\n    cursor.execute(\n        \"\"\"\n            SELECT \n                c.constructorId, c.name,\n                ROUND(AVG(res.points), 4) AS avg_points, ROUND(AVG(res.grid), 4) AS avg_grid, \n                ROUND(AVG(res.positionOrder), 4) AS avg_positionOrder, ROUND(AVG(res.laps), 4) AS avg_laps, \n                ROUND(AVG(res.fastestLapSpeed), 4) AS avg_fastestLapSpeed,\n                ROUND(AVG(CASE WHEN res.positionOrder = 1 THEN 1 ELSE 0 END), 4) AS avg_wins,\n                ROUND(AVG(p.stop), 4) AS avg_stops,\n                ROUND(AVG(CASE WHEN sta.status != 'Finished' THEN 1 ELSE 0 END), 4) AS avg_abandonos\n            FROM Constructors c\n            JOIN Results res ON c.constructorId = res.constructorId\n            LEFT JOIN Pit_Stops p ON res.raceId = p.raceId AND res.driverId = p.driverId\n            LEFT JOIN Status sta ON res.statusId = sta.statusId\n            GROUP BY c.constructorId, c.name;\n        \"\"\"\n    )\n\n    records = cursor.fetchall()\n    constructor_data = pd.DataFrame(records)\n\n    columns = []\n    for column in cursor.description:\n        columns.append(column[0])\n\n    constructor_data.columns = columns\n\n    display(constructor_data)\nexcept (Exception, Error) as e:\n    print('Error while executing the query', e)\nfinally:\n    if(connection):\n        cursor.close()\n        connection.close()\n\n\n\n\n\n\n\n\n\nconstructorid\nname\navg_points\navg_grid\navg_positionorder\navg_laps\navg_fastestlapspeed\navg_wins\navg_stops\navg_abandonos\n\n\n\n\n0\n157\nLangley\n0.0000\n31.0000\n16.0000\n128.0000\n140.3620\n0.0000\n1.0000\n1.0000\n\n\n1\n53\nToleman\n0.1985\n9.9771\n19.7099\n22.0763\n217.7816\n0.0000\n1.0000\n0.9237\n\n\n2\n32\nTeam Lotus\n1.1424\n11.0436\n13.0563\n42.3651\n210.1351\n0.0517\n1.0034\n0.7956\n\n\n3\n7\nToyota\n0.9964\n10.5357\n11.4500\n51.2964\n207.5047\n0.0000\n1.0071\n0.6500\n\n\n4\n100\nENB\n0.0000\n25.0000\n16.0000\n14.0000\n230.0360\n0.0000\n1.0000\n1.0000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n205\n142\nTurner\n0.0000\n23.0000\n21.0000\n146.0000\n123.2220\n0.0000\n1.0000\n1.0000\n\n\n206\n152\nAston Butterworth\n0.0000\n9.0000\n25.2500\n4.7500\n223.6188\n0.0000\n1.0000\n1.0000\n\n\n207\n41\nLeyton House\n0.1250\n13.7188\n17.4531\n33.3438\n212.6000\n0.0000\n1.0000\n0.9531\n\n\n208\n206\nMarussia\n0.0105\n19.8653\n17.6882\n53.5263\n194.6222\n0.0000\n1.7885\n0.8950\n\n\n209\n46\nOnyx\n0.1154\n9.9038\n23.2115\n20.7308\n213.7659\n0.0000\n1.0000\n0.9808\n\n\n\n\n210 rows × 10 columns\n\n\n\n\n Con este procedimiento, hemos obtenido los datos necesarios para nuestro análisis.\n\n\nComponentes principales (PCA)\nConvertiremos los datos a numeric, particularmente para manejar datos de tipo int64, además rellenaremos los datos NA y trataremos con los valores inf\n\nconstructor_data = constructor_data.apply(pd.to_numeric, errors='ignore')\n\nconstructor_data = constructor_data.fillna(0)\nconstructor_data = constructor_data.apply(lambda x: x.replace([float('inf'), float('-inf')], 0) if x.dtype.kind in 'biufc' else x)\n\nAhora, normalizaremos las características para asegurar que todas tengan la misma escala y contribución al análisis.\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nconstructor_data.iloc[:, 2:10] = scaler.fit_transform(constructor_data.iloc[:, 2:10])\n\nRealicemos ahora el análisis de componentes principales\n\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=4)\npca_results = pca.fit_transform(constructor_data.iloc[:, 2:10])\n\n\n\nVarianza explicada por cada componente principal:\n[0.40634954 0.27080934 0.11465565 0.0967851 ]\n\nSuma acumulada de varianza explicada:\n[0.40634954 0.67715888 0.79181454 0.88859964]\n\n\n\n\n\n\n\nReferencias\n\nRubio, Lihki. 2022. «Principal Component Analysis (PCA) Tutorial». 2022. https://lihkir.github.io/MachineLearningUninorte/practical_pca.html.",
    "crumbs": [
      "Análisis Predictivos",
      "Análisis de Componentes Principales (PCA)"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "",
    "text": "Introducción\nLa Fórmula 1, reconocida como la máxima expresión del automovilismo deportivo, constituye un fascinante universo donde convergen la tecnología y la destreza de los pilotos para brindar un espectáculo emocionante en circuitos de todo el mundo (consultar en ABC 2020). Cada temporada de Fórmula 1 se erige como un emocionante periplo repleto de una competencia feroz, innovación tecnológica y cambiantes clasificaciones de pilotos y equipos. Este apasionante deporte atrae no solo a fervientes aficionados del automovilismo, sino también a estadísticos y científicos de datos que buscan desentrañar los secretos detrás de cada carrera.\nEn el epicentro de la Fórmula 1 yace un vasto tesoro de datos que abarca décadas de competiciones, equipos, pilotos y circuitos. Gracias a los avances tecnológicos y a la meticulosa recopilación de datos, los aficionados y expertos en análisis de datos pueden sumergirse en una exploración profunda de este deporte de alto rendimiento (Amo Lledo 2020). En este proyecto, llevaremos a cabo un análisis exploratorio y predictivo de los datos extraídos de Ergast API recopilados por Vopani.\nEn este contexto, nos proponemos realizar un análisis predictivo de los datos de la Fórmula 1 utilizando diversas técnicas y modelos estadísticos. Entre estos modelos se incluyen:\n\nSeries de tiempo: Este enfoque nos permitirá analizar patrones temporales en los datos, como la evolución de rendimiento de un equipo o piloto a lo largo de las temporadas.\nRegresión logística: Utilizaremos este modelo para investigar la relación entre variables predictoras y variables de interés, como por ejemplo, predecir la probabilidad de que un equipo obtenga un determinado resultado en una carrera.\nAnálisis de componentes principales: Con este método, buscaremos reducir la dimensionalidad de nuestros datos y encontrar patrones subyacentes que expliquen la variabilidad en el desempeño de los equipos y pilotos.\nAnálisis discriminante: Este modelo nos ayudará a clasificar datos en función de múltiples variables predictoras, como predecir el rendimiento de un equipo en diferentes tipos de circuitos.\nClasificación mediante KNN (K-Nearest Neighbors): Utilizaremos este algoritmo de aprendizaje supervisado para clasificar nuevos datos en función de la similitud con ejemplos previamente clasificados, como predecir la posición final de un piloto en una carrera dada ciertas condiciones.\n\nAl combinar estos diversos enfoques, buscamos obtener una comprensión más profunda de los factores que influyen en el desempeño en la Fórmula 1 y generar predicciones precisas sobre los resultados de las carreras y los campeonatos futuros.\n\n\n\n\n\nReferencias\n\nABC. 2020. «Historia de la Formula 1». ABC.es. https://www.abc.es/deportes/formula-1/abci-historia-formula-1-202007141357_reportaje.html.\n\n\nAmo Lledo, A. 2020. «Análisis de la eficiencia aplicado a la Fórmula 1», 83. https://idus.us.es/bitstream/handle/11441/101320/TFG-2847-AMO%20LLEDO.pdf.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "constructors.html",
    "href": "constructors.html",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "",
    "text": "En esta sección, llevaremos a cabo un análisis exploratorio centrado en la tabla constructors, que abarca los datos de los equipos que han competido en las carreras disputadas desde 1950 hasta 2023. Sin embargo, para llevar a cabo este análisis de manera integral, necesitamos consolidar información proveniente de diversas fuentes. Utilizaremos consultas para unificar los datos de la tabla constructors con aquellos de las tablas circuits (que contiene información sobre los circuitos donde se celebran las carreras de Fórmula 1), results (que proporciona los resultados de las carreras), pit_stops (paradas realizadas en boxes).\nEs fundamental destacar que, para la tabla results nos enfocaremos exclusivamente en los equipos que obtuvieron puntos en cada carrera. Asimismo, de la tabla pit_stops, extraeremos únicamente la información correspondiente a la parada en boxes más rápida realizada.",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla constructors"
    ]
  },
  {
    "objectID": "constructors.html#tabla-constructors",
    "href": "constructors.html#tabla-constructors",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Tabla constructors",
    "text": "Tabla constructors\n\ntry:\n    connection = connection_db()\n    cursor = connection.cursor()\n\n    cursor.execute(\n        \"\"\"\n            SELECT *\n            FROM constructors\n            LIMIT 5;\n        \"\"\"\n    )\n\n    records = cursor.fetchall()\n    records_data = pd.DataFrame(records)\n\n    columns = []\n    for column in cursor.description:\n        columns.append(column[0])\n\n    records_data.columns = columns\n\n    display(records_data)\nexcept (Exception, Error) as e:\n    print('Error while executing the query', e)\nfinally:\n    if(connection):\n        cursor.close()\n        connection.close()\n\n\n\n\n\n\n\n\n\nconstructorid\nconstructorref\nname\nnationality\nurl\n\n\n\n\n0\n1\nmclaren\nMcLaren\nBritish\nhttp://en.wikipedia.org/wiki/McLaren\n\n\n1\n2\nbmw_sauber\nBMW Sauber\nGerman\nhttp://en.wikipedia.org/wiki/BMW_Sauber\n\n\n2\n3\nwilliams\nWilliams\nBritish\nhttp://en.wikipedia.org/wiki/Williams_Grand_Pr...\n\n\n3\n4\nrenault\nRenault\nFrench\nhttp://en.wikipedia.org/wiki/Renault_in_Formul...\n\n\n4\n5\ntoro_rosso\nToro Rosso\nItalian\nhttp://en.wikipedia.org/wiki/Scuderia_Toro_Rosso",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla constructors"
    ]
  },
  {
    "objectID": "constructors.html#tabla-circuits",
    "href": "constructors.html#tabla-circuits",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Tabla circuits",
    "text": "Tabla circuits\n\ntry:\n    connection = connection_db()\n    cursor = connection.cursor()\n\n    cursor.execute(\n        \"\"\"\n            SELECT *\n            FROM circuits\n            LIMIT 5;\n        \"\"\"\n    )\n\n    records = cursor.fetchall()\n    records_data = pd.DataFrame(records)\n\n    columns = []\n    for column in cursor.description:\n        columns.append(column[0])\n\n    records_data.columns = columns\n\n    display(records_data)\nexcept (Exception, Error) as e:\n    print('Error while executing the query', e)\nfinally:\n    if(connection):\n        cursor.close()\n        connection.close()\n\n\n\n\n\n\n\n\n\ncircuitid\ncircuitref\nname\nlocation\ncountry\nlat\nlng\nalt\nurl\n\n\n\n\n0\n1\nalbert_park\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n-37.8497\n144.968\n10\nhttp://en.wikipedia.org/wiki/Melbourne_Grand_P...\n\n\n1\n2\nsepang\nSepang International Circuit\nKuala Lumpur\nMalaysia\n2.76083\n101.738\n18\nhttp://en.wikipedia.org/wiki/Sepang_Internatio...\n\n\n2\n3\nbahrain\nBahrain International Circuit\nSakhir\nBahrain\n26.0325\n50.5106\n7\nhttp://en.wikipedia.org/wiki/Bahrain_Internati...\n\n\n3\n4\ncatalunya\nCircuit de Barcelona-Catalunya\nMontmeló\nSpain\n41.57\n2.26111\n109\nhttp://en.wikipedia.org/wiki/Circuit_de_Barcel...\n\n\n4\n5\nistanbul\nIstanbul Park\nIstanbul\nTurkey\n40.9517\n29.405\n130\nhttp://en.wikipedia.org/wiki/Istanbul_Park",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla constructors"
    ]
  },
  {
    "objectID": "constructors.html#tabla-results",
    "href": "constructors.html#tabla-results",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Tabla results",
    "text": "Tabla results\n\ntry:\n    connection = connection_db()\n    cursor = connection.cursor()\n\n    cursor.execute(\n        \"\"\"\n            SELECT *\n            FROM results\n            LIMIT 5;\n        \"\"\"\n    )\n\n    records = cursor.fetchall()\n    records_data = pd.DataFrame(records)\n\n    columns = []\n    for column in cursor.description:\n        columns.append(column[0])\n\n    records_data.columns = columns\n\n    display(records_data)\nexcept (Exception, Error) as e:\n    print('Error while executing the query', e)\nfinally:\n    if(connection):\n        cursor.close()\n        connection.close()\n\n\n\n\n\n\n\n\n\nresultid\nraceid\ndriverid\nconstructorid\nnumber\ngrid\nposition\npositiontext\npositionorder\npoints\nlaps\ntime\nmilliseconds\nfastestlap\nrank\nfastestlaptime\nfastestlapspeed\nstatusid\n\n\n\n\n0\n1\n18\n1\n1\n22\n1\n1\n1\n1\n10\n58\n1:34:50.616\n5690616\n39\n2\n1:27.452\n218.300\n1\n\n\n1\n2\n18\n2\n2\n3\n5\n2\n2\n2\n8\n58\n+5.478\n5696094\n41\n3\n1:27.739\n217.586\n1\n\n\n2\n3\n18\n3\n3\n7\n7\n3\n3\n3\n6\n58\n+8.163\n5698779\n41\n5\n1:28.090\n216.719\n1\n\n\n3\n4\n18\n4\n4\n5\n11\n4\n4\n4\n5\n58\n+17.181\n5707797\n58\n7\n1:28.603\n215.464\n1\n\n\n4\n5\n18\n5\n1\n23\n3\n5\n5\n5\n4\n58\n+18.014\n5708630\n43\n1\n1:27.418\n218.385\n1",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla constructors"
    ]
  },
  {
    "objectID": "constructors.html#tabla-pit-stops",
    "href": "constructors.html#tabla-pit-stops",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Tabla pit stops",
    "text": "Tabla pit stops\n\ntry:\n    connection = connection_db()\n    cursor = connection.cursor()\n\n    cursor.execute(\n        \"\"\"\n            SELECT *\n            FROM pit_stops\n            LIMIT 5;\n        \"\"\"\n    )\n\n    records = cursor.fetchall()\n    records_data = pd.DataFrame(records)\n\n    columns = []\n    for column in cursor.description:\n        columns.append(column[0])\n\n    records_data.columns = columns\n\n    display(records_data)\nexcept (Exception, Error) as e:\n    print('Error while executing the query', e)\nfinally:\n    if(connection):\n        cursor.close()\n        connection.close()\n\n\n\n\n\n\n\n\n\nraceid\ndriverid\nstop\nlap\ntime\nduration\nmilliseconds\n\n\n\n\n0\n841\n153\n1\n1\n17:05:23\n26.898\n26898\n\n\n1\n841\n30\n1\n1\n17:05:52\n25.021\n25021\n\n\n2\n841\n17\n1\n11\n17:20:48\n23.426\n23426\n\n\n3\n841\n4\n1\n12\n17:22:34\n23.251\n23251\n\n\n4\n841\n13\n1\n13\n17:24:10\n23.842\n23842",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla constructors"
    ]
  },
  {
    "objectID": "constructors.html#tabla-final",
    "href": "constructors.html#tabla-final",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Tabla final",
    "text": "Tabla final\nCon base en las columnas proporcionadas de cada tabla, podemos listar las que se utilizarán en el análisis de la siguiente manera:\n\nconstructors: constructorId, constructorRef, name, nationality\nCircuits: name, location, country.\nResults: raceId, driverId, points, grid, laps, milliseconds, fastestlap, rank, fastestlapspeed, number, status.\nPit Stops: stop, miliseconds.\n\nRealicemos entonces la consulta a la base de datos para obtener esta tabla.\n\ntry:\n    connection = connection_db()\n    cursor = connection.cursor()\n\n    cursor.execute(\n        \"\"\"\n            SELECT \n                c.constructorid, c.constructorref, c.name, c.nationality,\n                circuits.name AS circuit_name, circuits.location AS circuit_location, circuits.country AS circuit_country,\n                races.year,\n                r.raceid, r.driverid, r.number, r.grid, r.positionorder, r.points, r.laps, r.milliseconds, r.fastestlap, r.rank, r.fastestlapspeed, r.statusid,\n                fastest_pit_stop.stop AS fastest_pit_stop, fastest_pit_stop.milliseconds AS fastest_pit_stop_time\n            FROM constructors c\n            JOIN constructor_results ON c.constructorId = constructor_results.constructorId\n            JOIN races ON constructor_results.raceId = races.raceId\n            JOIN circuits ON races.circuitId = circuits.circuitId\n            JOIN (\n                SELECT raceId, constructorId, MAX(points) AS points\n                FROM constructor_standings\n                GROUP BY raceId, constructorId\n            ) AS cs ON constructor_results.raceId = cs.raceId AND constructor_results.constructorId = cs.constructorId\n            JOIN results as r ON constructor_results.raceId = r.raceId AND constructor_results.constructorId = r.constructorId AND r.points &gt; 0\n            LEFT JOIN (\n                SELECT ps.raceId, ps.driverId, ps.stop, ps.milliseconds\n                FROM pit_stops ps\n                JOIN drivers d ON ps.driverId = d.driverId\n                WHERE (ps.raceId, ps.driverId, ps.milliseconds) IN (\n                    SELECT raceId, driverId, MIN(milliseconds)\n                    FROM pit_stops\n                    GROUP BY raceId, driverId\n                )\n            ) AS fastest_pit_stop ON constructor_results.raceId = fastest_pit_stop.raceId AND r.driverId = fastest_pit_stop.driverId;\n        \"\"\"\n    )\n\n    records = cursor.fetchall()\n    records_data = pd.DataFrame(records)\n\n    columns = []\n    for column in cursor.description:\n        columns.append(column[0])\n\n    records_data.columns = columns\n\n    display(records_data.head())\nexcept (Exception, Error) as e:\n    print('Error while executing the query', e)\nfinally:\n    if(connection):\n        cursor.close()\n        connection.close()\n\n\n\n\n\n\n\n\n\nconstructorid\nconstructorref\nname\nnationality\ncircuit_name\ncircuit_location\ncircuit_country\nyear\nraceid\ndriverid\n...\npositionorder\npoints\nlaps\nmilliseconds\nfastestlap\nrank\nfastestlapspeed\nstatusid\nfastest_pit_stop\nfastest_pit_stop_time\n\n\n\n\n0\n1\nmclaren\nMcLaren\nBritish\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\n18\n1\n...\n1\n10\n58\n5690616.0\n39.0\n2.0\n218.300\n1\nNaN\nNaN\n\n\n1\n2\nbmw_sauber\nBMW Sauber\nGerman\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\n18\n2\n...\n2\n8\n58\n5696094.0\n41.0\n3.0\n217.586\n1\nNaN\nNaN\n\n\n2\n3\nwilliams\nWilliams\nBritish\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\n18\n3\n...\n3\n6\n58\n5698779.0\n41.0\n5.0\n216.719\n1\nNaN\nNaN\n\n\n3\n4\nrenault\nRenault\nFrench\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\n18\n4\n...\n4\n5\n58\n5707797.0\n58.0\n7.0\n215.464\n1\nNaN\nNaN\n\n\n4\n1\nmclaren\nMcLaren\nBritish\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\n18\n5\n...\n5\n4\n58\n5708630.0\n43.0\n1.0\n218.385\n1\nNaN\nNaN\n\n\n\n\n5 rows × 22 columns",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla constructors"
    ]
  },
  {
    "objectID": "constructors.html#conociendo-los-datos",
    "href": "constructors.html#conociendo-los-datos",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Conociendo los datos",
    "text": "Conociendo los datos\nConocer los datos es un paso fundamental en cualquier análisis. Proporciona una comprensión inicial del problema, permite validar la calidad de los datos, seleccionar características relevantes, preparar los datos adecuadamente y generar ideas y hipótesis. En resumen, la exploración inicial de los datos sienta las bases para un análisis más profundo y asegura que los resultados sean significativos y confiables.\n\nTipos de datos\nPara realizar un análisis exploratorio, primero debes conocer el tipo de variables con las que estamos tratando. Conocer si tenemos variables numéricas o categóricas podrían determinar el rumbo del análisis que realizaremos.\n\nrecords_data.dtypes\n\nconstructorid              int64\nconstructorref            object\nname                      object\nnationality               object\ncircuit_name              object\ncircuit_location          object\ncircuit_country           object\nyear                       int64\nraceid                     int64\ndriverid                   int64\nnumber                     int64\ngrid                       int64\npositionorder              int64\npoints                     int64\nlaps                       int64\nmilliseconds             float64\nfastestlap               float64\nrank                     float64\nfastestlapspeed           object\nstatusid                   int64\nfastest_pit_stop         float64\nfastest_pit_stop_time    float64\ndtype: object\n\n\nObservemos que todas las variables tienen el tipo de dato correcto, excepto la columna fastestlapspeed, que toma valores numéricos pero está siendo interpretada como un dato tipo object. Por lo tanto, es necesario convertir esta columna en tipo numérico. Además, vamos a cambiar los tipos de datos de las variables raceid, statusid,circuitid, driverid y constructorid a tipo object.\n\nrecords_data['fastestlapspeed'] = pd.to_numeric(records_data['fastestlapspeed'])\nrecords_data[['raceid', 'driverid', 'constructorid', 'statusid']] = records_data[['raceid', 'driverid', 'constructorid', 'statusid']].astype('object')\n\nrecords_data.dtypes\n\nconstructorid             object\nconstructorref            object\nname                      object\nnationality               object\ncircuit_name              object\ncircuit_location          object\ncircuit_country           object\nyear                       int64\nraceid                    object\ndriverid                  object\nnumber                     int64\ngrid                       int64\npositionorder              int64\npoints                     int64\nlaps                       int64\nmilliseconds             float64\nfastestlap               float64\nrank                     float64\nfastestlapspeed          float64\nstatusid                  object\nfastest_pit_stop         float64\nfastest_pit_stop_time    float64\ndtype: object\n\n\n\n\nDimensiones de los registros\nDeterminar el tamaño de nuestros registros es fundamental, ya que nos permite comprender la magnitud de la información que estamos manejando. Esto a su vez nos ayuda a establecer posibles caminos a seguir en caso de realizar transformaciones y análisis adicionales.\n\nrecords_data.shape\n\n(7441, 22)\n\n\n\nlen(records_data['constructorref'].unique())\n\n88\n\n\nEsto indica que desde el año 1950 hasta el 2023, en las más de 1000 carreras que se han llevado a cabo, han competido 88 equipos en esta competencia. Además, teniendo más de 7000 registros significa que estamos trabajando con una cantidad considerable de datos sobre equipos constructores.\n\n\nDatos faltantes\nDeterminar la presencia de datos faltantes es crucial, ya que puede indicar si podemos confiar en una columna para el análisis o si necesitamos tomar medidas para imputar esos valores ausentes.\n\nrecords_data.isnull().sum()\n\nconstructorid               0\nconstructorref              0\nname                        0\nnationality                 0\ncircuit_name                0\ncircuit_location            0\ncircuit_country             0\nyear                        0\nraceid                      0\ndriverid                    0\nnumber                      0\ngrid                        0\npositionorder               0\npoints                      0\nlaps                        0\nmilliseconds             1546\nfastestlap               3888\nrank                     3877\nfastestlapspeed          3888\nstatusid                    0\nfastest_pit_stop         4932\nfastest_pit_stop_time    4932\ndtype: int64\n\n\nCon los resultados obtenidos, observamos que tenemos una cantidad significativa de datos faltantes. Esta situación puede afectar los análisis futuros, dependiendo del tipo de variable que estemos considerando. Es importante determinar un método adecuado para la imputación de datos en caso de que sea necesario. Veamos el porcentaje que representa esta cantidad de datos faltantes en el total de nuestros datos.\n\nmissing_values = records_data.isnull().sum()\nmissing_percentage = round((missing_values / len(records_data)) * 100, 4)\nmissing_percentage\n\nconstructorid             0.0000\nconstructorref            0.0000\nname                      0.0000\nnationality               0.0000\ncircuit_name              0.0000\ncircuit_location          0.0000\ncircuit_country           0.0000\nyear                      0.0000\nraceid                    0.0000\ndriverid                  0.0000\nnumber                    0.0000\ngrid                      0.0000\npositionorder             0.0000\npoints                    0.0000\nlaps                      0.0000\nmilliseconds             20.7768\nfastestlap               52.2510\nrank                     52.1032\nfastestlapspeed          52.2510\nstatusid                  0.0000\nfastest_pit_stop         66.2814\nfastest_pit_stop_time    66.2814\ndtype: float64\n\n\nTenemos un gran porcentaje de datos faltantes en nuestras variables. Sin embargo, estos datos faltantes parecen estar concentrados en las variables relacionadas con medidas de tiempos y velocidades. Esto sugiere que estos datos podrían faltar debido a limitaciones técnicas o falta de registro en las fechas más antiguas, donde la toma de estas medidas podría no haber sido sistemática.\nPara comprender mejor la distribución de estos datos faltantes, examinemos en qué fechas están ocurriendo y verifiquemos la fecha máxima y mínima en la que faltan estas observaciones.\n\nrecords_data[records_data.isnull().any(axis = 1)]\n\n\n\n\n\n\n\n\n\nconstructorid\nconstructorref\nname\nnationality\ncircuit_name\ncircuit_location\ncircuit_country\nyear\nraceid\ndriverid\n...\npositionorder\npoints\nlaps\nmilliseconds\nfastestlap\nrank\nfastestlapspeed\nstatusid\nfastest_pit_stop\nfastest_pit_stop_time\n\n\n\n\n0\n1\nmclaren\nMcLaren\nBritish\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\n18\n1\n...\n1\n10\n58\n5690616.0\n39.0\n2.0\n218.300\n1\nNaN\nNaN\n\n\n1\n2\nbmw_sauber\nBMW Sauber\nGerman\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\n18\n2\n...\n2\n8\n58\n5696094.0\n41.0\n3.0\n217.586\n1\nNaN\nNaN\n\n\n2\n3\nwilliams\nWilliams\nBritish\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\n18\n3\n...\n3\n6\n58\n5698779.0\n41.0\n5.0\n216.719\n1\nNaN\nNaN\n\n\n3\n4\nrenault\nRenault\nFrench\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\n18\n4\n...\n4\n5\n58\n5707797.0\n58.0\n7.0\n215.464\n1\nNaN\nNaN\n\n\n4\n1\nmclaren\nMcLaren\nBritish\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\n18\n5\n...\n5\n4\n58\n5708630.0\n43.0\n1.0\n218.385\n1\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n7299\n1\nmclaren\nMcLaren\nBritish\nAutódromo Hermanos Rodríguez\nMexico City\nMexico\n2022\n1094\n846\n...\n9\n2\n70\nNaN\n48.0\n17.0\n185.779\n11\n1.0\n22585.0\n\n\n7300\n51\nalfa\nAlfa Romeo\nSwiss\nAutódromo Hermanos Rodríguez\nMexico City\nMexico\n2022\n1094\n822\n...\n10\n1\n70\nNaN\n43.0\n16.0\n185.866\n11\n1.0\n23863.0\n\n\n7379\n1\nmclaren\nMcLaren\nBritish\nCircuit de Monaco\nMonte-Carlo\nMonaco\n2023\n1104\n846\n...\n9\n2\n77\nNaN\n46.0\n19.0\n154.324\n11\n1.0\n24663.0\n\n\n7380\n1\nmclaren\nMcLaren\nBritish\nCircuit de Monaco\nMonte-Carlo\nMonaco\n2023\n1104\n857\n...\n10\n1\n77\nNaN\n47.0\n14.0\n154.983\n11\n1.0\n25851.0\n\n\n7430\n117\naston_martin\nAston Martin\nBritish\nHungaroring\nBudapest\nHungary\n2023\n1109\n840\n...\n10\n1\n69\nNaN\n54.0\n11.0\n189.051\n11\n1.0\n21910.0\n\n\n\n\n5280 rows × 22 columns\n\n\n\n\n\n\nFecha mínima:  1958\nFecha promedio:  1990\nFecha máxima:  2023\n\n\nObservando estos resultados, podemos confirmar nuestra teoría. Estos registros faltantes pueden ser debidos a limitaciones técnicas en aquellos tiempos. Sin embargo, también tenemos datos faltantes recientes.",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla constructors"
    ]
  },
  {
    "objectID": "constructors.html#exploración-de-los-datos",
    "href": "constructors.html#exploración-de-los-datos",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Exploración de los datos",
    "text": "Exploración de los datos\nEn esta sección realizaremos el verdadero análisis exploratorio de nuestros datos. Abordaremos los siguientes aspectos:\n\nMedidas de tendencia central: Calcularemos medidas como la media, la mediana y la moda para entender mejor la distribución de nuestros datos.\nLimpieza de los datos: Abordaremos la limpieza de nuestros datos, incluyendo la búsqueda de datos atípicos.\nTransformación: Determinaremos si es necesario aplicar alguna transformación a nuestros datos para facilitar los análisis subsiguientes.\nVisualización: Utilizaremos herramientas gráficas para explorar el comportamiento de nuestros datos y extraer patrones o tendencias.\n\nEsta fase nos permitirá comprender mejor la naturaleza de nuestros datos y prepararlos adecuadamente para análisis más avanzados.\n\nMedidas de tendencia central\n\nrecords_data.describe()\n\n\n\n\n\n\n\n\n\nyear\nnumber\ngrid\npositionorder\npoints\nlaps\nmilliseconds\nfastestlap\nrank\nfastestlapspeed\nfastest_pit_stop\nfastest_pit_stop_time\n\n\n\n\ncount\n7441.000000\n7441.000000\n7441.000000\n7441.000000\n7441.000000\n7441.000000\n5.895000e+03\n3553.000000\n3564.000000\n3553.000000\n2509.000000\n2.509000e+03\n\n\nmean\n1997.963177\n14.495498\n7.137078\n4.354522\n6.467679\n62.388792\n5.989774e+06\n46.603152\n6.680415\n206.006290\n1.536070\n3.173199e+04\n\n\nstd\n18.309481\n15.192749\n4.989723\n2.463845\n5.667732\n13.737097\n1.089727e+06\n14.355980\n4.232408\n20.582848\n0.761929\n9.771809e+04\n\n\nmin\n1958.000000\n0.000000\n0.000000\n1.000000\n1.000000\n1.000000\n2.070710e+05\n2.000000\n0.000000\n147.980000\n1.000000\n1.317300e+04\n\n\n25%\n1983.000000\n5.000000\n3.000000\n2.000000\n2.000000\n54.000000\n5.388156e+06\n39.000000\n3.000000\n195.557000\n1.000000\n2.147400e+04\n\n\n50%\n2002.000000\n10.000000\n6.000000\n4.000000\n4.000000\n61.000000\n5.771321e+06\n48.000000\n6.000000\n206.603000\n1.000000\n2.287400e+04\n\n\n75%\n2014.000000\n19.000000\n10.000000\n6.000000\n9.000000\n71.000000\n6.295221e+06\n56.000000\n10.000000\n219.005000\n2.000000\n2.463900e+04\n\n\nmax\n2023.000000\n99.000000\n26.000000\n21.000000\n50.000000\n110.000000\n1.472659e+07\n85.000000\n20.000000\n257.320000\n6.000000\n1.517308e+06\n\n\n\n\n\n\n\n\n\nEstos resultados nos pueden permitir concluir lo siguiente:\n\nPuntos, posición en la parrilla y número de vueltas: Los datos muestran que el promedio de puntos obtenidos por carrera es de aproximadamente 6.47. La posición promedio en la parrilla de salida es alrededor de 7.14. En cuanto al número de vueltas, el promedio es de aproximadamente 62.39. Estas variabilidades indican que hay una amplia gama de resultados en términos de puntos, posición en la parrilla y número de vueltas, lo que podría atribuirse a diferencias en la dificultad de los circuitos, la calidad de los vehículos y las estrategias de los equipos en cada carrera.\nTiempo de carrera y velocidad: El tiempo medio de carrera es de aproximadamente 5.99 millones de milisegundos (alrededor de 99.83 minutos) millones de milisegundos. Esta variabilidad en los tiempos de carrera puede deberse a la longitud del circuito, las condiciones climáticas y la cantidad de incidentes en la pista. La velocidad media de la vuelta más rápida realizada por el ganador es de alrededor de 206.01 km/h. Estas diferencias en la velocidad pueden ser atribuibles a las características específicas del circuito y la competencia entre los conductores.\nParadas en boxes: El tiempo medio para la parada en boxes más rápida es de aproximadamente 31.73 segundos. Las paradas en boxes indican que hay una variabilidad en los tiempos de pit stop entre las carreras, que puede estar influenciada por factores como la estrategia del equipo y la eficiencia en el box.\n\n\n\nLimpieza de los datos\nLa limpieza de datos es una etapa crucial en cualquier análisis, por lo que en este apartado trataremos los datos faltantes y observaremos si existen datos atípicos en nuestras variables.\n\nDatos faltantes\nExisten diversas estrategias para abordar este problema. Usualmente, en este tipo de análisis se recurre a la imputación de valores faltantes utilizando la media, moda o mediana, o llenando los datos con los valores anteriores o siguientes. Sin embargo, estas técnicas pueden no ser óptimas para conjuntos de datos extensos o con características específicas.\nEn nuestro caso, una estrategia efectiva sería utilizar la imputación de datos faltantes basada en puntos similares en los datos mediante el algoritmo KNN (K-Nearest Neighbors) y Random Forest Classification. Este método considera las características de observaciones similares para estimar los valores faltantes de manera más precisa y realista, lo que resulta especialmente útil en conjuntos de datos complejos como el nuestro.\nInicialmente, creemos un DataFrame temporal donde estarán los mismos datos de records_data pero sin las columnas correspondientes a tipo object.\n\ntemp_df = records_data.select_dtypes(exclude=['object'])\n\nimputer = IterativeImputer(min_value=0, max_iter=30, imputation_order='roman', random_state=1)\nimputed_data = imputer.fit_transform(temp_df)\n\ntemp_df_imputed = pd.DataFrame(imputed_data, columns=temp_df.columns)\ntemp_df_imputed.isnull().sum()\n\nyear                     0\nnumber                   0\ngrid                     0\npositionorder            0\npoints                   0\nlaps                     0\nmilliseconds             0\nfastestlap               0\nrank                     0\nfastestlapspeed          0\nfastest_pit_stop         0\nfastest_pit_stop_time    0\ndtype: int64\n\n\nBien, ya no tenemos datos faltantes. Ahora, verifiquemos si los resultados obtenidos en las medidas de tendencia central del DataFrame original cambiaron significativamente.\n\ntemp_df_imputed.describe()\n\n\n\n\n\n\n\n\n\nyear\nnumber\ngrid\npositionorder\npoints\nlaps\nmilliseconds\nfastestlap\nrank\nfastestlapspeed\nfastest_pit_stop\nfastest_pit_stop_time\n\n\n\n\ncount\n7441.000000\n7441.000000\n7441.000000\n7441.000000\n7441.000000\n7441.000000\n7.441000e+03\n7441.000000\n7441.000000\n7441.000000\n7441.000000\n7.441000e+03\n\n\nmean\n1997.963177\n14.495498\n7.137078\n4.354522\n6.467679\n62.388792\n6.081225e+06\n37.759931\n5.846977\n196.131523\n2.240600\n3.454560e+04\n\n\nstd\n18.309481\n15.192749\n4.989723\n2.463845\n5.667732\n13.737097\n1.042933e+06\n15.428452\n3.313179\n24.840240\n0.824293\n5.900247e+04\n\n\nmin\n1958.000000\n0.000000\n0.000000\n1.000000\n1.000000\n1.000000\n2.070710e+05\n0.000000\n0.000000\n102.884413\n0.646780\n0.000000e+00\n\n\n25%\n1983.000000\n5.000000\n3.000000\n2.000000\n2.000000\n54.000000\n5.471968e+06\n28.193697\n3.334282\n181.618486\n1.843325\n2.172100e+04\n\n\n50%\n2002.000000\n10.000000\n6.000000\n4.000000\n4.000000\n61.000000\n5.899051e+06\n37.728190\n5.300952\n198.225000\n2.185505\n2.571253e+04\n\n\n75%\n2014.000000\n19.000000\n10.000000\n6.000000\n9.000000\n71.000000\n6.496058e+06\n48.000000\n7.430359\n212.063000\n2.871513\n3.848875e+04\n\n\nmax\n2023.000000\n99.000000\n26.000000\n21.000000\n50.000000\n110.000000\n1.472659e+07\n85.000000\n20.818095\n327.756546\n6.000000\n1.517308e+06\n\n\n\n\n\n\n\n\n\nComparando los resultados de las medidas de tendencia central antes y después de la imputación de datos con el algoritmo KNN, observamos algunas diferencias significativas en ciertas variables:\n\nPuntos, posición en la parrilla y número de vueltas: No se observan cambios significativos en las medidas de tendencia central y dispersión de los puntos obtenidos, la posición en la parrilla de salida y el número de vueltas antes y después de la imputación de datos.\nTiempo de carrera y velocidad: Después de la imputación de datos, se observa un ligero aumento en la media del tiempo de carrera, mientras que la desviación estándar disminuye. Esto sugiere una mayor consistencia en los tiempos de carrera entre las carreras. Por otro lado, no hay cambios significativos en las estadísticas de velocidad de la vuelta más rápida antes y después de la imputación.\nParadas en boxes: Después de la imputación de datos, se observa un aumento en la media del tiempo de la parada más rápida, lo que indica que las paradas en boxes pueden haber sido ligeramente más lentas en promedio después de la imputación. Sin embargo, la desviación estándar disminuye, lo que sugiere una mayor consistencia en los tiempos de parada más rápida entre las carreras.\n\nAhora que hemos realizado la imputación de datos, pasemos estos datos a nuestro dataframe original.\n\nrecords_data[temp_df.columns] = temp_df_imputed\nrecords_data.isnull().sum()\n\nconstructorid            0\nconstructorref           0\nname                     0\nnationality              0\ncircuit_name             0\ncircuit_location         0\ncircuit_country          0\nyear                     0\nraceid                   0\ndriverid                 0\nnumber                   0\ngrid                     0\npositionorder            0\npoints                   0\nlaps                     0\nmilliseconds             0\nfastestlap               0\nrank                     0\nfastestlapspeed          0\nstatusid                 0\nfastest_pit_stop         0\nfastest_pit_stop_time    0\ndtype: int64\n\n\n\n\nDatos atípicos\nVeamos ahora si existen datos atípicos en nuestro registro. En este caso, utilizaremos el rango intercuartílico (IQR) para identificar los valores atípicos. Si un valor cae por debajo de Q1 - 1.5 * IQR o por encima de Q3 + 1.5 * IQR, se considera un valor atípico.\n\nnumeric_columns = temp_df.columns\n\nfor col in numeric_columns:\n    q1 = records_data[col].quantile(0.25)\n    q3 = records_data[col].quantile(0.75)\n\n    iqr = q3 - q1\n    lower_bound = q1 - 1.5 * iqr\n    upper_bound = q3 + 1.5 * iqr\n    outliers = records_data[(records_data[col] &lt; lower_bound) | (records_data[col] &gt; upper_bound)]\n    n_outliers = len(outliers)\n    print(f'#Outliers in {col} are {n_outliers} and represent a {round(n_outliers/len(records_data) * 100, 4)}% of total records')\n\n#Outliers in year are 0 and represent a 0.0% of total records\n#Outliers in number are 503 and represent a 6.7598% of total records\n#Outliers in grid are 94 and represent a 1.2633% of total records\n#Outliers in positionorder are 1 and represent a 0.0134% of total records\n#Outliers in points are 274 and represent a 3.6823% of total records\n#Outliers in laps are 263 and represent a 3.5345% of total records\n#Outliers in milliseconds are 309 and represent a 4.1527% of total records\n#Outliers in fastestlap are 10 and represent a 0.1344% of total records\n#Outliers in rank are 272 and represent a 3.6554% of total records\n#Outliers in fastestlapspeed are 155 and represent a 2.0831% of total records\n#Outliers in fastest_pit_stop are 12 and represent a 0.1613% of total records\n#Outliers in fastest_pit_stop_time are 451 and represent a 6.061% of total records\n\n\nComo podemos observar, respecto a los más de 7000 registros que tiene la tabla, hay una pequeña cantidad significativa de datos atípicos en nuestras variables. Veamos gráficamente qué es lo que está ocurriendo con ellos.\nRealizaremos un gráfico de caja y bigotes e histogramas para ver el comportamiento y la distribución de nuestros datos.\n\nplt.figure(figsize=(9,12))\n\ni = 1\nfor col in numeric_columns:\n    plt.subplot(5,3,i)\n    plt.boxplot(records_data[col],whis=1.5)\n    plt.title(col)\n\n    i += 1\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure(figsize=(8,12))\n\ni = 1\nfor col in numeric_columns:\n    plt.subplot(5, 3, i)\n    sns.histplot(records_data[col], kde=True)\n    plt.title(col)\n    i += 1\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nDada la naturaleza de las variables, en algunos casos como rank, lap, grid, points, entre otros que son datos numéricos discretos y representan una categoría específica, es normal que existan datos atípicos. Por otro lado, para las otras variables en nuestra base de datos, estos datos atípicos no están afectando mucho la distribución de cada una de ellas, por lo tanto, no realizaremos cambios en ellas.",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla constructors"
    ]
  },
  {
    "objectID": "constructors.html#visualización",
    "href": "constructors.html#visualización",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Visualización",
    "text": "Visualización\nLa visualización es uno de los puntos más importantes a la hora de realizar una exploración de los datos. Con ella, no solo podemos encontrar las relaciones que existen entre nuestras variables, sino que también podemos representar gráficamente las informaciones más relevantes de los datos.\nComencemos visualizando los gráficos de correlación y dispersión entre las variables para comprender mejor sus relaciones y encontrar posibles patrones.\n\nGráfico de correlación\n\ncorr = records_data[numeric_columns].corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\nsns.heatmap(corr, annot=True, cmap='PRGn', square=True, center=0, mask=mask)\n\n\n\n\n\n\n\n\nComo podemos observar, las variables con una alta correlación (&gt;0.5 o &lt;-0.5) son aquellas que están relacionadas entre sí, como laps, fastestlapspeed, fastest_lap, positionorder, year, fastest_pip_stop entre otras. Por lo tanto, esto no debería ser un problema y podemos proseguir con la exploración de los datos.\n\n\nGráfico de dispersión\n\nplt.figure(figsize=(8, 12))\nsns.pairplot(records_data[numeric_columns])\nplt.show()\n\n&lt;Figure size 768x1152 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\nDe este gráfico podemos notar que a medida que pasan los años, los equipos han ha evolucionado progresivamente en términos de velocidades y tiempos de carreras obtenidos. La velocidad y duración en boxes han aumentado, lo que indica una mejora en los automóviles y las técnicas de revisión de ellos. Sin embargo, estos cambios en las velocidades y tiempos también se han vuelto más dispersos a lo largo de los años, lo que implica que ha habido una gran diferencia entre los equipos constructores. Además, también podemos observar algunas relaciones proporcionales en nuestras variables, como aquellas relacionadas nuevamente con las velocidades y tiempos.\n\n\nDistribución de carreras\n\nconstructor_stats = records_data.groupby('name').size().reset_index(name='total_races')\nconstructor_stats = constructor_stats.sort_values(by='total_races', ascending=False)\nconstructor_stats = constructor_stats.rename(columns={'name': 'constructor_name'})\n\ntop_constructors = constructor_stats.head(5)\n\nplt.figure(figsize=(8, 7))\nsns.histplot(constructor_stats['total_races'], kde=False, bins=30, color='skyblue', edgecolor='black')\nplt.title('Distribución del número total de carreras por constructor')\nplt.xlabel('Número Total de Carreras')\nplt.ylabel('Frecuencia')\n\ntext = '\\n'.join([f\"{i+1}. {row['constructor_name']}: {row['total_races']} carreras\" for i, (index, row) in enumerate(top_constructors.iterrows(), start=0)])\nplt.text(max(top_constructors['total_races']) * 1.02, plt.ylim()[1] * 0.9, text, ha='right', va='top', fontsize=10)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nSe observa que la mayoría de los constructores han participado en una cantidad menor de carreras, con una concentración significativa cerca del cero. Esto indica que hay muchos equipos que han tenido una presencia breve en el deporte (pocas temporadas). Sin embargo, hay un pequeño grupo de equipos, como Ferrari y McLaren, que resaltan con una participación en un número mucho mayor de carreras, superando los 800 Grandes Premios, lo que subraya su posición como pilares históricos de la Fórmula 1 con una larga tradición de competencia continua.\n\n\nDistribución de costructores por nacionalidad\n\nconstructor_stats = records_data.groupby('nationality').size().reset_index(name='num_constructors')\nconstructor_stats = constructor_stats.sort_values(by='num_constructors', ascending=False)\nconstructor_stats = constructor_stats.rename(columns={'nationality': 'constructor_nationality'})\n\ntop_constructors = constructor_stats.head(5)\n\nplt.figure(figsize=(8, 7))\nconstructor_stats.set_index('constructor_nationality')['num_constructors'].plot(kind='bar')\nplt.title('Número de constructores por nacionalidad')\nplt.xlabel('Nacionalidad')\nplt.ylabel('Número de Constructores')\nplt.xticks(rotation=45)  \nplt.tight_layout() \nplt.show()\n\n\n\n\n\n\n\n\n\nEl gráfico muestra la distribución de constructores de Fórmula 1 por nacionalidad. La nacionalidad británica domina claramente con la mayor cantidad de constructores, lo cual resalta la influencia y la historia del Reino Unido en el automovilismo de F1. Le siguen con menor frecuencia los constructores americanos e italianos, reflejando también su papel significativo en la F1.\nLa presencia de una variedad de otras nacionalidades indica la diversidad internacional de los equipos, aunque con una representación mucho menor comparada con las tres principales. Esta distribución no solo refleja la historia y geografía del deporte sino también las industrias automotrices nacionales y su apoyo al automovilismo.\n\n\nTop 5 equipos más ganadores\n\nconstructor_stats = records_data[records_data['positionorder'] == 1]\nconstructor_stats = records_data.groupby('name').size().reset_index(name='total_wins')\nconstructor_stats = constructor_stats.sort_values(by='total_wins', ascending=False)\nconstructor_stats = constructor_stats.rename(columns={'name': 'constructor_name'})\n\ntop_constructors = constructor_stats.head(5)\n\nplt.figure(figsize=(8, 7))\nplt.bar(top_constructors['constructor_name'], top_constructors['total_wins'], color='skyblue')\nplt.title('Top 5 Equipos más ganadores en F1')\nplt.xlabel('Equipo')\nplt.ylabel('Número Total de Victorias')\nplt.xticks()\nplt.show()\n\n\n\n\n\n\n\n\n\nEl gráfico muestra el top 10 de equipos más ganadores en la historia de la Fórmula 1. Ferrari lidera con una diferencia significativa, destacando su legado como la escudería más exitosa. McLaren le sigue, con Mercedes, Williams y Red Bull completando los cinco primeros lugares. Estos equipos han sido fundamentales en el deporte, no solo por su número de victorias sino también por su influencia en la evolución de la competición.\n\n\nEvolución de la velocidad\n\nplt.figure(figsize=(8, 8))\nsns.lineplot(x='year', y='fastestlapspeed', data=records_data, label='Velocidad de Vuelta Más Rápida')\nplt.title('Evolución de la velocidad a lo largo de los años')\nplt.xlabel('Año')\nplt.ylabel('Velocidad (km/h)')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nEl gráfico presenta la evolución de la velocidad de la vuelta más rápida en la Fórmula 1 a lo largo de los años. Se observan fluctuaciones en la velocidad a lo largo del tiempo, con una tendencia general al aumento. La sombra alrededor de la línea indica la variabilidad en la velocidad de la vuelta más rápida cada año, sugiriendo que, aunque hay años con velocidades pico, también existen otros factores que pueden afectar la velocidad, como las regulaciones técnicas, las condiciones meteorológicas o el diseño de los circuitos.\nEl incremento significativo de la velocidad podría atribuirse a avances tecnológicos en los motores y la aerodinámica, así como a cambios en las regulaciones de la F1 que permiten vehículos más rápidos. Sin embargo, el pico en los años recientes también puede reflejar el desarrollo y perfeccionamiento constante en las estrategias de carrera y la optimización del rendimiento del vehículo.\n\n\nEvolución de la velocidad máxima alcanzada por equipo\n\nfig, axes = plt.subplots(3, 2, figsize=(12, 8))\n\nfor ax, team in zip(axes.flatten(), top_constructors['constructor_name']):\n    team_data = records_data[records_data['name'] == team]\n    sns.lineplot(x='year', y='fastestlapspeed', data=team_data, ax=ax)\n    ax.set_title(f'Evolución de {team} - Velocidad máxima alcanzada')\n    ax.set_xlabel('Año')\n    ax.set_ylabel('Velocidad máxima alcanzada (km/h)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nLa evolución de la velocidad máxima en la Fórmula 1 a lo largo de los años es un resultado complejo de factores como la tecnología, las regulaciones, el diseño de los circuitos y la competencia entre equipos. Cada equipo tiene su propia trayectoria, y las mejoras constantes o altibajos pueden atribuirse a diversas razones.\n\n\nEvolución de las paradas en boxes\n\nrecords_data['fastest_pit_stop_time_in_seconds'] = records_data['fastest_pit_stop_time'] / 1000\n\nplt.figure(figsize=(8, 8))\nsns.lineplot(x='year', y='fastestlapspeed', data=records_data, label='Velocidad de Vuelta Más Rápida')\nplt.title('Evolución de la velocidad a lo largo de los años')\nplt.xlabel('Año')\nplt.ylabel('Velocidad (km/h)')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nEvolución de las paradas en boxes por equipo\n\nfig, axes = plt.subplots(3, 2, figsize=(12, 12))\n\nfor ax, team in zip(axes.flatten(), top_constructors['constructor_name']):\n    team_data = records_data[records_data['name'] == team]\n    sns.lineplot(x='year', y='fastest_pit_stop_time_in_seconds', data=team_data, ax=ax)\n    ax.set_title(f'Evolución de {team} - Tiempo Promedio de Parada en Boxes')\n    ax.set_xlabel('Año')\n    ax.set_ylabel('Tiempo Promedio de Parada en Boxes (segundos)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nLa gráfica muestra cómo ha evolucionado el tiempo promedio de parada en boxes para los mejores equipos de Fórmula 1 a lo largo de los años. Las mejoras tecnológicas, el entrenamiento del personal, las estrategias de carrera y los cambios en el diseño de los autos han influido en estos tiempos. Los equipos más eficientes han logrado reducir sus tiempos de parada, demostrando habilidad y dedicación en las carreras.",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla constructors"
    ]
  },
  {
    "objectID": "drivers.html",
    "href": "drivers.html",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "",
    "text": "En esta sección, llevaremos a cabo un análisis exploratorio centrado en la tabla drivers, que abarca los datos de los equipos que han competido en las carreras disputadas desde 1950 hasta 2023. Sin embargo, para llevar a cabo este análisis de manera integral, necesitamos consolidar información proveniente de diversas fuentes. Utilizaremos consultas para unificar los datos de la tabla drivers con aquellos de las tablas circuits (que contiene información sobre los circuitos donde se celebran las carreras de Fórmula 1), results (que proporciona los resultados de las carreras) y constructors (equipos en los que ha competido).\nEs fundamental destacar que, para la tabla results nos enfocaremos exclusivamente en los pilotos que obtuvieron puntos en cada carrera.",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla drivers"
    ]
  },
  {
    "objectID": "drivers.html#tabla-drivers",
    "href": "drivers.html#tabla-drivers",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Tabla drivers",
    "text": "Tabla drivers\n\ntry:\n    connection = connection_db()\n    cursor = connection.cursor()\n\n    cursor.execute(\n        \"\"\"\n            SELECT *\n            FROM drivers\n            LIMIT 5;\n        \"\"\"\n    )\n\n    records = cursor.fetchall()\n    records_data = pd.DataFrame(records)\n\n    columns = []\n    for column in cursor.description:\n        columns.append(column[0])\n\n    records_data.columns = columns\n\n    display(records_data)\nexcept (Exception, Error) as e:\n    print('Error while executing the query', e)\nfinally:\n    if(connection):\n        cursor.close()\n        connection.close()\n\n\n\n\n\n\n\n\n\ndriverid\ndriverref\nnumber\ncode\nforename\nsurname\ndob\nnationality\nurl\n\n\n\n\n0\n1\nhamilton\n44.0\nHAM\nLewis\nHamilton\n1985-01-07\nBritish\nhttp://en.wikipedia.org/wiki/Lewis_Hamilton\n\n\n1\n2\nheidfeld\nNaN\nHEI\nNick\nHeidfeld\n1977-05-10\nGerman\nhttp://en.wikipedia.org/wiki/Nick_Heidfeld\n\n\n2\n3\nrosberg\n6.0\nROS\nNico\nRosberg\n1985-06-27\nGerman\nhttp://en.wikipedia.org/wiki/Nico_Rosberg\n\n\n3\n4\nalonso\n14.0\nALO\nFernando\nAlonso\n1981-07-29\nSpanish\nhttp://en.wikipedia.org/wiki/Fernando_Alonso\n\n\n4\n5\nkovalainen\nNaN\nKOV\nHeikki\nKovalainen\n1981-10-19\nFinnish\nhttp://en.wikipedia.org/wiki/Heikki_Kovalainen",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla drivers"
    ]
  },
  {
    "objectID": "drivers.html#tabla-constructors",
    "href": "drivers.html#tabla-constructors",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Tabla constructors",
    "text": "Tabla constructors\n\ntry:\n    connection = connection_db()\n    cursor = connection.cursor()\n\n    cursor.execute(\n        \"\"\"\n            SELECT *\n            FROM constructors\n            LIMIT 5;\n        \"\"\"\n    )\n\n    records = cursor.fetchall()\n    records_data = pd.DataFrame(records)\n\n    columns = []\n    for column in cursor.description:\n        columns.append(column[0])\n\n    records_data.columns = columns\n\n    display(records_data)\nexcept (Exception, Error) as e:\n    print('Error while executing the query', e)\nfinally:\n    if(connection):\n        cursor.close()\n        connection.close()\n\n\n\n\n\n\n\n\n\nconstructorid\nconstructorref\nname\nnationality\nurl\n\n\n\n\n0\n1\nmclaren\nMcLaren\nBritish\nhttp://en.wikipedia.org/wiki/McLaren\n\n\n1\n2\nbmw_sauber\nBMW Sauber\nGerman\nhttp://en.wikipedia.org/wiki/BMW_Sauber\n\n\n2\n3\nwilliams\nWilliams\nBritish\nhttp://en.wikipedia.org/wiki/Williams_Grand_Pr...\n\n\n3\n4\nrenault\nRenault\nFrench\nhttp://en.wikipedia.org/wiki/Renault_in_Formul...\n\n\n4\n5\ntoro_rosso\nToro Rosso\nItalian\nhttp://en.wikipedia.org/wiki/Scuderia_Toro_Rosso",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla drivers"
    ]
  },
  {
    "objectID": "drivers.html#tabla-circuits",
    "href": "drivers.html#tabla-circuits",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Tabla circuits",
    "text": "Tabla circuits\n\ntry:\n    connection = connection_db()\n    cursor = connection.cursor()\n\n    cursor.execute(\n        \"\"\"\n            SELECT *\n            FROM circuits\n            LIMIT 5;\n        \"\"\"\n    )\n\n    records = cursor.fetchall()\n    records_data = pd.DataFrame(records)\n\n    columns = []\n    for column in cursor.description:\n        columns.append(column[0])\n\n    records_data.columns = columns\n\n    display(records_data)\nexcept (Exception, Error) as e:\n    print('Error while executing the query', e)\nfinally:\n    if(connection):\n        cursor.close()\n        connection.close()\n\n\n\n\n\n\n\n\n\ncircuitid\ncircuitref\nname\nlocation\ncountry\nlat\nlng\nalt\nurl\n\n\n\n\n0\n1\nalbert_park\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n-37.8497\n144.968\n10\nhttp://en.wikipedia.org/wiki/Melbourne_Grand_P...\n\n\n1\n2\nsepang\nSepang International Circuit\nKuala Lumpur\nMalaysia\n2.76083\n101.738\n18\nhttp://en.wikipedia.org/wiki/Sepang_Internatio...\n\n\n2\n3\nbahrain\nBahrain International Circuit\nSakhir\nBahrain\n26.0325\n50.5106\n7\nhttp://en.wikipedia.org/wiki/Bahrain_Internati...\n\n\n3\n4\ncatalunya\nCircuit de Barcelona-Catalunya\nMontmeló\nSpain\n41.57\n2.26111\n109\nhttp://en.wikipedia.org/wiki/Circuit_de_Barcel...\n\n\n4\n5\nistanbul\nIstanbul Park\nIstanbul\nTurkey\n40.9517\n29.405\n130\nhttp://en.wikipedia.org/wiki/Istanbul_Park",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla drivers"
    ]
  },
  {
    "objectID": "drivers.html#tabla-results",
    "href": "drivers.html#tabla-results",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Tabla results",
    "text": "Tabla results\n\ntry:\n    connection = connection_db()\n    cursor = connection.cursor()\n\n    cursor.execute(\n        \"\"\"\n            SELECT *\n            FROM results\n            LIMIT 5;\n        \"\"\"\n    )\n\n    records = cursor.fetchall()\n    records_data = pd.DataFrame(records)\n\n    columns = []\n    for column in cursor.description:\n        columns.append(column[0])\n\n    records_data.columns = columns\n\n    display(records_data)\nexcept (Exception, Error) as e:\n    print('Error while executing the query', e)\nfinally:\n    if(connection):\n        cursor.close()\n        connection.close()\n\n\n\n\n\n\n\n\n\nresultid\nraceid\ndriverid\nconstructorid\nnumber\ngrid\nposition\npositiontext\npositionorder\npoints\nlaps\ntime\nmilliseconds\nfastestlap\nrank\nfastestlaptime\nfastestlapspeed\nstatusid\n\n\n\n\n0\n1\n18\n1\n1\n22\n1\n1\n1\n1\n10\n58\n1:34:50.616\n5690616\n39\n2\n1:27.452\n218.300\n1\n\n\n1\n2\n18\n2\n2\n3\n5\n2\n2\n2\n8\n58\n+5.478\n5696094\n41\n3\n1:27.739\n217.586\n1\n\n\n2\n3\n18\n3\n3\n7\n7\n3\n3\n3\n6\n58\n+8.163\n5698779\n41\n5\n1:28.090\n216.719\n1\n\n\n3\n4\n18\n4\n4\n5\n11\n4\n4\n4\n5\n58\n+17.181\n5707797\n58\n7\n1:28.603\n215.464\n1\n\n\n4\n5\n18\n5\n1\n23\n3\n5\n5\n5\n4\n58\n+18.014\n5708630\n43\n1\n1:27.418\n218.385\n1",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla drivers"
    ]
  },
  {
    "objectID": "drivers.html#tabla-final",
    "href": "drivers.html#tabla-final",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Tabla final",
    "text": "Tabla final\nCon base en las columnas proporcionadas de cada tabla, podemos listar las que se utilizarán en el análisis de la siguiente manera:\n\nDrivers: driverid, driverref, code, dob, nationality.\nConstructors: constructorId, name.\nCircuits: name, location, country.\nResults: points, grid, laps, milliseconds, fastestlap, rank, fastestlapspeed, number, status.\n\nRealicemos entonces la consulta a la base de datos para obtener esta tabla.\n\ntry:\n    connection = connection_db()\n    cursor = connection.cursor()\n\n    cursor.execute(\n        \"\"\"\n            SELECT \n                d.driverId, d.driverRef, \n                d.dob, d.nationality,\n                circuits.name AS circuit_name, circuits.location AS circuit_location, circuits.country AS circuit_country,\n                races.year, races.name AS race_name, races.round, \n                constructors.constructorId, constructors.name AS team_name,\n                results.number, results.grid, results.positionorder, results.points, results.laps, results.milliseconds,\n                results.fastestlap, results.rank, results.fastestlapspeed, results.statusid\n            FROM \n                drivers d\n            JOIN \n                results ON d.driverId = results.driverId\n            JOIN \n                races ON results.raceId = races.raceId\n            JOIN \n                circuits ON races.circuitId = circuits.circuitId\n            JOIN \n                constructors ON results.constructorId = constructors.constructorId\n            WHERE \n                results.points &gt; 0;\n        \"\"\"\n    )\n\n    records = cursor.fetchall()\n    records_data = pd.DataFrame(records)\n\n    columns = []\n    for column in cursor.description:\n        columns.append(column[0])\n\n    records_data.columns = columns\n\n    display(records_data.head())\nexcept (Exception, Error) as e:\n    print('Error while executing the query', e)\nfinally:\n    if(connection):\n        cursor.close()\n        connection.close()\n\n\n\n\n\n\n\n\n\ndriverid\ndriverref\ndob\nnationality\ncircuit_name\ncircuit_location\ncircuit_country\nyear\nrace_name\nround\n...\nnumber\ngrid\npositionorder\npoints\nlaps\nmilliseconds\nfastestlap\nrank\nfastestlapspeed\nstatusid\n\n\n\n\n0\n1\nhamilton\n1985-01-07\nBritish\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\nAustralian Grand Prix\n1\n...\n22\n1\n1\n10\n58\n5690616.0\n39.0\n2.0\n218.300\n1\n\n\n1\n2\nheidfeld\n1977-05-10\nGerman\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\nAustralian Grand Prix\n1\n...\n3\n5\n2\n8\n58\n5696094.0\n41.0\n3.0\n217.586\n1\n\n\n2\n3\nrosberg\n1985-06-27\nGerman\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\nAustralian Grand Prix\n1\n...\n7\n7\n3\n6\n58\n5698779.0\n41.0\n5.0\n216.719\n1\n\n\n3\n4\nalonso\n1981-07-29\nSpanish\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\nAustralian Grand Prix\n1\n...\n5\n11\n4\n5\n58\n5707797.0\n58.0\n7.0\n215.464\n1\n\n\n4\n5\nkovalainen\n1981-10-19\nFinnish\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\nAustralian Grand Prix\n1\n...\n23\n3\n5\n4\n58\n5708630.0\n43.0\n1.0\n218.385\n1\n\n\n\n\n5 rows × 22 columns",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla drivers"
    ]
  },
  {
    "objectID": "drivers.html#conociendo-los-datos",
    "href": "drivers.html#conociendo-los-datos",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Conociendo los datos",
    "text": "Conociendo los datos\nConocer los datos es un paso fundamental en cualquier análisis. Proporciona una comprensión inicial del problema, permite validar la calidad de los datos, seleccionar características relevantes, preparar los datos adecuadamente y generar ideas y hipótesis. En resumen, la exploración inicial de los datos sienta las bases para un análisis más profundo y asegura que los resultados sean significativos y confiables.\n\nTipos de datos\nPara realizar un análisis exploratorio, primero debes conocer el tipo de variables con las que estamos tratando. Conocer si tenemos variables numéricas o categóricas podrían determinar el rumbo del análisis que realizaremos.\n\nrecords_data.dtypes\n\ndriverid              int64\ndriverref            object\ndob                  object\nnationality          object\ncircuit_name         object\ncircuit_location     object\ncircuit_country      object\nyear                  int64\nrace_name            object\nround                 int64\nconstructorid         int64\nteam_name            object\nnumber                int64\ngrid                  int64\npositionorder         int64\npoints                int64\nlaps                  int64\nmilliseconds        float64\nfastestlap          float64\nrank                float64\nfastestlapspeed      object\nstatusid              int64\ndtype: object\n\n\nObservemos que todas las variables tienen el tipo de dato correcto, excepto la columna fastestlapspeed, que toma valores numéricos pero está siendo interpretada como un dato tipo object. Por lo tanto, es necesario convertir esta columna en tipo numérico. Además, vamos a cambiar los tipos de datos de la variable driverid y constructorid a tipo object.\n\nrecords_data['fastestlapspeed'] = pd.to_numeric(records_data['fastestlapspeed'])\nrecords_data[['driverid', 'constructorid']] = records_data[['driverid', 'constructorid']].astype('object')\n\nrecords_data.dtypes\n\ndriverid             object\ndriverref            object\ndob                  object\nnationality          object\ncircuit_name         object\ncircuit_location     object\ncircuit_country      object\nyear                  int64\nrace_name            object\nround                 int64\nconstructorid        object\nteam_name            object\nnumber                int64\ngrid                  int64\npositionorder         int64\npoints                int64\nlaps                  int64\nmilliseconds        float64\nfastestlap          float64\nrank                float64\nfastestlapspeed     float64\nstatusid              int64\ndtype: object\n\n\n\n\nDimensiones de los registros\nDeterminar el tamaño de nuestros registros es fundamental, ya que nos permite comprender la magnitud de la información que estamos manejando. Esto a su vez nos ayuda a establecer posibles caminos a seguir en caso de realizar transformaciones y análisis adicionales.\n\nrecords_data.shape\n\n(7830, 22)\n\n\n\nlen(records_data['driverref'].unique())\n\n349\n\n\nEsto indica que desde el año 1950 hasta el 2023, en las más de 1000 carreras que se han llevado a cabo, han competido 73 pilotos en esta competencia. Además, teniendo casi 8000 registros significa que estamos trabajando con una cantidad considerable de datos sobre equipos constructores.\n\n\nDatos faltantes\nDeterminar la presencia de datos faltantes es crucial, ya que puede indicar si podemos confiar en una columna para el análisis o si necesitamos tomar medidas para imputar esos valores ausentes.\n\nrecords_data.isnull().sum()\n\ndriverid               0\ndriverref              0\ndob                    0\nnationality            0\ncircuit_name           0\ncircuit_location       0\ncircuit_country        0\nyear                   0\nrace_name              0\nround                  0\nconstructorid          0\nteam_name              0\nnumber                 0\ngrid                   0\npositionorder          0\npoints                 0\nlaps                   0\nmilliseconds        1720\nfastestlap          4277\nrank                4266\nfastestlapspeed     4277\nstatusid               0\ndtype: int64\n\n\nCon los resultados obtenidos, observamos que tenemos una cantidad significativa de datos faltantes. Esta situación puede afectar los análisis futuros, dependiendo del tipo de variable que estemos considerando. Es importante determinar un método adecuado para la imputación de datos en caso de que sea necesario. Veamos el porcentaje que representa esta cantidad de datos faltantes en el total de nuestros datos.\n\nmissing_values = records_data.isnull().sum()\nmissing_percentage = round((missing_values / len(records_data)) * 100, 4)\nmissing_percentage\n\ndriverid             0.0000\ndriverref            0.0000\ndob                  0.0000\nnationality          0.0000\ncircuit_name         0.0000\ncircuit_location     0.0000\ncircuit_country      0.0000\nyear                 0.0000\nrace_name            0.0000\nround                0.0000\nconstructorid        0.0000\nteam_name            0.0000\nnumber               0.0000\ngrid                 0.0000\npositionorder        0.0000\npoints               0.0000\nlaps                 0.0000\nmilliseconds        21.9668\nfastestlap          54.6232\nrank                54.4828\nfastestlapspeed     54.6232\nstatusid             0.0000\ndtype: float64\n\n\nTenemos un gran porcentaje de datos faltantes en nuestras variables. Sin embargo, estos datos faltantes parecen estar concentrados en las variables relacionadas con medidas de tiempos y velocidades. Esto sugiere que estos datos podrían faltar debido a limitaciones técnicas o falta de registro en las fechas más antiguas, donde la toma de estas medidas podría no haber sido sistemática.\nPara comprender mejor la distribución de estos datos faltantes, examinemos en qué fechas están ocurriendo y verifiquemos la fecha máxima y mínima en la que faltan estas observaciones.\n\nrecords_data[records_data.isnull().any(axis = 1)]\n\n\n\n\n\n\n\n\n\ndriverid\ndriverref\ndob\nnationality\ncircuit_name\ncircuit_location\ncircuit_country\nyear\nrace_name\nround\n...\nnumber\ngrid\npositionorder\npoints\nlaps\nmilliseconds\nfastestlap\nrank\nfastestlapspeed\nstatusid\n\n\n\n\n5\n6\nnakajima\n1985-01-11\nJapanese\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\nAustralian Grand Prix\n1\n...\n8\n13\n6\n3\n57\nNaN\n50.0\n14.0\n212.974\n11\n\n\n6\n7\nbourdais\n1979-02-28\nFrench\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\nAustralian Grand Prix\n1\n...\n14\n17\n7\n2\n55\nNaN\n22.0\n12.0\n213.224\n5\n\n\n7\n8\nraikkonen\n1979-10-17\nFinnish\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n2008\nAustralian Grand Prix\n1\n...\n1\n15\n8\n1\n53\nNaN\n20.0\n4.0\n217.180\n5\n\n\n67\n8\nraikkonen\n1979-10-17\nFinnish\nSilverstone Circuit\nSilverstone\nUK\n2008\nBritish Grand Prix\n9\n...\n1\n3\n4\n5\n59\nNaN\n18.0\n1.0\n200.842\n11\n\n\n68\n5\nkovalainen\n1981-10-19\nFinnish\nSilverstone Circuit\nSilverstone\nUK\n2008\nBritish Grand Prix\n9\n...\n23\n1\n5\n4\n59\nNaN\n17.0\n5.0\n198.728\n11\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n7688\n846\nnorris\n1999-11-13\nBritish\nAutódromo Hermanos Rodríguez\nMexico City\nMexico\n2022\nMexico City Grand Prix\n20\n...\n4\n8\n9\n2\n70\nNaN\n48.0\n17.0\n185.779\n11\n\n\n7689\n822\nbottas\n1989-08-28\nFinnish\nAutódromo Hermanos Rodríguez\nMexico City\nMexico\n2022\nMexico City Grand Prix\n20\n...\n77\n6\n10\n1\n70\nNaN\n43.0\n16.0\n185.866\n11\n\n\n7768\n846\nnorris\n1999-11-13\nBritish\nCircuit de Monaco\nMonte-Carlo\nMonaco\n2023\nMonaco Grand Prix\n6\n...\n4\n10\n9\n2\n77\nNaN\n46.0\n19.0\n154.324\n11\n\n\n7769\n857\npiastri\n2001-04-06\nAustralian\nCircuit de Monaco\nMonte-Carlo\nMonaco\n2023\nMonaco Grand Prix\n6\n...\n81\n11\n10\n1\n77\nNaN\n47.0\n14.0\n154.983\n11\n\n\n7819\n840\nstroll\n1998-10-29\nCanadian\nHungaroring\nBudapest\nHungary\n2023\nHungarian Grand Prix\n11\n...\n18\n14\n10\n1\n69\nNaN\n54.0\n11.0\n189.051\n11\n\n\n\n\n4720 rows × 22 columns\n\n\n\n\n\n\nFecha mínima:  1950\nFecha promedio:  1984\nFecha máxima:  2023\n\n\nObservando estos resultados, podemos confirmar nuestra teoría. Estos registros faltantes pueden ser debidos a limitaciones técnicas en aquellos tiempos.",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla drivers"
    ]
  },
  {
    "objectID": "drivers.html#exploración-de-los-datos",
    "href": "drivers.html#exploración-de-los-datos",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Exploración de los datos",
    "text": "Exploración de los datos\nEn esta sección realizaremos el verdadero análisis exploratorio de nuestros datos. Abordaremos los siguientes aspectos:\n\nMedidas de tendencia central: Calcularemos medidas como la media, la mediana y la moda para entender mejor la distribución de nuestros datos.\nLimpieza de los datos: Abordaremos la limpieza de nuestros datos, incluyendo la búsqueda de datos atípicos.\nTransformación: Determinaremos si es necesario aplicar alguna transformación a nuestros datos para facilitar los análisis subsiguientes.\nVisualización: Utilizaremos herramientas gráficas para explorar el comportamiento de nuestros datos y extraer patrones o tendencias.\n\nEsta fase nos permitirá comprender mejor la naturaleza de nuestros datos y prepararlos adecuadamente para análisis más avanzados.\n\nMedidas de tendencia central\n\nrecords_data.describe()\n\n\n\n\n\n\n\n\n\nyear\nround\nnumber\ngrid\npositionorder\npoints\nlaps\nmilliseconds\nfastestlap\nrank\nfastestlapspeed\nstatusid\n\n\n\n\ncount\n7830.000000\n7830.000000\n7830.000000\n7830.000000\n7830.000000\n7830.000000\n7830.000000\n6.110000e+03\n3553.000000\n3564.000000\n3553.000000\n7830.000000\n\n\nmean\n1995.771520\n8.717880\n14.807791\n7.120817\n4.314815\n6.352618\n63.614304\n6.183581e+06\n46.603152\n6.680415\n206.006290\n3.538697\n\n\nstd\n20.267524\n5.186542\n15.616540\n5.022058\n2.505760\n5.574510\n18.795303\n1.514364e+06\n14.355980\n4.232408\n20.582848\n6.342502\n\n\nmin\n1950.000000\n1.000000\n0.000000\n0.000000\n1.000000\n1.000000\n1.000000\n2.070710e+05\n2.000000\n0.000000\n147.980000\n1.000000\n\n\n25%\n1980.000000\n4.000000\n5.000000\n3.000000\n2.000000\n2.000000\n54.000000\n5.405438e+06\n39.000000\n3.000000\n195.557000\n1.000000\n\n\n50%\n2000.000000\n8.000000\n10.000000\n6.000000\n4.000000\n4.000000\n62.000000\n5.802887e+06\n48.000000\n6.000000\n206.603000\n1.000000\n\n\n75%\n2013.000000\n13.000000\n20.000000\n10.000000\n6.000000\n9.000000\n71.000000\n6.415483e+06\n56.000000\n10.000000\n219.005000\n1.000000\n\n\nmax\n2023.000000\n22.000000\n117.000000\n33.000000\n33.000000\n50.000000\n200.000000\n1.472659e+07\n85.000000\n20.000000\n257.320000\n131.000000\n\n\n\n\n\n\n\n\n\nEstos resultados nos pueden permitir concluir lo siguiente:\n\nRonda: El número promedio de rondas por temporada es de aproximadamente 8.72, con una desviación estándar de aproximadamente 5.19. Esto sugiere que hay una variabilidad en la cantidad de rondas que se llevan a cabo en diferentes temporadas de Fórmula 1.\nNúmero de participantes, posición de salida y orden de llegada: Se observa una variabilidad significativa en el número de participantes por carrera, con un promedio de aproximadamente 14.81. Esta variabilidad puede atribuirse a factores como las regulaciones de la Fórmula 1 que pueden influir en la participación de equipos y pilotos en diferentes eventos. La posición en la parrilla de salida, con un promedio de alrededor de 7.12, refleja las diferencias en el rendimiento de los pilotos durante la clasificación, que puede estar influenciada por la aerodinámica del automóvil, la configuración del circuito y las habilidades individuales de los pilotos. A pesar de la variabilidad en la posición inicial, el orden promedio de llegada es de aproximadamente 4.31, lo que sugiere que, en promedio, los pilotos logran avanzar durante la carrera, ya sea mediante adelantamientos en pista o a través de estrategias de pit stop.\nNúmero de vueltas y tiempo de carrera: La cantidad promedio de vueltas completadas por carrera es de aproximadamente 63.61. Esta variabilidad puede ser atribuida a factores como la longitud y complejidad del circuito, así como la presencia de incidentes en pista que pueden afectar la duración de la carrera. El tiempo medio de carrera, aproximadamente 103 minutos, refleja la suma del tiempo requerido para completar todas las vueltas, así como los períodos de posibles intervenciones, como banderas amarillas o detenciones en boxes. La consistencia en la duración de la carrera sugiere una cierta estandarización en el formato de los eventos de la Fórmula 1, aunque la variabilidad aún puede ocurrir debido a diferentes condiciones de pista y estrategias de carrera.\nMejor vuelta, velocidad más rápida y puntos: La vuelta más rápida realizada por el ganador, con un promedio de alrededor de 206.01 km/h y una desviación estándar de aproximadamente 20.58 km/h, refleja el rendimiento máximo alcanzado por los pilotos durante la carrera. Esta velocidad puede variar según las condiciones del circuito y la estrategia de los equipos. En cuanto a los puntos obtenidos, con un promedio de aproximadamente 6.35, reflejan la efectividad de los pilotos y equipos para acumular puntos en cada evento. Esta puntuación puede influir en el desarrollo del campeonato y reflejar la consistencia y el rendimiento a lo largo de la temporada.\n\n\n\nLimpieza de los datos\nLa limpieza de datos es una etapa crucial en cualquier análisis, por lo que en este apartado trataremos los datos faltantes y observaremos si existen datos atípicos en nuestras variables.\n\nDatos faltantes\nExisten diversas estrategias para abordar este problema. Usualmente, en este tipo de análisis se recurre a la imputación de valores faltantes utilizando la media, moda o mediana, o llenando los datos con los valores anteriores o siguientes. Sin embargo, estas técnicas pueden no ser óptimas para conjuntos de datos extensos o con características específicas.\nEn nuestro caso, una estrategia efectiva sería utilizar la imputación de datos faltantes basada en puntos similares en los datos mediante el algoritmo KNN (K-Nearest Neighbors) y Random Forest Classification. Este método considera las características de observaciones similares para estimar los valores faltantes de manera más precisa y realista, lo que resulta especialmente útil en conjuntos de datos complejos como el nuestro.\nInicialmente, creemos un DataFrame temporal donde estarán los mismos datos de records_data pero sin las columnas correspondientes a tipo object.\n\ntemp_df = records_data.select_dtypes(exclude=['object'])\n\nimputer = IterativeImputer(min_value=0, max_iter=30, imputation_order='roman', random_state=1)\nimputed_data = imputer.fit_transform(temp_df)\n\ntemp_df_imputed = pd.DataFrame(imputed_data, columns=temp_df.columns)\ntemp_df_imputed.isnull().sum()\n\nyear               0\nround              0\nnumber             0\ngrid               0\npositionorder      0\npoints             0\nlaps               0\nmilliseconds       0\nfastestlap         0\nrank               0\nfastestlapspeed    0\nstatusid           0\ndtype: int64\n\n\nBien, ya no tenemos datos faltantes. Ahora, verifiquemos si los resultados obtenidos en las medidas de tendencia central del DataFrame original cambiaron significativamente.\n\ntemp_df_imputed.describe()\n\n\n\n\n\n\n\n\n\nyear\nround\nnumber\ngrid\npositionorder\npoints\nlaps\nmilliseconds\nfastestlap\nrank\nfastestlapspeed\nstatusid\n\n\n\n\ncount\n7830.000000\n7830.000000\n7830.000000\n7830.000000\n7830.000000\n7830.000000\n7830.000000\n7.830000e+03\n7830.000000\n7830.000000\n7830.000000\n7830.000000\n\n\nmean\n1995.771520\n8.717880\n14.807791\n7.120817\n4.314815\n6.352618\n63.614304\n6.357840e+06\n37.583611\n5.902056\n191.230541\n3.538697\n\n\nstd\n20.267524\n5.186542\n15.616540\n5.022058\n2.505760\n5.574510\n18.795303\n1.503172e+06\n17.275427\n3.355313\n33.140535\n6.342502\n\n\nmin\n1950.000000\n1.000000\n0.000000\n0.000000\n1.000000\n1.000000\n1.000000\n2.070710e+05\n0.000000\n0.000000\n0.000000\n1.000000\n\n\n25%\n1980.000000\n4.000000\n5.000000\n3.000000\n2.000000\n2.000000\n54.000000\n5.484704e+06\n27.278717\n3.307868\n176.963262\n1.000000\n\n\n50%\n2000.000000\n8.000000\n10.000000\n6.000000\n4.000000\n4.000000\n62.000000\n5.952724e+06\n37.110519\n5.285219\n196.594000\n1.000000\n\n\n75%\n2013.000000\n13.000000\n20.000000\n10.000000\n6.000000\n9.000000\n71.000000\n6.815400e+06\n48.000000\n7.720035\n210.953515\n1.000000\n\n\nmax\n2023.000000\n22.000000\n117.000000\n33.000000\n33.000000\n50.000000\n200.000000\n1.520664e+07\n135.030294\n31.667058\n325.915900\n131.000000\n\n\n\n\n\n\n\n\n\nComparando los resultados de las medidas de tendencia central antes y después de la imputación de datos con el algoritmo KNN, observamos algunas diferencias significativas en ciertas variables:\n\nNúmero de vueltas y tiempo de carrera: Ambos conjuntos de datos muestran una distribución similar en el número de vueltas por carrera, con una media y desviación estándar comparables. Sin embargo, se observan diferencias mínimas en el tiempo medio de carrera entre los dos conjuntos de datos, lo que indica que no se ha visto afectada la dispersión luego de la imputación.\nMejor vuelta y velocidad más rápida: Las estadísticas de la mejor vuelta y la velocidad más rápida son comparables entre los dos conjuntos de datos, lo que sugiere una consistencia en la imputación de los datos faltantes.\n\nAhora que hemos realizado la imputación de datos, pasemos estos datos a nuestro dataframe original.\n\nrecords_data[temp_df.columns] = temp_df_imputed\nrecords_data.isnull().sum()\n\ndriverid            0\ndriverref           0\ndob                 0\nnationality         0\ncircuit_name        0\ncircuit_location    0\ncircuit_country     0\nyear                0\nrace_name           0\nround               0\nconstructorid       0\nteam_name           0\nnumber              0\ngrid                0\npositionorder       0\npoints              0\nlaps                0\nmilliseconds        0\nfastestlap          0\nrank                0\nfastestlapspeed     0\nstatusid            0\ndtype: int64\n\n\n\n\nDatos atípicos\nVeamos ahora si existen datos atípicos en nuestro registro. En este caso, utilizaremos el rango intercuartílico (IQR) para identificar los valores atípicos. Si un valor cae por debajo de Q1 - 1.5 * IQR o por encima de Q3 + 1.5 * IQR, se considera un valor atípico.\n\nnumeric_columns = temp_df.columns\n\nfor col in numeric_columns:\n    q1 = records_data[col].quantile(0.25)\n    q3 = records_data[col].quantile(0.75)\n\n    iqr = q3 - q1\n    lower_bound = q1 - 1.5 * iqr\n    upper_bound = q3 + 1.5 * iqr\n    outliers = records_data[(records_data[col] &lt; lower_bound) | (records_data[col] &gt; upper_bound)]\n    n_outliers = len(outliers)\n    print(f'#Outliers in {col} are {n_outliers} and represent a {round(n_outliers/len(records_data) * 100, 4)}% of total records')\n\n#Outliers in year are 0 and represent a 0.0% of total records\n#Outliers in round are 0 and represent a 0.0% of total records\n#Outliers in number are 544 and represent a 6.9476% of total records\n#Outliers in grid are 105 and represent a 1.341% of total records\n#Outliers in positionorder are 12 and represent a 0.1533% of total records\n#Outliers in points are 274 and represent a 3.4994% of total records\n#Outliers in laps are 412 and represent a 5.2618% of total records\n#Outliers in milliseconds are 542 and represent a 6.9221% of total records\n#Outliers in fastestlap are 63 and represent a 0.8046% of total records\n#Outliers in rank are 196 and represent a 2.5032% of total records\n#Outliers in fastestlapspeed are 331 and represent a 4.2273% of total records\n#Outliers in statusid are 1719 and represent a 21.954% of total records\n\n\nComo podemos observar, respecto a los más de 7000 registros que tiene la tabla, hay una pequeña cantidad significativa de datos atípicos en nuestras variables. Veamos gráficamente qué es lo que está ocurriendo con ellos. Y, aunque statusid tiene una gran cantidad de datos atípicos, esta es una variable categórica y que solo describe el estado de finalización de una carrera.\nRealizaremos un gráfico de caja y bigotes e histogramas para ver el comportamiento y la distribución de nuestros datos.\n\nplt.figure(figsize=(9,12))\n\ni = 1\nfor col in numeric_columns:\n    plt.subplot(5,3,i)\n    plt.boxplot(records_data[col],whis=1.5)\n    plt.title(col)\n\n    i += 1\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure(figsize=(8,12))\n\ni = 1\nfor col in numeric_columns:\n    plt.subplot(5, 3, i)\n    sns.histplot(records_data[col], kde=True)\n    plt.title(col)\n    i += 1\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nDada la naturaleza de las variables, en algunos casos como round, positionorder, grid, points, entre otros que son datos numéricos discretos y representan una categoría específica, es normal que existan datos atípicos. Por otro lado, para las otras variables en nuestra base de datos, estos datos atípicos no están afectando mucho la distribución de cada una de ellas, por lo tanto, no realizaremos cambios en ellas.",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla drivers"
    ]
  },
  {
    "objectID": "drivers.html#visualización",
    "href": "drivers.html#visualización",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Visualización",
    "text": "Visualización\nLa visualización es uno de los puntos más importantes a la hora de realizar una exploración de los datos. Con ella, no solo podemos encontrar las relaciones que existen entre nuestras variables, sino que también podemos representar gráficamente las informaciones más relevantes de los datos.\nComencemos visualizando los gráficos de correlación y dispersión entre las variables para comprender mejor sus relaciones y encontrar posibles patrones.\n\nGráfico de correlación\n\ncorr = records_data[numeric_columns].corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\nsns.heatmap(corr, annot=True, cmap='PRGn', square=True, center=0, mask=mask)\n\n\n\n\n\n\n\n\nComo podemos observar, las variables con una alta correlación (&gt;0.5 o &lt;-0.5) son aquellas que están relacionadas entre sí, como laps, fastestlapspeed, fastest_lap, positionorder, year, fastest_pip_stop entre otras. Por lo tanto, esto no debería ser un problema y podemos proseguir con la exploración de los datos.\n\n\nGráfico de dispersión\n\nplt.figure(figsize=(8, 12))\nsns.pairplot(records_data[numeric_columns])\nplt.show()\n\n&lt;Figure size 768x1152 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\nDe este gráfico podemos notar que a medida que pasan los años, los equipos han ha evolucionado progresivamente en términos de velocidades y tiempos de carreras obtenidos. La velocidad y duración en boxes han aumentado, lo que indica una mejora en los automóviles y las técnicas de revisión de ellos. Sin embargo, estos cambios en las velocidades y tiempos también se han vuelto más dispersos a lo largo de los años, lo que implica que ha habido una gran diferencia entre los equipos constructores. Además, también podemos observar algunas relaciones proporcionales en nuestras variables, como aquellas relacionadas nuevamente con las velocidades y tiempos.\n\n\nDistribución de carreras por piloto\n\ndriver_stats = records_data.groupby('driverref').size().reset_index(name='total_races')\ndriver_stats = driver_stats.sort_values(by='total_races', ascending=False)\ndriver_stats = driver_stats.rename(columns={'driverref': 'driver_name'})\n\ntop_constructors = driver_stats.head(5)\n\nplt.figure(figsize=(8, 7))\nsns.histplot(driver_stats['total_races'], kde=False, bins=30, color='skyblue', edgecolor='black')\nplt.title('Distribución del número total de carreras por piloto')\nplt.xlabel('Número Total de Carreras')\nplt.ylabel('Frecuencia')\n\ntext = '\\n'.join([f\"{i+1}. {row['driver_name']}: {row['total_races']} carreras\" for i, (index, row) in enumerate(top_constructors.iterrows(), start=0)])\nplt.text(max(top_constructors['total_races']) * 1.02, plt.ylim()[1] * 0.9, text, ha='right', va='top', fontsize=10)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nTop 5 pilotos más ganadores\n\ndriver_stats = records_data[records_data['positionorder'] == 1]\ndriver_stats = records_data.groupby('driverref').size().reset_index(name='total_wins')\ndriver_stats = driver_stats.sort_values(by='total_wins', ascending=False)\ndriver_stats = driver_stats.rename(columns={'driverref': 'driver_name'})\n\ntop_constructors = driver_stats.head(5)\n\nplt.figure(figsize=(8, 7))\nplt.bar(top_constructors['driver_name'], top_constructors['total_wins'], color='skyblue')\nplt.title('Top 5 Equipos Más Ganadores en F1')\nplt.xlabel('Equipo')\nplt.ylabel('Número Total de Victorias')\nplt.xticks()\nplt.show()",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla drivers"
    ]
  },
  {
    "objectID": "logisticbinary.html",
    "href": "logisticbinary.html",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "",
    "text": "La regresión lineal es una herramienta de modelado ampliamente aplicable, pero no es apropiada cuando el modelo correcto debe ser no lineal en los parámetros. Tal es el caso cuando el punto final del estudio es una variable binaria. El modelo se vuelve no lineal porque lo que se está modelando es la probabilidad de que un caso experimente el evento de interés o que un caso esté en una categoría particular de la respuesta binaria (DeMaris y Selman 2013).\n(IBM 2024) Este tipo de modelo estadístico (también conocido como modelo logit) se utiliza frecuentemente para clasificación y análisis predictivo. Dado que el resultado es una probabilidad, la variable dependiente está limitada entre 0 y 1. En la regresión logística, se aplica una transformación logit a las probabilidades, es decir, la probabilidad de éxito dividida por la probabilidad de fracaso. Esto también se conoce comúnmente como logaritmo de las probabilidades o logaritmo natural de las probabilidades, y esta función logística se representa mediante las siguientes fórmulas:\n\\[\n    \\text{Logit} (p_j) := \\ln\\left(\\frac{p_j}{1-p_j}\\right) =  \\delta  \\;+\\;  \\beta_1 \\,x_{j1}  \\;+\\;\\cdots \\;+\\; \\beta_K \\,x_{jK}.\n\\]\nEn esta ecuación de regresión logística, \\(\\text{Logit} (p_j)\\) es la variable dependiente o de respuesta, y \\(x\\) es la variable independiente. El parámetro beta, o coeficiente, en este modelo comúnmente se estima mediante la estimación de máxima verosimilitud (MLE, por sus siglas en inglés). Este método prueba diferentes valores de beta a través de múltiples iteraciones para optimizar el mejor ajuste de los logaritmos de las probabilidades. Todas estas iteraciones producen la función de verosimilitud logarítmica, y la regresión logística busca maximizar esta función para encontrar la mejor estimación de los parámetros. Una vez que se encuentra el coeficiente óptimo (o coeficientes si hay más de una variable independiente), se pueden calcular las probabilidades condicionales para cada observación, tomarles el logaritmo y sumarlos para obtener una probabilidad predicha. Para la clasificación binaria, una probabilidad menor que 0.5 predecirá 0, mientras que una probabilidad mayor que 0.5 predecirá 1.\n(Llinás y Carreño 2012) Notemos que este modelo es construido suponiendo una matriz de diseño de la siguiente forma:\n\\[\n    C = \\left(\n        \\begin{array}{cccc}\n            1          & x_{11}    &\\cdots     &x_{1K}\\\\\n            1          & x_{21}    &\\cdots     &x_{2K}\\\\\n            \\vdots     &\\vdots     &           &\\vdots\\\\\n            1          &x_{J1}     &\\cdots     &x_{JK}\\\\\n        \\end{array}\n    \\right)\n\\]\ndonde el rango completo de esta matriz estará dado por: \\(Rg(C) = 1 + K \\leq J\\), tal que \\(J\\) representa el número de poblaciones existentens en los datos.\nLa ecuación denotada para \\(\\text{Logit} (p_j)\\) es conocido como el modelo logístico. Sin embargo, para hallarlo necesitamos conocer el valor de \\(p_j\\). Este valor representa la probabilidad (riesgo) de que se obtenga alguna de las respuestas de la variable dependiente. Entonces, la probabilidad\n\\[\n    p_j = P\\left(Y_j = 1 | x_{j1},\\dots, x_{jK}\\right),\n\\]\nde obtener un éxito en la población \\(j = 1, \\dots, J\\), dados los valores \\(x_{j1},\\dots, x_{jK}\\), viene dada por:\n\\[\n    p_j \\;= \\; \\mbox{Logit}^{-1}(g_j) \\;= \\; \\frac{e^{g_j}} {1 + e^{g_j}},\n\\]\ndonde \\(g_j\\) está definido así:\n\\[\n    g_j:=\\delta \\;+\\; \\beta_1\\,x_{1j} \\;+\\;\\cdots \\;+\\; \\beta_K \\,x_{Kj},\n\\]\ncon vector de parámetros \\(\\alpha = \\left(\\delta, \\beta_1, \\dots, \\beta_K \\right)^\\top\\). Ahora, para obtener el logaritmo de la función de verosimilitud del modelo logístico debemos tener en cuenta la siguiente ecuación:\n\\[\n    \\begin{align*}\n        \\cal L (p) &= \\sum_{j = 1}^J \\left(\\sum_{i = 1}^n \\left[y_{ij} \\ln (p_j) + (1 - y_{ij}) \\ln (1 - p_j)\\right]\\right) \\\\\n        &=  \\sum_{j = 1}^J \\left[z_j \\ln (p_j) + (n_j - z_j) \\ln (1 - p_j)\\right],\n    \\end{align*}\n\\]\ntal que \\(z_j\\) es una variable aleatoria binomial \\(z_j \\sim{\\cal B} (n_j, p_j)\\) de las distintas poblaciones.\nAhora, reescribiendo esta ecuación en términos de \\(\\alpha\\) tenemos\n\\[\n    \\begin{align*}\n        {\\cal L} ({\\alpha}) &= \\sum^{J}_{j = 1} \\left[z_j \\ln \\left(\\frac{p_j}{1 - p_j}\\right) + n_j \\ln(1 - p_j)\\right] \\\\\n        &= \\sum^{J}_{j = 1} z_j \\, g_j \\;-\\; \\sum^{J}_{j = 1} n_j \\ln \\left[1 + e^{g_j}\\right].\n    \\end{align*}\n\\]",
    "crumbs": [
      "Análisis Predictivos",
      "Modelo de Regresión Logística Binaria"
    ]
  },
  {
    "objectID": "logisticbinary.html#curva-roc",
    "href": "logisticbinary.html#curva-roc",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Curva ROC",
    "text": "Curva ROC\nAntes de realizar el gráfico de la curva ROC debemos ver dos gráficos que nos darán contexto al mecánismo de los umbrales detrás de esta curva.\n\nfrom sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(y, y_pred)\n\ny_g = y['scored_or_no'].values\n\nfig_hist = px.histogram(\n    x=y_pred, color=y_g, nbins=50,\n    labels=dict(color='True Labels', x='Score')\n)\n\nfig_hist.update_layout(\n    margin={'b': 0, 'r': 30, 'l': 30, 't': 0},\n    xaxis={'gridcolor': '#111', 'tickfont': {'color': 'white'}},\n    yaxis={'gridcolor': '#111', 'tickfont': {'color': 'white'}},\n    plot_bgcolor='rgba(0, 0, 0, 0.0)',\n    paper_bgcolor='rgba(0, 0, 0, 0.0)',\n    font_color=\"white\",\n    hoverlabel=dict(\n        bgcolor=\"#111\"\n    )\n)\n\nfig_hist.show()\n\n\n\nEn el histograma, observamos que la puntuación se distribuye de tal forma que la mayoría de las etiquetas positivas y negativas se sitúan cerca de 0, y las que más valores se reunen en 1 serían las negativas. Cuando fijamos un umbral en la puntuación, todos los bines a su izquierda se clasificarán como 0, y todo a la derecha serán 1. Obviamente, hay algunos valores atípicos, como las muestras negativas a las que nuestro modelo dio una puntuación alta, y las muestras positivas con una puntuación baja. Si fijamos un umbral justo en el medio, esos valores atípicos se convertirán respectivamente en falsos positivos y falsos negativos.\nEvaluemos entonces el rendimiento del modelo con diferentes umbrales\n\ndf = pd.DataFrame({\n    'False Positive Rate': fpr,\n    'True Positive Rate': tpr\n}, index=thresholds)\ndf.index.name = \"Thresholds\"\ndf.columns.name = \"Rate\"\n\nfig_thresh = px.line(\n    df, title='TPR y FPR en cada umbral',\n    width=700, height=500\n)\n\nfig_thresh.update_yaxes(scaleanchor=\"x\", scaleratio=1)\nfig_thresh.update_xaxes(range=[0, 1], constrain='domain')\n\nfig_thresh.update_layout(\n    margin={'b': 0, 'r': 30, 'l': 30, 't': 50},\n    xaxis={'gridcolor': '#111', 'tickfont': {'color': 'white'}},\n    yaxis={'gridcolor': '#111', 'tickfont': {'color': 'white'}},\n    plot_bgcolor='rgba(0, 0, 0, 0.0)',\n    paper_bgcolor='rgba(0, 0, 0, 0.0)',\n    font_color=\"white\",\n    hoverlabel=dict(\n        bgcolor=\"#111\"\n    )\n)\n\nfig_thresh.show()\n\n\n\nA medida que ajustamos los umbrales, el número de positivos aumentará o disminuirá, y al mismo tiempo también cambiará el número de verdaderos positivos; esto se muestra en el segundo gráfico. Como se puede ver, el modelo parece funcionar bastante bien, porque la tasa de verdaderos positivos disminuye lentamente, mientras que la tasa de falsos positivos disminuye bruscamente a medida que aumentamos el umbral. Cada una de esas dos líneas representa una dimensión de la curva ROC.\n\nfig_roc = px.area(\n    x=fpr, y=tpr,\n    title=f'Curva de ROC',\n    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n    width=700, height=500\n)\n\nfig_roc.add_shape(\n    type='line', line=dict(dash='dash', color='white'),\n    x0=0, x1=1, y0=0, y1=1\n)\n\nfig_roc.add_annotation(\n    xref = 'paper', yref = 'paper',\n    x = .95, y = .05,\n    text = f'AUC: {auc:.4f}',\n    showarrow = False,\n    bordercolor = 'black',\n    borderwidth = .5,\n    bgcolor = '#e10600'\n)\n\nfig_roc.update_yaxes(scaleanchor=\"x\", scaleratio=1)\nfig_roc.update_xaxes(constrain='domain')\n\nfig_roc.update_layout(\n    margin={'b': 0, 'r': 30, 'l': 30, 't': 50},\n    xaxis={'gridcolor': '#111', 'tickfont': {'color': 'white'}},\n    yaxis={'gridcolor': '#111', 'tickfont': {'color': 'white'}},\n    plot_bgcolor='rgba(0, 0, 0, 0.0)',\n    paper_bgcolor='rgba(0, 0, 0, 0.0)',\n    font_color=\"white\",\n    hoverlabel=dict(\n        bgcolor=\"#111\"\n    )\n)\n\nfig_roc.show()\n\n\n\nNotemos que esta curva ROC se parece a la curva de TPR del gráfico anterior. Esto se debe a que son la misma curva, salvo que el eje x consiste en valores crecientes de FPR en lugar de umbral, razón por la cual la línea está invertida y distorsionada. También se puede observar el área bajo la curva ROC (ROC AUC), que es bastante alta, lo que concuerda con nuestra interpretación de los gráficos anteriores.",
    "crumbs": [
      "Análisis Predictivos",
      "Modelo de Regresión Logística Binaria"
    ]
  },
  {
    "objectID": "logisticbinary.html#matriz-de-confusión",
    "href": "logisticbinary.html#matriz-de-confusión",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Matriz de confusión",
    "text": "Matriz de confusión\nOtra forma de visualizar los aciertos en las predicciones de los modelos es mediante una matriz de confusión. En ella podremos observar los valores \\(TP\\), \\(FP\\), \\(TN\\) y \\(FN\\) predichos por el modelo y determinar qué tanto es el acierto.\n\nfrom sklearn.metrics import confusion_matrix\nimport plotly.figure_factory as ff\n\nconf_matrix_log_reg = confusion_matrix(y, y_pred_a).T\n\nlabels = ['No Puntuó', 'Puntuó']\nfig_cm = ff.create_annotated_heatmap(conf_matrix_log_reg, x=labels, y=labels, colorscale=[[0, '#FFFFFF'], [1, '#e10600']])\nfig_cm.update_layout(title='Matriz de Confusión')\n\nfig_cm.update_layout(\n    margin={'b': 0, 'r': 30, 'l': 30, 't': 50},\n    xaxis={'gridcolor': '#111', 'tickfont': {'color': 'white'}},\n    yaxis={'gridcolor': '#111', 'tickfont': {'color': 'white'}},\n    plot_bgcolor='rgba(0, 0, 0, 0.0)',\n    paper_bgcolor='rgba(0, 0, 0, 0.0)',\n    font_color=\"white\",\n    hoverlabel=dict(\n        bgcolor=\"#111\"\n    )\n)\n\nfig_cm.show()",
    "crumbs": [
      "Análisis Predictivos",
      "Modelo de Regresión Logística Binaria"
    ]
  },
  {
    "objectID": "races.html",
    "href": "races.html",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "",
    "text": "En esta sección, llevaremos a cabo un análisis exploratorio centrado en la tabla races, que abarca los datos de las carreras disputadas desde 1950 hasta 2023. Sin embargo, para llevar a cabo este análisis de manera integral, necesitamos consolidar información proveniente de diversas fuentes. Utilizaremos consultas para unificar los datos de la tabla races con aquellos de las tablas circuits (que contiene información sobre los circuitos donde se celebran las carreras de Fórmula 1), results (que proporciona los resultados de las carreras) y lap_times (los tiempos registrados por vuelta).\nEs fundamental destacar que, para la tabla results nos enfocaremos exclusivamente en los datos del ganador de cada carrera. Asimismo, de la tabla lap_time, extraeremos únicamente la información correspondiente a la vuelta más rápida registrada.",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla races"
    ]
  },
  {
    "objectID": "races.html#tabla-races",
    "href": "races.html#tabla-races",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Tabla races",
    "text": "Tabla races\n\ntry:\n    connection = connection_db()\n    cursor = connection.cursor()\n\n    cursor.execute(\n        \"\"\"\n            SELECT *\n            FROM races\n            LIMIT 5;\n        \"\"\"\n    )\n\n    records = cursor.fetchall()\n    records_data = pd.DataFrame(records)\n\n    columns = []\n    for column in cursor.description:\n        columns.append(column[0])\n\n    records_data.columns = columns\n\n    display(records_data)\nexcept (Exception, Error) as e:\n    print('Error while executing the query', e)\nfinally:\n    if(connection):\n        cursor.close()\n        connection.close()\n\n\n\n\n\n\n\n\n\nraceid\nyear\nround\ncircuitid\nname\ndate\ntime\nurl\nfp1_date\nfp1_time\nfp2_date\nfp2_time\nfp3_date\nfp3_time\nquali_date\nquali_time\nsprint_date\nsprint_time\n\n\n\n\n0\n1\n2009\n1\n1\nAustralian Grand Prix\n2009-03-29\n06:00:00\nhttp://en.wikipedia.org/wiki/2009_Australian_G...\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\n\n\n1\n2\n2009\n2\n2\nMalaysian Grand Prix\n2009-04-05\n09:00:00\nhttp://en.wikipedia.org/wiki/2009_Malaysian_Gr...\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\n\n\n2\n3\n2009\n3\n17\nChinese Grand Prix\n2009-04-19\n07:00:00\nhttp://en.wikipedia.org/wiki/2009_Chinese_Gran...\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\n\n\n3\n4\n2009\n4\n3\nBahrain Grand Prix\n2009-04-26\n12:00:00\nhttp://en.wikipedia.org/wiki/2009_Bahrain_Gran...\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\n\n\n4\n5\n2009\n5\n4\nSpanish Grand Prix\n2009-05-10\n12:00:00\nhttp://en.wikipedia.org/wiki/2009_Spanish_Gran...\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla races"
    ]
  },
  {
    "objectID": "races.html#tabla-circuits",
    "href": "races.html#tabla-circuits",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Tabla circuits",
    "text": "Tabla circuits\n\ntry:\n    connection = connection_db()\n    cursor = connection.cursor()\n\n    cursor.execute(\n        \"\"\"\n            SELECT *\n            FROM circuits\n            LIMIT 5;\n        \"\"\"\n    )\n\n    records = cursor.fetchall()\n    records_data = pd.DataFrame(records)\n\n    columns = []\n    for column in cursor.description:\n        columns.append(column[0])\n\n    records_data.columns = columns\n\n    display(records_data)\nexcept (Exception, Error) as e:\n    print('Error while executing the query', e)\nfinally:\n    if(connection):\n        cursor.close()\n        connection.close()\n\n\n\n\n\n\n\n\n\ncircuitid\ncircuitref\nname\nlocation\ncountry\nlat\nlng\nalt\nurl\n\n\n\n\n0\n1\nalbert_park\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n-37.8497\n144.968\n10\nhttp://en.wikipedia.org/wiki/Melbourne_Grand_P...\n\n\n1\n2\nsepang\nSepang International Circuit\nKuala Lumpur\nMalaysia\n2.76083\n101.738\n18\nhttp://en.wikipedia.org/wiki/Sepang_Internatio...\n\n\n2\n3\nbahrain\nBahrain International Circuit\nSakhir\nBahrain\n26.0325\n50.5106\n7\nhttp://en.wikipedia.org/wiki/Bahrain_Internati...\n\n\n3\n4\ncatalunya\nCircuit de Barcelona-Catalunya\nMontmeló\nSpain\n41.57\n2.26111\n109\nhttp://en.wikipedia.org/wiki/Circuit_de_Barcel...\n\n\n4\n5\nistanbul\nIstanbul Park\nIstanbul\nTurkey\n40.9517\n29.405\n130\nhttp://en.wikipedia.org/wiki/Istanbul_Park",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla races"
    ]
  },
  {
    "objectID": "races.html#tabla-results",
    "href": "races.html#tabla-results",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Tabla results",
    "text": "Tabla results\n\ntry:\n    connection = connection_db()\n    cursor = connection.cursor()\n\n    cursor.execute(\n        \"\"\"\n            SELECT *\n            FROM results\n            LIMIT 5;\n        \"\"\"\n    )\n\n    records = cursor.fetchall()\n    records_data = pd.DataFrame(records)\n\n    columns = []\n    for column in cursor.description:\n        columns.append(column[0])\n\n    records_data.columns = columns\n\n    display(records_data)\nexcept (Exception, Error) as e:\n    print('Error while executing the query', e)\nfinally:\n    if(connection):\n        cursor.close()\n        connection.close()\n\n\n\n\n\n\n\n\n\nresultid\nraceid\ndriverid\nconstructorid\nnumber\ngrid\nposition\npositiontext\npositionorder\npoints\nlaps\ntime\nmilliseconds\nfastestlap\nrank\nfastestlaptime\nfastestlapspeed\nstatusid\n\n\n\n\n0\n1\n18\n1\n1\n22\n1\n1\n1\n1\n10\n58\n1:34:50.616\n5690616\n39\n2\n1:27.452\n218.300\n1\n\n\n1\n2\n18\n2\n2\n3\n5\n2\n2\n2\n8\n58\n+5.478\n5696094\n41\n3\n1:27.739\n217.586\n1\n\n\n2\n3\n18\n3\n3\n7\n7\n3\n3\n3\n6\n58\n+8.163\n5698779\n41\n5\n1:28.090\n216.719\n1\n\n\n3\n4\n18\n4\n4\n5\n11\n4\n4\n4\n5\n58\n+17.181\n5707797\n58\n7\n1:28.603\n215.464\n1\n\n\n4\n5\n18\n5\n1\n23\n3\n5\n5\n5\n4\n58\n+18.014\n5708630\n43\n1\n1:27.418\n218.385\n1",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla races"
    ]
  },
  {
    "objectID": "races.html#tabla-lap_times",
    "href": "races.html#tabla-lap_times",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Tabla lap_times",
    "text": "Tabla lap_times\n\ntry:\n    connection = connection_db()\n    cursor = connection.cursor()\n\n    cursor.execute(\n        \"\"\"\n            SELECT *\n            FROM lap_times\n            LIMIT 5;\n        \"\"\"\n    )\n\n    records = cursor.fetchall()\n    records_data = pd.DataFrame(records)\n\n    columns = []\n    for column in cursor.description:\n        columns.append(column[0])\n\n    records_data.columns = columns\n\n    display(records_data)\nexcept (Exception, Error) as e:\n    print('Error while executing the query', e)\nfinally:\n    if(connection):\n        cursor.close()\n        connection.close()\n\n\n\n\n\n\n\n\n\nraceid\ndriverid\nlap\nposition\ntime\nmilliseconds\n\n\n\n\n0\n841\n20\n1\n1\n1:38.109\n98109\n\n\n1\n841\n20\n2\n1\n1:33.006\n93006\n\n\n2\n841\n20\n3\n1\n1:32.713\n92713\n\n\n3\n841\n20\n4\n1\n1:32.803\n92803\n\n\n4\n841\n20\n5\n1\n1:32.342\n92342",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla races"
    ]
  },
  {
    "objectID": "races.html#tabla-final",
    "href": "races.html#tabla-final",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Tabla final",
    "text": "Tabla final\nCon base en las columnas proporcionadas de cada tabla, podemos listar las que se utilizarán en el análisis de la siguiente manera:\n\nRaces: raceId, year, round, circuitId, name, time.\nCircuits: circuit_ref, name, location, country, lat, lng.\nResults: driverId, constructorId, points, grid, laps, milliseconds, fastestlap, rank, fastestlapspeed.\nLap Times: lap, miliseconds.\n\nRealicemos entonces la consulta a la base de datos para obtener esta tabla.\n\ntry:\n    connection = connection_db()\n    cursor = connection.cursor()\n\n    cursor.execute(\n        \"\"\"\n            SELECT \n                r.raceId, r.year, r.round, r.circuitId, r.name AS race_name,\n                c.circuitref, c.name AS circuit_name, c.location AS circuit_location, c.country AS circuit_country,\n                c.lat AS circuit_lat, c.lng AS circuit_lng,\n                re.driverId, re.constructorId, re.points, re.grid, re.laps, re.milliseconds as race_time_in_milliseconds,\n                re.fastestlap AS winner_fastest_lap, re.rank as winner_lap_rank, re.fastestlapspeed as winner_fastestlapspeed,\n                l.lap as general_fastest_lap, l.milliseconds AS general_fastest_lap_time\n            FROM races AS r\n            JOIN circuits AS c ON r.circuitId = c.circuitId\n            JOIN (\n                SELECT raceId, driverId, constructorId, points, grid, laps, milliseconds, fastestlap, rank, fastestlapspeed\n                FROM results\n                WHERE positionOrder = 1\n            ) AS re ON r.raceId = re.raceId\n            LEFT JOIN (\n                SELECT lt.raceId, lt.lap, lt.milliseconds\n                FROM lap_times lt\n                JOIN (\n                    SELECT raceId, MIN(milliseconds) AS min_milliseconds\n                    FROM lap_times\n                    GROUP BY raceId\n                ) AS min_lap_times ON lt.raceId = min_lap_times.raceId AND lt.milliseconds = min_lap_times.min_milliseconds\n            ) AS l ON r.raceId = l.raceId;\n        \"\"\"\n    )\n\n    records = cursor.fetchall()\n    records_data = pd.DataFrame(records)\n\n    columns = []\n    for column in cursor.description:\n        columns.append(column[0])\n\n    records_data.columns = columns\n\n    display(records_data.head())\nexcept (Exception, Error) as e:\n    print('Error while executing the query', e)\nfinally:\n    if(connection):\n        cursor.close()\n        connection.close()\n\n\n\n\n\n\n\n\n\nraceid\nyear\nround\ncircuitid\nrace_name\ncircuitref\ncircuit_name\ncircuit_location\ncircuit_country\ncircuit_lat\n...\nconstructorid\npoints\ngrid\nlaps\nrace_time_in_milliseconds\nwinner_fastest_lap\nwinner_lap_rank\nwinner_fastestlapspeed\ngeneral_fastest_lap\ngeneral_fastest_lap_time\n\n\n\n\n0\n18\n2008\n1\n1\nAustralian Grand Prix\nalbert_park\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n-37.8497\n...\n1\n10\n1\n58\n5690616\n39.0\n2.0\n218.300\n43.0\n87418.0\n\n\n1\n19\n2008\n2\n2\nMalaysian Grand Prix\nsepang\nSepang International Circuit\nKuala Lumpur\nMalaysia\n2.76083\n...\n6\n10\n2\n56\n5478555\n37.0\n2.0\n209.158\n55.0\n95366.0\n\n\n2\n20\n2008\n3\n3\nBahrain Grand Prix\nbahrain\nBahrain International Circuit\nSakhir\nBahrain\n26.0325\n...\n6\n10\n2\n57\n5466970\n38.0\n3.0\n208.153\n49.0\n93193.0\n\n\n3\n21\n2008\n4\n4\nSpanish Grand Prix\ncatalunya\nCircuit de Barcelona-Catalunya\nMontmeló\nSpain\n41.57\n...\n6\n10\n1\n66\n5899051\n46.0\n1.0\n205.191\n46.0\n81670.0\n\n\n4\n22\n2008\n5\n5\nTurkish Grand Prix\nistanbul\nIstanbul Park\nIstanbul\nTurkey\n40.9517\n...\n6\n10\n1\n58\n5209451\n16.0\n3.0\n221.734\n20.0\n86506.0\n\n\n\n\n5 rows × 22 columns",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla races"
    ]
  },
  {
    "objectID": "races.html#conociendo-los-datos",
    "href": "races.html#conociendo-los-datos",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Conociendo los datos",
    "text": "Conociendo los datos\nConocer los datos es un paso fundamental en cualquier análisis. Proporciona una comprensión inicial del problema, permite validar la calidad de los datos, seleccionar características relevantes, preparar los datos adecuadamente y generar ideas y hipótesis. En resumen, la exploración inicial de los datos sienta las bases para un análisis más profundo y asegura que los resultados sean significativos y confiables.\n\nTipos de datos\nPara realizar un análisis exploratorio, primero debes conocer el tipo de variables con las que estamos tratando. Conocer si tenemos variables numéricas o categóricas podrían determinar el rumbo del análisis que realizaremos.\n\nrecords_data.dtypes\n\nraceid                         int64\nyear                           int64\nround                          int64\ncircuitid                      int64\nrace_name                     object\ncircuitref                    object\ncircuit_name                  object\ncircuit_location              object\ncircuit_country               object\ncircuit_lat                   object\ncircuit_lng                   object\ndriverid                       int64\nconstructorid                  int64\npoints                         int64\ngrid                           int64\nlaps                           int64\nrace_time_in_milliseconds      int64\nwinner_fastest_lap           float64\nwinner_lap_rank              float64\nwinner_fastestlapspeed        object\ngeneral_fastest_lap          float64\ngeneral_fastest_lap_time     float64\ndtype: object\n\n\nObservemos que todas las variables tienen el tipo de dato correcto, excepto la columna winner_fastestlapspeed, que toma valores numéricos pero está siendo interpretada como un dato tipo object. Por lo tanto, es necesario convertir esta columna en tipo numérico. Además, vamos a cambiar los tipos de datos de las variables raceid, round, circuitid, driverid y constructorid a tipo object.\n\nrecords_data['winner_fastestlapspeed'] = pd.to_numeric(records_data['winner_fastestlapspeed'])\nrecords_data[['raceid', 'round', 'circuitid', 'driverid', 'constructorid']] = records_data[['raceid', 'round', 'circuitid', 'driverid', 'constructorid']].astype('object')\n\nrecords_data.dtypes\n\nraceid                        object\nyear                           int64\nround                         object\ncircuitid                     object\nrace_name                     object\ncircuitref                    object\ncircuit_name                  object\ncircuit_location              object\ncircuit_country               object\ncircuit_lat                   object\ncircuit_lng                   object\ndriverid                      object\nconstructorid                 object\npoints                         int64\ngrid                           int64\nlaps                           int64\nrace_time_in_milliseconds      int64\nwinner_fastest_lap           float64\nwinner_lap_rank              float64\nwinner_fastestlapspeed       float64\ngeneral_fastest_lap          float64\ngeneral_fastest_lap_time     float64\ndtype: object\n\n\n\n\nDimensiones de los registros\nDeterminar el tamaño de nuestros registros es fundamental, ya que nos permite comprender la magnitud de la información que estamos manejando. Esto a su vez nos ayuda a establecer posibles caminos a seguir en caso de realizar transformaciones y análisis adicionales.\n\nrecords_data.shape\n\n(1094, 22)\n\n\nEsto indica que desde el año 1950 hasta el 2023 se llevaron a cabo más de 1000 carreras, lo que significa que estamos trabajando con una cantidad considerable de datos sobre carreras.\n\n\nDatos faltantes\nDeterminar la presencia de datos faltantes es crucial, ya que puede indicar si podemos confiar en una columna para el análisis o si necesitamos tomar medidas para imputar esos valores ausentes.\n\nrecords_data.isnull().sum()\n\nraceid                         0\nyear                           0\nround                          0\ncircuitid                      0\nrace_name                      0\ncircuitref                     0\ncircuit_name                   0\ncircuit_location               0\ncircuit_country                0\ncircuit_lat                    0\ncircuit_lng                    0\ndriverid                       0\nconstructorid                  0\npoints                         0\ngrid                           0\nlaps                           0\nrace_time_in_milliseconds      0\nwinner_fastest_lap           717\nwinner_lap_rank              716\nwinner_fastestlapspeed       717\ngeneral_fastest_lap          584\ngeneral_fastest_lap_time     584\ndtype: int64\n\n\nCon los resultados obtenidos, observamos que tenemos una cantidad significativa de datos faltantes. Esta situación puede afectar los análisis futuros, dependiendo del tipo de variable que estemos considerando. Es importante determinar un método adecuado para la imputación de datos en caso de que sea necesario. Veamos el porcentaje que representa esta cantidad de datos faltantes en el total de nuestros datos.\n\nmissing_values = records_data.isnull().sum()\nmissing_percentage = round((missing_values / len(records_data)) * 100, 4)\nmissing_percentage\n\nraceid                        0.0000\nyear                          0.0000\nround                         0.0000\ncircuitid                     0.0000\nrace_name                     0.0000\ncircuitref                    0.0000\ncircuit_name                  0.0000\ncircuit_location              0.0000\ncircuit_country               0.0000\ncircuit_lat                   0.0000\ncircuit_lng                   0.0000\ndriverid                      0.0000\nconstructorid                 0.0000\npoints                        0.0000\ngrid                          0.0000\nlaps                          0.0000\nrace_time_in_milliseconds     0.0000\nwinner_fastest_lap           65.5393\nwinner_lap_rank              65.4479\nwinner_fastestlapspeed       65.5393\ngeneral_fastest_lap          53.3821\ngeneral_fastest_lap_time     53.3821\ndtype: float64\n\n\nTenemos un gran porcentaje de datos faltantes en nuestras variables. Sin embargo, estos datos faltantes parecen estar concentrados en las variables relacionadas con medidas de tiempos y velocidades. Esto sugiere que estos datos podrían faltar debido a limitaciones técnicas o falta de registro en las fechas más antiguas, donde la toma de estas medidas podría no haber sido sistemática.\nPara comprender mejor la distribución de estos datos faltantes, examinemos en qué fechas están ocurriendo y verifiquemos la fecha máxima y mínima en la que faltan estas observaciones.\n\nrecords_data[records_data.isnull().any(axis = 1)]\n\n\n\n\n\n\n\n\n\nraceid\nyear\nround\ncircuitid\nrace_name\ncircuitref\ncircuit_name\ncircuit_location\ncircuit_country\ncircuit_lat\n...\nconstructorid\npoints\ngrid\nlaps\nrace_time_in_milliseconds\nwinner_fastest_lap\nwinner_lap_rank\nwinner_fastestlapspeed\ngeneral_fastest_lap\ngeneral_fastest_lap_time\n\n\n\n\n90\n108\n2003\n1\n1\nAustralian Grand Prix\nalbert_park\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n-37.8497\n...\n1\n10\n11\n58\n5682100\nNaN\nNaN\nNaN\n32.0\n87724.0\n\n\n91\n109\n2003\n2\n2\nMalaysian Grand Prix\nsepang\nSepang International Circuit\nKuala Lumpur\nMalaysia\n2.76083\n...\n1\n10\n7\n56\n5542195\nNaN\nNaN\nNaN\n45.0\n96412.0\n\n\n92\n110\n2003\n3\n18\nBrazilian Grand Prix\ninterlagos\nAutódromo José Carlos Pace\nSão Paulo\nBrazil\n-23.7036\n...\n17\n10\n8\n54\n5478200\nNaN\nNaN\nNaN\n46.0\n82032.0\n\n\n93\n111\n2003\n4\n21\nSan Marino Grand Prix\nimola\nAutodromo Enzo e Dino Ferrari\nImola\nItaly\n44.3439\n...\n6\n10\n1\n62\n5292058\nNaN\nNaN\nNaN\n17.0\n82491.0\n\n\n94\n112\n2003\n5\n4\nSpanish Grand Prix\ncatalunya\nCircuit de Barcelona-Catalunya\nMontmeló\nSpain\n41.57\n...\n6\n10\n1\n65\n5626933\nNaN\nNaN\nNaN\n52.0\n80143.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n819\n828\n1951\n4\n55\nFrench Grand Prix\nreims\nReims-Gueux\nReims\nFrance\n49.2542\n...\n51\n5\n7\n77\n12131000\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n820\n784\n1956\n1\n25\nArgentine Grand Prix\ngalvez\nAutódromo Juan y Oscar Gálvez\nBuenos Aires\nArgentina\n-34.6943\n...\n6\n5\n3\n98\n10803700\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n821\n780\n1957\n5\n58\nBritish Grand Prix\naintree\nAintree\nLiverpool\nUK\n53.4769\n...\n118\n5\n3\n90\n11197800\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n822\n728\n1963\n10\n56\nSouth African Grand Prix\ngeorge\nPrince George Circuit\nEastern Cape Province\nSouth Africa\n-33.0486\n...\n172\n9\n1\n85\n7836900\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1049\n1063\n2021\n12\n13\nBelgian Grand Prix\nspa\nCircuit de Spa-Francorchamps\nSpa\nBelgium\n50.4372\n...\n9\n13\n1\n1\n207071\nNaN\n0.0\nNaN\n1.0\n207071.0\n\n\n\n\n717 rows × 22 columns\n\n\n\n\n\n\nFecha mínima:  1950\nFecha promedio:  1980\nFecha máxima:  2021\n\n\nObservando estos resultados, podemos confirmar nuestra teoría. Estos registros faltantes pueden ser debidos a limitaciones técnicas en aquellos tiempos. Sin embargo, también tenemos datos faltantes recientes.",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla races"
    ]
  },
  {
    "objectID": "races.html#exploración-de-los-datos",
    "href": "races.html#exploración-de-los-datos",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Exploración de los datos",
    "text": "Exploración de los datos\nEn esta sección realizaremos el verdadero análisis exploratorio de nuestros datos. Abordaremos los siguientes aspectos:\n\nMedidas de tendencia central: Calcularemos medidas como la media, la mediana y la moda para entender mejor la distribución de nuestros datos.\nLimpieza de los datos: Abordaremos la limpieza de nuestros datos, incluyendo la búsqueda de datos atípicos.\nTransformación: Determinaremos si es necesario aplicar alguna transformación a nuestros datos para facilitar los análisis subsiguientes.\nVisualización: Utilizaremos herramientas gráficas para explorar el comportamiento de nuestros datos y extraer patrones o tendencias.\n\nEsta fase nos permitirá comprender mejor la naturaleza de nuestros datos y prepararlos adecuadamente para análisis más avanzados.\n\nMedidas de tendencia central\n\nrecords_data.describe()\n\n\n\n\n\n\n\n\n\nyear\npoints\ngrid\nlaps\nrace_time_in_milliseconds\nwinner_fastest_lap\nwinner_lap_rank\nwinner_fastestlapspeed\ngeneral_fastest_lap\ngeneral_fastest_lap_time\n\n\n\n\ncount\n1094.000000\n1094.000000\n1094.000000\n1094.000000\n1.094000e+03\n377.000000\n378.000000\n377.000000\n510.000000\n510.000000\n\n\nmean\n1991.635283\n13.200183\n2.710238\n64.812614\n6.390212e+06\n44.297082\n2.695767\n207.944472\n45.986275\n88098.447059\n\n\nstd\n20.236151\n6.952141\n2.657508\n20.397213\n1.657215e+06\n15.989751\n1.935302\n20.773775\n16.101282\n12714.556207\n\n\nmin\n1950.000000\n4.000000\n1.000000\n1.000000\n2.070710e+05\n5.000000\n0.000000\n151.388000\n1.000000\n55404.000000\n\n\n25%\n1976.000000\n9.000000\n1.000000\n54.000000\n5.445916e+06\n36.000000\n1.000000\n197.014000\n36.000000\n78443.000000\n\n\n50%\n1993.000000\n10.000000\n2.000000\n65.000000\n5.905204e+06\n47.000000\n2.000000\n208.314000\n49.000000\n86233.500000\n\n\n75%\n2009.000000\n10.000000\n3.000000\n73.000000\n6.805843e+06\n55.000000\n4.000000\n220.782000\n56.000000\n96421.000000\n\n\nmax\n2023.000000\n50.000000\n22.000000\n200.000000\n1.467954e+07\n78.000000\n14.000000\n257.320000\n80.000000\n207071.000000\n\n\n\n\n\n\n\n\n\nEstos resultados nos pueden permitir concluir lo siguiente:\n\nPuntos, posición en la parrilla y número de vueltas: La distribución de puntos obtenidos, la posición en la parrilla de salida y el número de vueltas varían ampliamente entre las carreras. Esto puede reflejar diferencias en la dificultad de los circuitos, la calidad de los vehículos y la estrategia de los equipos en cada evento específico.\nTiempo de carrera y velocidad: El tiempo medio de carrera es de aproximadamente 106 minutos, pero con una variabilidad significativa. lo que puede ser atribuible a factores como la longitud del circuito, condiciones climáticas y la cantidad de incidentes en la pista. La velocidad media de la vuelta más rápida realizada por el ganador es de alrededor de 207.94 km/h, lo que también puede variar según las características específicas del circuito y la competencia entre los conductores.\n\n\n\nLimpieza de los datos\nLa limpieza de datos es una etapa crucial en cualquier análisis, por lo que en este apartado trataremos los datos faltantes y observaremos si existen datos atípicos en nuestras variables.\n\nDatos faltantes\nExisten diversas estrategias para abordar este problema. Usualmente, en este tipo de análisis se recurre a la imputación de valores faltantes utilizando la media, moda o mediana, o llenando los datos con los valores anteriores o siguientes. Sin embargo, estas técnicas pueden no ser óptimas para conjuntos de datos extensos o con características específicas.\nEn nuestro caso, una estrategia efectiva sería utilizar la imputación de datos faltantes basada en puntos similares en los datos mediante el algoritmo KNN (K-Nearest Neighbors) y Random Forest Classification. Este método considera las características de observaciones similares para estimar los valores faltantes de manera más precisa y realista, lo que resulta especialmente útil en conjuntos de datos complejos como el nuestro.\nInicialmente, creemos un DataFrame temporal donde estarán los mismos datos de records_data pero sin las columnas correspondientes a tipo object.\n\ntemp_df = records_data.select_dtypes(exclude=['object'])\n\nimputer = IterativeImputer(min_value=0, max_iter=30, imputation_order='roman', random_state=1)\nimputed_data = imputer.fit_transform(temp_df)\n\ntemp_df_imputed = pd.DataFrame(imputed_data, columns=temp_df.columns)\ntemp_df_imputed.isnull().sum()\n\nyear                         0\npoints                       0\ngrid                         0\nlaps                         0\nrace_time_in_milliseconds    0\nwinner_fastest_lap           0\nwinner_lap_rank              0\nwinner_fastestlapspeed       0\ngeneral_fastest_lap          0\ngeneral_fastest_lap_time     0\ndtype: int64\n\n\nBien, ya no tenemos datos faltantes. Ahora, verifiquemos si los resultados obtenidos en las medidas de tendencia central del DataFrame original cambiaron significativamente.\n\ntemp_df_imputed.describe()\n\n\n\n\n\n\n\n\n\nyear\npoints\ngrid\nlaps\nrace_time_in_milliseconds\nwinner_fastest_lap\nwinner_lap_rank\nwinner_fastestlapspeed\ngeneral_fastest_lap\ngeneral_fastest_lap_time\n\n\n\n\ncount\n1094.000000\n1094.000000\n1094.000000\n1094.000000\n1.094000e+03\n1094.000000\n1094.000000\n1094.000000\n1094.000000\n1094.000000\n\n\nmean\n1991.635283\n13.200183\n2.710238\n64.812614\n6.390212e+06\n41.198089\n2.388976\n197.487624\n43.406781\n87917.959131\n\n\nstd\n20.236151\n6.952141\n2.657508\n20.397213\n1.657215e+06\n13.042462\n1.212770\n51.466986\n14.678942\n8687.161576\n\n\nmin\n1950.000000\n4.000000\n1.000000\n1.000000\n2.070710e+05\n4.442446\n0.000000\n0.000000\n1.000000\n55404.000000\n\n\n25%\n1976.000000\n9.000000\n1.000000\n54.000000\n5.445916e+06\n34.248065\n2.000000\n170.246741\n34.155086\n86470.178618\n\n\n50%\n1993.000000\n10.000000\n2.000000\n65.000000\n5.905204e+06\n41.206371\n2.220656\n202.165329\n44.429436\n87882.189112\n\n\n75%\n2009.000000\n10.000000\n3.000000\n73.000000\n6.805843e+06\n48.000000\n2.584096\n223.148500\n51.635757\n88294.173027\n\n\nmax\n2023.000000\n50.000000\n22.000000\n200.000000\n1.467954e+07\n97.874592\n14.000000\n368.033143\n96.392282\n207071.000000\n\n\n\n\n\n\n\n\n\nComparando los resultados de las medidas de tendencia central antes y después de la imputación de datos con el algoritmo KNN, observamos algunas diferencias significativas en ciertas variables:\n\nPuntos, posición en la parrilla y número de vueltas: No hubo cambios notables en estas variables, lo que indica que la imputación de datos no tuvo un impacto significativo en su distribución.\nTiempo de carrera y velocidad: La media del tiempo de carrera disminuyó ligeramente después de la imputación de datos, lo que sugiere que los nuevos valores imputados pueden haber afectado este aspecto. Por otro lado, la velocidad media de la vuelta más rápida realizada por el ganador experimentó una disminución significativa en su media y desviación estándar, lo que indica que la imputación de datos pudo haber tenido un impacto más notable en esta variable.\n\nAhora que hemos realizado la imputación de datos, pasemos estos datos a nuestro dataframe original.\n\nrecords_data[temp_df.columns] = temp_df_imputed\nrecords_data.isnull().sum()\n\nraceid                       0\nyear                         0\nround                        0\ncircuitid                    0\nrace_name                    0\ncircuitref                   0\ncircuit_name                 0\ncircuit_location             0\ncircuit_country              0\ncircuit_lat                  0\ncircuit_lng                  0\ndriverid                     0\nconstructorid                0\npoints                       0\ngrid                         0\nlaps                         0\nrace_time_in_milliseconds    0\nwinner_fastest_lap           0\nwinner_lap_rank              0\nwinner_fastestlapspeed       0\ngeneral_fastest_lap          0\ngeneral_fastest_lap_time     0\ndtype: int64\n\n\n\n\nDatos atípicos\nVeamos ahora si existen datos atípicos en nuestro registro. En este caso, utilizaremos el rango intercuartílico (IQR) para identificar los valores atípicos. Si un valor cae por debajo de Q1 - 1.5 * IQR o por encima de Q3 + 1.5 * IQR, se considera un valor atípico.\n\nnumeric_columns = temp_df.columns\n\nfor col in numeric_columns:\n    q1 = records_data[col].quantile(0.25)\n    q3 = records_data[col].quantile(0.75)\n\n    iqr = q3 - q1\n    lower_bound = q1 - 1.5 * iqr\n    upper_bound = q3 + 1.5 * iqr\n    outliers = records_data[(records_data[col] &lt; lower_bound) | (records_data[col] &gt; upper_bound)]\n    n_outliers = len(outliers)\n    print(f'#Outliers in {col} are {n_outliers} and represent a {round(n_outliers/len(records_data) * 100, 4)}% of total records')\n\n#Outliers in year are 0 and represent a 0.0% of total records\n#Outliers in points are 282 and represent a 25.777% of total records\n#Outliers in grid are 84 and represent a 7.6782% of total records\n#Outliers in laps are 47 and represent a 4.2962% of total records\n#Outliers in race_time_in_milliseconds are 94 and represent a 8.5923% of total records\n#Outliers in winner_fastest_lap are 48 and represent a 4.3876% of total records\n#Outliers in winner_lap_rank are 234 and represent a 21.3894% of total records\n#Outliers in winner_fastestlapspeed are 78 and represent a 7.1298% of total records\n#Outliers in general_fastest_lap are 17 and represent a 1.5539% of total records\n#Outliers in general_fastest_lap_time are 412 and represent a 37.66% of total records\n\n\nComo podemos observar, tenemos una cantidad significativa de datos atípicos en algunas de nuestras variables. Esto podría afectar más adelante en los modelos estadísticos que querramos implementar. Veamos gráficamente qué es lo que está ocurriendo con ellos.\nRealizaremos un gráfico de caja y bigotes e histogramas para ver el comportamiento y la distribución de nuestros datos.\n\nplt.figure(figsize=(9,12))\n\ni = 1\nfor col in numeric_columns:\n    plt.subplot(5,3,i)\n    plt.boxplot(records_data[col],whis=1.5)\n    plt.title(col)\n\n    i += 1\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure(figsize=(8,12))\n\ni = 1\nfor col in numeric_columns:\n    plt.subplot(5, 3, i)\n    sns.histplot(records_data[col], kde=True)\n    plt.title(col)\n    i += 1\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nDada la naturaleza de las variables, en algunos casos como rank, lap, grid, points, que son datos numéricos discretos y representan una categoría específica, es normal que existan datos atípicos. Por otro lado, para las otras variables en nuestra base de datos, estos datos atípicos no están afectando mucho la distribución de cada una de ellas, por lo tanto, no realizaremos cambios en ellas.",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla races"
    ]
  },
  {
    "objectID": "races.html#visualización",
    "href": "races.html#visualización",
    "title": "Campeonato Mundial de la Formula 1 (1950 - 2023)",
    "section": "Visualización",
    "text": "Visualización\nLa visualización es uno de los puntos más importantes a la hora de realizar una exploración de los datos. Con ella, no solo podemos encontrar las relaciones que existen entre nuestras variables, sino que también podemos representar gráficamente las informaciones más relevantes de los datos.\nComencemos visualizando los gráficos de correlación y dispersión entre las variables para comprender mejor sus relaciones y encontrar posibles patrones.\n\nGráfico de correlación\n\ncorr = records_data[numeric_columns].corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\nsns.heatmap(corr, annot=True, cmap='PRGn', square=True, center=0, mask=mask)\n\n\n\n\n\n\n\n\nComo podemos observar, las variables con una alta correlación (&gt;0.5 o &lt;-0.5) son aquellas que están relacionadas entre sí, como laps, winner_fastestlapspeed, general_fastest_lap, entre otras. Por lo tanto, esto no debería ser un problema y podemos proseguir con la exploración de los datos.\n\n\nGráfico de dispersión\n\nnumeric_columns = numeric_columns.drop(['points', 'winner_lap_rank'])\n\nplt.figure(figsize=(8, 12))\nsns.pairplot(records_data[numeric_columns])\nplt.show()\n\n&lt;Figure size 768x1152 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\nDe este gráfico podemos notar que a medida que pasan los años, la competencia ha evolucionado en términos de velocidades y tiempos de carreras obtenidos. La velocidad ha aumentado, lo que indica una mejora en los automóviles, y afecta directamente la duración de las carreras. Sin embargo, estos cambios en las velocidades y tiempos de carrera también se han vuelto más dispersos a lo largo de los años, lo que implica que ha habido una gran diferencia entre los equipos constructores. Además, también podemos observar algunas relaciones proporcionales en nuestras variables, como aquellas relacionadas nuevamente con las velocidades y tiempos.\n\n\nDistribución de tiempos de carrera por décadas\nVeamos cómo se distribuyen en cada una de las vueltas a lo largo de los años.\n\nrecords_data['race_time_in_seconds'] = records_data['race_time_in_milliseconds'] / 1000\nrecords_data['decade'] = records_data['year'].apply(lambda x: int(np.floor(x / 10) * 10))\n\nplt.figure(figsize=(8, 8))\nsns.boxplot(x='decade', y='race_time_in_seconds', data=records_data, palette=\"PRGn\", hue='decade', legend=False)\nplt.title('Distribución de duración de carreras por década')\nplt.xlabel('Década')\nplt.ylabel('Duración de Carreras (segundos)')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nSe destaca una clara tendencia hacia la reducción de los tiempos de vuelta con cada década sucesiva, lo que refleja los avances en la tecnología automotriz y la eficiencia aerodinámica. Esta mejora continua se evidencia en la reducción de la dispersión de los boxplots en décadas más recientes, especialmente en los años 2020, lo que sugiere una menor variabilidad y una mayor consistencia en el rendimiento de los pilotos y los vehículos.\nAdemás, la presencia de valores atípicos en los datos indica la ocurrencia de carreras con condiciones anómalas o extraordinarias, como cambios climáticos extremos o incidentes en la pista que han impactado significativamente en los tiempos de vuelta. Este análisis revela tanto la evolución constante de las capacidades tecnológicas como la influencia de factores externos en el rendimiento en pista.\n\n\nNúmero de premios celebrados por país\n\nraces_per_country = records_data['circuit_country'].value_counts()\n\nplt.figure(figsize=(8, 8))\nsns.barplot(x=races_per_country.values, y=races_per_country.index)\nplt.title('Número de premios celebrados por país')\nplt.xlabel('Número de Premios')\nplt.ylabel('País')\nplt.show()\n\n\n\n\n\n\n\n\nEl histograma presenta la distribución del número de Grandes Premios de Fórmula 1 celebrados por país. Italia lidera la lista, seguida por el Reino Unido (UK) y Alemania, lo que sugiere su arraigada tradición y su papel significativo en la historia del automovilismo. La prominencia de naciones europeas en la parte superior del gráfico refleja la influencia y la popularidad de la Fórmula 1 en Europa.\nPor otro lado, países como Qatar y Marruecos muestran un número relativamente bajo de eventos, lo que podría indicar una incorporación más reciente al calendario de la F1 o una frecuencia de carreras menos habitual. La variación en el número de premios por país puede estar influenciada por varios factores, como el interés local en el automovilismo, la infraestructura disponible para albergar eventos de este nivel y la historia del deporte en la región.\n\n\nEvolución de la velocidad\n\nplt.figure(figsize=(8, 8))\nsns.lineplot(x='year', y='winner_fastestlapspeed', data=records_data, label='Velocidad de Vuelta Más Rápida')\nplt.title('Evolución de la velocidad a lo largo de los años')\nplt.xlabel('Año')\nplt.ylabel('Velocidad (km/h)')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nEl gráfico presenta la evolución de la velocidad de la vuelta más rápida en la Fórmula 1 a lo largo de los años. Se observan fluctuaciones en la velocidad a lo largo del tiempo, con una tendencia general al aumento, especialmente notoria a partir de 2015. La sombra alrededor de la línea indica la variabilidad en la velocidad de la vuelta más rápida cada año, sugiriendo que, aunque hay años con velocidades pico, también existen otros factores que pueden afectar la velocidad, como las regulaciones técnicas, las condiciones meteorológicas o el diseño de los circuitos.\nEl incremento significativo de la velocidad a partir de la mitad de la década de 2010 podría atribuirse a avances tecnológicos en los motores y la aerodinámica, así como a cambios en las regulaciones de la F1 que permiten vehículos más rápidos. Sin embargo, el pico en los años recientes también puede reflejar el desarrollo y perfeccionamiento constante en las estrategias de carrera y la optimización del rendimiento del vehículo.\n\n\nMapa de las carreras realizadas\n\ncountry_counts = records_data['circuit_country'].value_counts().reset_index()\ncountry_counts.columns = ['circuit_country', 'num_races']\n\ntemp_df = pd.merge(records_data, country_counts, on='circuit_country')\n\nfig = px.scatter_mapbox(temp_df, lat=\"circuit_lat\", lon=\"circuit_lng\", hover_name=\"race_name\",\n                         hover_data={\"raceid\": True, \"race_time_in_milliseconds\": True, \"general_fastest_lap_time\": True},\n                         size=\"num_races\",\n                         zoom=4)\n\nfig.update_layout(mapbox_style=\"open-street-map\")\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n\nfig.show()",
    "crumbs": [
      "Análisis Exploratorio de Datos (EDA)",
      "Análisis de la tabla races"
    ]
  }
]